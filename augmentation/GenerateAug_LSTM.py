import os
import sys
import random
import time
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
pd.options.display.max_rows = None
pd.set_option('display.max_columns', 500)
np.set_printoptions(threshold=sys.maxsize)
np.set_printoptions(threshold=np.inf)
os.environ['PYTHONHASHSEED'] = '0'
np.random.seed(42)
random.seed(12345)
###Start sklearn
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import recall_score, auc, roc_curve, roc_auc_score, precision_recall_curve
from sklearn.metrics import precision_recall_fscore_support, f1_score
from sklearn.model_selection import train_test_split,TimeSeriesSplit,cross_val_score,KFold,cross_validate,GridSearchCV
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn import preprocessing
### End sklearn

###***Start tensorflow.keras
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import optimizers
from tensorflow.keras.optimizers import Adam
tf.random.set_seed(1234)
###**** End tensorflow.keras

from pathlib import Path
pathCurrrent = Path.cwd()
pathMainCodes = Path.cwd().parent
pathCurrrent = str(pathCurrrent).replace("\\", '/')
pathMainCodes = str(pathMainCodes).replace("\\", '/')
pathData = pathMainCodes + "/data/paperMachine/"
pathDataAuged = pathMainCodes + "/data/paperMachine/auged/"

DATA_SPLIT_PCT = 0.2

LABELS = ["Normal","Break"]

7#LSTM model tests
#LSTM model tests

datestr = time.strftime("%y%m%d_%H%M%S")
print(f"Start running time: {datestr}")

dfpShifted5ForAug = pd.read_csv(pathData+"dfpShifted5ForAug_1To5_201204_192153.csv",header=None)# All LSTM generated by this DS
#dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5JitterAuged_1To5_201204_192153.csv",header=None)#.8
# dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_ForAug_withAugedFawaz_OneZero_1To5_201221_002448.csv",header=None)# Fawaz
#dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_ForAug_withAugedJitter_OneZero_1To5_201220_013915.csv",header=None)#Jitter
#dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_ForAug_withAugedFawaz4_OneZero_1To5_201221_011005.csv",header=None)# Fawaz*4
#dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_AugedMagnitude_OneZero_1To5_201222_154819.csv",header=None)#Magnitude
dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_AugedFawazAll_OneZero_1To5_201223_172909.csv",header=None)# FawazAll
#dfpShifted5ForAug = pd.read_csv(pathData+"dfpShifted5_ForAug_AllTrainTest_201204_161806.csv",header=None)#shuffled
#dfpShifted5ForAug = pd.read_csv(pathData+"dfpShifted5_ForAug_201201_202734_AllTested_Correct_NT_NH.csv",header=None)#shuffled

dfpShifted5ForAug = dfpShifted5ForAug.loc[dfpShifted5ForAug[0]==1]
print(dfpShifted5ForAug.shape)
dfpShifted5JitterAuged = dfpShifted5JitterAuged.loc[dfpShifted5JitterAuged[0]==0]

dfActual=dfpShifted5ForAug
dfJAuged=dfpShifted5JitterAuged

rowCounts0 = len(dfActual)
rowCounts1 = len(dfJAuged)

input_XActual = dfActual.iloc[:rowCounts0, 1:].values  # converts the df to a numpy array
input_yActual = dfActual.iloc[:rowCounts0, 0].values

input_XJAuged = dfJAuged.iloc[:rowCounts1, 1:].values  # converts the df to a numpy array
input_yJAuged = dfJAuged.iloc[:rowCounts1, 0].values

# print('First instance of y = 1 in the original data')
# print(df.iloc[(np.where(np.array(input_y) == 1)[0][0]-5):(np.where(np.array(input_y) == 1)[0][0]+1), ])

# Temporalize the data
print(f'shape input_XActual: {input_XActual.shape}')
print(f'shape input_yActual: {input_yActual.shape}')

print(f'shape input_XJAuged: {input_XJAuged.shape}')
print(f'shape input_yJAuged: {input_yJAuged.shape}')


#ytest=yJAuged.reshpe(yJAuged.shape[0],-1)

# print('For the same instance of y = 1, we are keeping past 5 samples in the 3D predictor array, X.')
# print(pd.DataFrame(np.concatenate(X[np.where(np.array(y) == 1)[0][0]], axis=0 )))

xtrainActual = XActual#[:400]
ytrainActual=yActual#[:400]

xValidActual = XActual[400:]
yValidActual=yActual[400:]

xtestJAuged = XJAuged

#xtrain, xvalid, ytrain, yvalid = train_test_split(xtrain, ytrain, test_size=DATA_SPLIT_PCT, random_state=42)

# print(f"xtrain: {np.shape(xtrain)}, ytrain: {np.shape(ytrain)}")
# print(f"xvalid: {np.shape(xvalid)}, yvalid: {np.shape(yvalid)}")
# print(f"xtest: {np.shape(xtest)}, ytest: {np.shape(ytest)}")

timesteps = xtrainActual.shape[1]  # equal to the lookback
n_features = xtrainActual.shape[2]  # 59 number of features

epochs = 10#150
batch = 32
lr = 0.1

model = Sequential()
model.add(LSTM(256, activation='relu', input_shape=(timesteps,n_features), return_sequences=True))
model.add(LSTM(128, activation='relu', return_sequences=True))
model.add(LSTM(128, activation='relu', return_sequences=True))
model.add(LSTM(256, activation='relu', return_sequences=True))
model.add(TimeDistributed(Dense(n_features)))
model.compile(optimizer='adam', loss='mse')

print(model.summary())
# cp = ModelCheckpoint(filepath="lstm_autoencoder_classifier.h5",
#                                save_best_only=True,
#                                verbose=0)

# tb = TensorBoard(log_dir='./logs',
#                 histogram_freq=0,
#                 write_graph=True,
#                 write_images=True)

lstm_autoencoder_history = model.fit(xtrainActual, xtrainActual,
                                                epochs=epochs,
                                                batch_size=batch,
                                                #validation_data=(xValidActual, xValidActual),
                                                verbose=1, use_multiprocessing=True)#.history

yPred = model.predict(xtrainActual)


# min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))
# min_max_scaler.fit(flatten(xtrainActual))
# yPred_scaled = min_max_scaler.transform(flatten(yPred))
#ytrainActual=ytrainActual.astype(int)
#AugedLSTM=np.concatenate([ytrainActual.reshape(ytrainActual.shape[0],1),flatten(yPred)],axis=1)

datestr = time.strftime("%y%m%d_%H%M%S")
pd.DataFrame(flatten(yPred)).to_csv(pathData+f'dfpShifted5_AugedLSTM_Ones_1To5_seed_{datestr}.csv',index=None,header=None)
mse = np.mean(np.power(flatten(xtrainActual) - flatten(yPred), 2), axis=1)



ytrainActual=ytrainActual.tolist()#yJAuged
yPred=flatten(yPred)


precision_rt, recall_rt, threshold_rt = precision_recall_curve(ytrainActual, mse)#yJAuged
pr_re_auc = auc(recall_rt, precision_rt)
#lr_f1 = f1_score(ytest, y_pred_class)
# summarize scores
#print(f'f1: {lr_f1} , pr_re_auc: {pr_re_auc}')
print('pr_re_auc=%.3f' % (pr_re_auc))
print(f"MSE==> mean: {mse.mean()}, min: {mse.min()}, max: {mse.max()}")
plt.plot(threshold_rt, precision_rt[1:], label="Precision", linewidth=5)
plt.plot(threshold_rt, recall_rt[1:], label="Recall", linewidth=5)
plt.title('Precision and recall for different threshold values')
plt.xlabel('Threshold')
plt.ylabel('Precision/Recall')
plt.legend()
plt.show()

# scores = model.evaluate(xtest, ytest, verbose=0)
# print("Accuracy: %.2f%%" % (scores[1] * 100))

# apply threshold to positive probabilities to create labels
def to_labels(pos_probs, threshold):
	return (pos_probs >= threshold).astype('int')

# define thresholds
thresholds = np.arange(0, 1, 0.001)
# evaluate each threshold
# scores = [f1_score(yJAuged, to_labels(mse, t)) for t in thresholds]
# # get best threshold
# ix = np.argmax(scores)
# print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))
# #[0 if e > .1335 else 1 for e in mse]
y_pred_class = [1 if e < .00001 else 0 for e in mse]

target_names = ['Normal 0', 'Anomalous 1']
print(classification_report(ytrainActual, y_pred_class, target_names=target_names))

# print(f"xtrain: {np.shape(xtrain)}, ytrain: {np.shape(ytrain)}")
# print(f"xvalid: {np.shape(xvalid)}, yvalid: {np.shape(yvalid)}")
# print(f"xtest: {np.shape(xtest)}, ytest: {np.shape(ytest)}")

tn, fp, fn, tp = confusion_matrix(ytrainActual, y_pred_class).ravel()
print("True Negatives: ",tn)
print("False Positives: ",fp)
print("False Negatives: ",fn)
print("True Positives: ",tp)

datestr = time.strftime("%y%m%d_%H%M%S")
print(f"End running time: {datestr}")

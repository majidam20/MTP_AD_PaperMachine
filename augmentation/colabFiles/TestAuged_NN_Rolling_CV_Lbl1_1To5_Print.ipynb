{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U28pRChlTIhp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bveYbeBQTJmz"
   },
   "source": [
    "## **Start running RolLbl2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXy5Uq85HaYs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = None\n",
    "pd.set_option('display.max_columns', 500)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "random.seed(12345)\n",
    "\n",
    "###Start sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import recall_score, auc, roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.model_selection import train_test_split,TimeSeriesSplit,cross_val_score,KFold,cross_validate,GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "### End sklearn\n",
    "\n",
    "###***Start tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tf.random.set_seed(1234)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "###**** End tensorflow.keras\n",
    "#sys.path.append(\"..\")\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "pathAug = \"/content/drive/MyDrive/MasterThesis_Files/mainCodes/augmentation/\"\n",
    "pathData =\"/content/drive/MyDrive/MasterThesis_Files/mainCodes/data/forCrossValidation/Shifted5_Rol_Lbl2/\"\n",
    "\n",
    "\n",
    "\n",
    "sys.path.insert(0,pathAug)\n",
    "sys.path.insert(1,pathData)\n",
    "\n",
    "import preprocessRollingLabel2_NN as aug\n",
    "\n",
    "#####End Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5KxzUHw03_x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j29MxY7LgANj"
   },
   "outputs": [],
   "source": [
    "\n",
    "############ Start Running codes\n",
    "\n",
    "datestr = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "print(f\"Main Start running time : {datestr}\")\n",
    "\n",
    "#dfActual = pd.read_csv(pathData+\"Shifted5_NoLess5_AfterRol_Lbl2_5To1_210124_163135.csv\",header=None)\n",
    "dfActual = pd.read_csv(pathData+\"Shifted5_NoLess5_AfterRol_Lbl2_210124_155122.csv\",header=None)\n",
    "\n",
    "\n",
    "accPerFold = []\n",
    "lossPerFold = []\n",
    "dfPrReF1=pd.DataFrame()\n",
    "\n",
    "#dfActual=dfActual[:5000]\n",
    "\n",
    "yX=dfActual.values\n",
    "X = yX[:, 1:]  # converts the df to a numpy array\n",
    "y = yX[:, 0]\n",
    "\n",
    "print(f\"\\n Number of Actual labeled 0: {len(y[np.where(y==0)])}\")\n",
    "print(f\"Number of Actual labeled 1: {len(y[np.where(y==1)])}\")\n",
    "print(f\"Number of Actual labeled 2: {len(y[np.where(y==2)])} \\n\")\n",
    "\n",
    "\n",
    "dataSplitPCT=.3\n",
    "dataSplitValTestPCT=.5\n",
    "\n",
    "train_test_split_Shuffle=True\n",
    "flagFitShuffle = True\n",
    "flagSeed=True\n",
    "\n",
    "p1=\"\"\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)#5\n",
    "model=0\n",
    "\n",
    "for foldNum, (trainIndex, testIndex) in enumerate(skf.split(X,y),start=1):\n",
    "\n",
    "    #print(\"TRAIN:\", trainIndex, \"TEST:\", testIndex)\n",
    "\n",
    "    yXtrain, yXtest = yX[trainIndex], yX[testIndex]\n",
    "    #ytrain, ytest = y[trainIndex], y[testIndex]\n",
    "\n",
    "    AugedNN=aug.GenerateAug_NN_Rolling(yXtrain,foldNum,flagLbl2=False,jitterNum4Lbl1=3,jitterNum4Lbl2=29)###***Generate synthetic data 38\n",
    "\n",
    "    datestrfoldNum = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "    print(f\"\\n Start running time Fold={foldNum}: {datestrfoldNum} ,-------------------------- \\n\")\n",
    "\n",
    "    Actual_AugedNN=np.concatenate((yXtrain,AugedNN),axis=0)\n",
    "\n",
    "    yXtrain1, yXtrain2 = train_test_split(Actual_AugedNN, shuffle=train_test_split_Shuffle,\n",
    "                                                          test_size=dataSplitPCT, random_state=42,\n",
    "                                                          stratify=Actual_AugedNN[:,0])  # stratify=input_y\n",
    "\n",
    "    yXtrain = np.concatenate((yXtrain1, yXtrain2), axis=0)\n",
    "\n",
    "    yXvalid, yXtest = train_test_split(yXtest, shuffle=train_test_split_Shuffle,\n",
    "                                          test_size=dataSplitValTestPCT, random_state=42,\n",
    "                                          stratify=yXtest[:, 0])  # stratify=input_y\n",
    "\n",
    "    print(f\"\\n Number of Final yXtrain_Fold={foldNum} labeled 0: {len(yXtrain[np.where(yXtrain[:, 0] == 0)])}\")\n",
    "    print(f\"Number of Final yXtrain_Fold={foldNum} labeled 1: {len(yXtrain[np.where(yXtrain[:, 0] == 1)])}\")\n",
    "    print(f\"Number of Final yXtrain_Fold={foldNum} labeled 2: {len(yXtrain[np.where(yXtrain[:, 0] == 2)])} \\n\")\n",
    "\n",
    "    ytrain = to_categorical(yXtrain  [:,0] )\n",
    "    yvalid = to_categorical(yXvalid  [:,0] )\n",
    "    ytest  = to_categorical(yXtest   [:,0] )\n",
    "\n",
    "    xtrain = yXtrain  [:,1:]\n",
    "    xvalid = yXvalid  [:,1:]\n",
    "    xtest  = yXtest   [:,1:]\n",
    "\n",
    "\n",
    "    neurons = xtrain.shape[1]\n",
    "\n",
    "    epochs = 100#100#0#30#30# 150  # 0  # 100#300#60#300#10#200#00#150\n",
    "    batch = 32\n",
    "    lr = 0.0001\n",
    "\n",
    "    #flagR1 = True\n",
    "    flagR1=False\n",
    "    r1 = .1\n",
    "    r2 = .3\n",
    "    d1 = .3\n",
    "\n",
    "    if foldNum==1:\n",
    "        print(\"\\n Hyperparameters:\")\n",
    "        print(f\"epochs: {epochs}, batch: {batch}, lr: {lr}, neurons: {neurons}, flagFitShuffle: {flagFitShuffle} , train_test_split_Shuffle: {train_test_split_Shuffle}, flagSeed: {flagSeed}\\n \")\n",
    "\n",
    "        print(f\"\\n xtrain: {np.shape(xtrain)}, ytrain: {np.shape(ytrain)}\")\n",
    "        print(f\"xvalid: {np.shape(xvalid)}, yvalid: {np.shape(yvalid)}\")\n",
    "        print(f\"xtest: {np.shape(xtest)}, ytest: {np.shape(ytest)} \\n\")\n",
    "\n",
    "        #p1 = os.path.join(str(pathCurrent.parent.parent), \"Results\", \"Results_001_class_oppys\", \"bestModels\", \"\")\n",
    "        # pathSavingPlotsPerRunning = pathSavingPlots + datestr #+ \"_\" + modelname\n",
    "        # if not os.path.exists(pathSavingPlotsPerRunning):\n",
    "        #     os.makedirs(pathSavingPlotsPerRunning)\n",
    "\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(177, activation='tanh', input_dim=xtrain.shape[1]\n",
    "                    #,kernel_regularizer=l1_l2(l1=r1, l2=r2)\n",
    "                    #,kernel_regularizer = l1(r1) if flagR1 else l2(r2),\n",
    "                    ))  # , input_dim=xtrain.shape[1]\n",
    "    #model.add(Dropout(d1))\n",
    "\n",
    "    model.add(Dense(150, activation='tanh'\n",
    "                    #,kernel_regularizer=l1(r1) if flagR1 else l2(r2)\n",
    "                    #,kernel_regularizer=l1_l2(l1=r1, l2=r2)\n",
    "                    # bias_regularizer=l1(r2),\n",
    "                    #activity_regularizer=l1(r1) if flagR1 else l2(r2)\n",
    "                    # activity_regularizer=l1(r2)\n",
    "                    ))\n",
    "    #model.add(Dropout(d1))\n",
    "\n",
    "    model.add(Dense(90, activation='tanh'\n",
    "                    #,kernel_regularizer=l1(r1) if flagR1 else l2(r2)\n",
    "                    #,kernel_regularizer=l1_l2(l1=r1, l2=r2)\n",
    "                    # bias_regularizer=l1(r2),\n",
    "                    #activity_regularizer = l1(r1) if flagR1 else l2(r2)\n",
    "                    # activity_regularizer=l2(r2)\n",
    "                    ))\n",
    "    #model.add(Dropout(d1))\n",
    "\n",
    "    # model.add(Dense(295, activation='tanh'\n",
    "    #                 #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\n",
    "    # #                 # bias_regularizer=l1(r2),\n",
    "    # #                 activity_regularizer=l1(r1) if flagR1 else l2(r2)\n",
    "    # #                 # activity_regularizer=l2(r2)\n",
    "    #                 ))\n",
    "    #model.add(Dropout(d1))\n",
    "\n",
    "    # model.add(Dense(1, activation='sigmoid'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    adam = optimizers.Adam(lr)#lr\n",
    "    # cp = ModelCheckpoint(filepath=\"lstm_autoencoder_classifier.h5\",save_best_only=True,verbose=0)\n",
    "    # model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "    if foldNum == 1:\n",
    "        print(\"\\n Final test model.summary(): \\n\")\n",
    "        print(model.summary())\n",
    "\n",
    "        print(f\"\\n model.get_config: {str(model.get_config())}\")\n",
    "\n",
    "    # fit model\n",
    "    history1 = model.fit(xtrain, ytrain, batch_size=batch, epochs=epochs\n",
    "                         , validation_data=(xvalid, yvalid)\n",
    "                         , verbose=1, use_multiprocessing=True,\n",
    "                         shuffle=flagFitShuffle).history  # ,shuffle=True#,callbacks=[es]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history1['loss'], linewidth=2, label='Train')  # OR accuracy\n",
    "    plt.plot(history1['val_loss'], linewidth=2, label='Validation')  # OR val_accuracy\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.13, 1.13))\n",
    "    plt.title(f'Model loss Fold={foldNum}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(0,.5)\n",
    "    #plt.savefig(pathSavingPlotsPerRunning +\"/\" + f\"loss&val_loss_Fold={foldNum}_Epochs{epochs}_flagSeed{flagSeed}.png\", dpi=300, format='png')\n",
    "    plt.show()\n",
    "\n",
    "    yPred = model.predict(xtest, verbose=1)\n",
    "\n",
    "    print(f\"confusion_matrix_Fold={foldNum}:\\n {confusion_matrix(ytest.argmax(axis=1), yPred.argmax(axis=1))} \\n\")\n",
    "\n",
    "    # Creating multilabel confusion matrix\n",
    "    mlbConfusion = multilabel_confusion_matrix(ytest.argmax(axis=1), yPred.argmax(axis=1))\n",
    "    print(f\"multilabel_confusion_matrix_Fold={foldNum}:\\n {mlbConfusion} \\n\")\n",
    "\n",
    "    print(f\"accuracy_score_Fold={foldNum}:\\n {accuracy_score(ytest.argmax(axis=1), yPred.argmax(axis=1), normalize=False)} \\n\")\n",
    "\n",
    "    print(f\"classification_report_Fold={foldNum}:\\n {classification_report(ytest.argmax(axis=1), yPred.argmax(axis=1))} \\n\")\n",
    "\n",
    "    cr=pd.DataFrame(classification_report(ytest.argmax(axis=1), yPred.argmax(axis=1),output_dict=True))\n",
    "    dfPrReF1=dfPrReF1.append(cr.iloc[:3,:3])\n",
    "\n",
    "    # Predicting test images\n",
    "    # preds = np.where(yPred < 0.5, 0, 1)\n",
    "\n",
    "    mlbClasses = [0, 1, 2]\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for j, (label, matrix) in enumerate(zip(mlbClasses, mlbConfusion)):\n",
    "        plt.subplot(f'23{j + 1}')\n",
    "        labels = [f'Not_{label}', label]\n",
    "        sns.heatmap(matrix, annot=True, square=True, fmt='d', cbar=False, cmap='Blues',\n",
    "                    cbar_kws={'label': 'My Colorbar'},  # , fmt = 'd'\n",
    "                    xticklabels=labels, yticklabels=labels, linecolor='black', linewidth=1)\n",
    "\n",
    "        plt.ylabel('Actual class')\n",
    "        plt.xlabel(f'Predicted class_Fold={foldNum}')\n",
    "        plt.title(labels[0])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(pathSavingPlotsPerRunning +\"/\" + f\"ConfusionMatrix_Fold={foldNum}_Epochs{epochs}_flagSeed{flagSeed}.png\", dpi=300, format='png')\n",
    "    plt.show()\n",
    "\n",
    "    datestr = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "    print(f\"End running time Fold={foldNum}: {datestr} ,-------------------------- \\n\")\n",
    "\n",
    "dfPrReF1=pd.DataFrame([np.round(dfPrReF1[dfPrReF1.index=='precision'].mean(),2),np.round(dfPrReF1[dfPrReF1.index=='recall'].mean(),2)\n",
    ",np.round(dfPrReF1[dfPrReF1.index=='f1-score'].mean(),2)],index=['precision','recall','f1-score'])\n",
    "\n",
    "print(f\"\\nclassification_report_AllFolds:\\n {dfPrReF1}\")\n",
    "\n",
    "datestr = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "print(f\"End running time: {datestr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuXYtlqxpsNe"
   },
   "source": [
    "# End running  RolLbl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9zEE1AkST-3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nu1S5oeop9-Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiOORdHtqT-x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKUFvQagSUGD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVVZVyLVj_Zc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQ9Rj0YFjfWx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GX9ZZl-73Ev5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP6J0IarSgdJ"
   },
   "source": [
    "## **forAugShifted5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173919
    },
    "id": "Nz1jPyPPm6Ir",
    "outputId": "83f22a13-a2d5-45ca-f164-178e30d68946",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Start running time : 210214_085547\n",
      "\n",
      " Number of Actual labeled 0: 87245\n",
      "Number of Actual labeled 1: 2870\n",
      "Number of Actual labeled 2: 0 \n",
      "\n",
      "Start running time Data Augmentation_Fold=1: 210214_085548 ,-------------------------- \n",
      "\n",
      "\n",
      " Data Augmentation Hyperparameters:\n",
      "epochs: 2000, batch: 32, lr: 0.0001, neurons1: 177, neurons2: 150, flagFitShuffle: True \n",
      " \n",
      "\n",
      " Hyperparameters:\n",
      "\n",
      " Data Augmentation model.summary(): \n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 177)               10620     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               26700     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 90)                13590     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 59)                5369      \n",
      "=================================================================\n",
      "Total params: 56,279\n",
      "Trainable params: 56,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Data Augmentation MSE Label1, iter2==> mean: 1.2333758419753588e-05, min: 3.510143964658872e-06, max: 0.00023430869206242266\n",
      "End running time Data Augmentation_Fold=1: 210214_091523 ,-------------------------- \n",
      "\n",
      "\n",
      " Start running time Fold=1: 210214_091523 ,-------------------------- \n",
      "\n",
      "\n",
      " Number of Final yXtrain_Fold=1 labeled 0: 69796\n",
      "Number of Final yXtrain_Fold=1 labeled 1: 16072\n",
      "Number of Final yXtrain_Fold=1 labeled 2: 0 \n",
      "\n",
      "\n",
      " Hyperparameters:\n",
      "epochs: 1000, batch: 512, lr: 0.0001, neurons: 59, flagFitShuffle: True , train_test_split_Shuffle: True, flagSeed: True\n",
      " \n",
      "\n",
      " xtrain: (85868, 59), ytrain: (85868,)\n",
      "xvalid: (9011, 59), yvalid: (9011,)\n",
      "xtest: (9012, 59), ytest: (9012,) \n",
      "\n",
      "\n",
      " Final test model.summary(): \n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 177)               10620     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               26700     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 90)                13590     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 91        \n",
      "=================================================================\n",
      "Total params: 51,001\n",
      "Trainable params: 51,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      " model.get_config: {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 59), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'dense_input'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'batch_input_shape': (None, 59), 'dtype': 'float32', 'units': 177, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 150, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 90, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.5575 - accuracy: 0.7114 - val_loss: 0.2311 - val_accuracy: 0.9673\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8187 - val_loss: 0.2391 - val_accuracy: 0.9599\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8213 - val_loss: 0.2465 - val_accuracy: 0.9557\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8226 - val_loss: 0.2302 - val_accuracy: 0.9543\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8256 - val_loss: 0.2419 - val_accuracy: 0.9538\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8245 - val_loss: 0.2318 - val_accuracy: 0.9534\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8246 - val_loss: 0.2138 - val_accuracy: 0.9562\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8281 - val_loss: 0.2294 - val_accuracy: 0.9521\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8296 - val_loss: 0.2356 - val_accuracy: 0.9482\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8291 - val_loss: 0.2411 - val_accuracy: 0.9493\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8305 - val_loss: 0.2188 - val_accuracy: 0.9511\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8286 - val_loss: 0.2249 - val_accuracy: 0.9484\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8317 - val_loss: 0.2213 - val_accuracy: 0.9464\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.2308 - val_accuracy: 0.9433\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8340 - val_loss: 0.2112 - val_accuracy: 0.9462\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8355 - val_loss: 0.2179 - val_accuracy: 0.9444\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8369 - val_loss: 0.1953 - val_accuracy: 0.9494\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8374 - val_loss: 0.2074 - val_accuracy: 0.9451\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8364 - val_loss: 0.1879 - val_accuracy: 0.9484\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8395 - val_loss: 0.2280 - val_accuracy: 0.9370\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8409 - val_loss: 0.1907 - val_accuracy: 0.9465\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8399 - val_loss: 0.1870 - val_accuracy: 0.9481\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8415 - val_loss: 0.2032 - val_accuracy: 0.9414\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8411 - val_loss: 0.2073 - val_accuracy: 0.9349\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8429 - val_loss: 0.2087 - val_accuracy: 0.9345\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8438 - val_loss: 0.1842 - val_accuracy: 0.9430\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8458 - val_loss: 0.2218 - val_accuracy: 0.9289\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8483 - val_loss: 0.1995 - val_accuracy: 0.9390\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8505 - val_loss: 0.1769 - val_accuracy: 0.9482\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8505 - val_loss: 0.2054 - val_accuracy: 0.9332\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3131 - accuracy: 0.8515 - val_loss: 0.1840 - val_accuracy: 0.9404\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8548 - val_loss: 0.1810 - val_accuracy: 0.9397\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8569 - val_loss: 0.2116 - val_accuracy: 0.9252\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8576 - val_loss: 0.2015 - val_accuracy: 0.9314\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8613 - val_loss: 0.1716 - val_accuracy: 0.9443\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8637 - val_loss: 0.1785 - val_accuracy: 0.9402\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8644 - val_loss: 0.1606 - val_accuracy: 0.9502\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8670 - val_loss: 0.1877 - val_accuracy: 0.9334\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8694 - val_loss: 0.1900 - val_accuracy: 0.9312\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8714 - val_loss: 0.1885 - val_accuracy: 0.9298\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8742 - val_loss: 0.1649 - val_accuracy: 0.9424\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2710 - accuracy: 0.8760 - val_loss: 0.1939 - val_accuracy: 0.9293\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8791 - val_loss: 0.1578 - val_accuracy: 0.9440\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.8804 - val_loss: 0.1952 - val_accuracy: 0.9229\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8826 - val_loss: 0.1688 - val_accuracy: 0.9356\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.8835 - val_loss: 0.1677 - val_accuracy: 0.9372\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2551 - accuracy: 0.8846 - val_loss: 0.1514 - val_accuracy: 0.9457\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2507 - accuracy: 0.8858 - val_loss: 0.1780 - val_accuracy: 0.9311\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.8883 - val_loss: 0.1522 - val_accuracy: 0.9452\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2428 - accuracy: 0.8921 - val_loss: 0.1473 - val_accuracy: 0.9483\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2406 - accuracy: 0.8915 - val_loss: 0.1789 - val_accuracy: 0.9274\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.8931 - val_loss: 0.1622 - val_accuracy: 0.9372\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.8942 - val_loss: 0.1506 - val_accuracy: 0.9438\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.8961 - val_loss: 0.1685 - val_accuracy: 0.9347\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.8965 - val_loss: 0.1903 - val_accuracy: 0.9200\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.8988 - val_loss: 0.1453 - val_accuracy: 0.9444\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9002 - val_loss: 0.1348 - val_accuracy: 0.9492\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.9015 - val_loss: 0.1301 - val_accuracy: 0.9514\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9027 - val_loss: 0.1316 - val_accuracy: 0.9514\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9061 - val_loss: 0.1517 - val_accuracy: 0.9393\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9065 - val_loss: 0.1601 - val_accuracy: 0.9349\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9080 - val_loss: 0.1603 - val_accuracy: 0.9333\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9083 - val_loss: 0.1341 - val_accuracy: 0.9495\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2069 - accuracy: 0.9081 - val_loss: 0.1450 - val_accuracy: 0.9454\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2020 - accuracy: 0.9123 - val_loss: 0.1345 - val_accuracy: 0.9486\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2006 - accuracy: 0.9114 - val_loss: 0.1378 - val_accuracy: 0.9452\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9123 - val_loss: 0.1196 - val_accuracy: 0.9536\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9153 - val_loss: 0.1479 - val_accuracy: 0.9403\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9148 - val_loss: 0.1508 - val_accuracy: 0.9359\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9165 - val_loss: 0.1459 - val_accuracy: 0.9424\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9216 - val_loss: 0.1225 - val_accuracy: 0.9522\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1857 - accuracy: 0.9195 - val_loss: 0.1405 - val_accuracy: 0.9438\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9197 - val_loss: 0.1324 - val_accuracy: 0.9482\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9218 - val_loss: 0.1236 - val_accuracy: 0.9516\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1787 - accuracy: 0.9243 - val_loss: 0.1177 - val_accuracy: 0.9543\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9258 - val_loss: 0.1254 - val_accuracy: 0.9504\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9270 - val_loss: 0.1166 - val_accuracy: 0.9524\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9259 - val_loss: 0.1257 - val_accuracy: 0.9498\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9280 - val_loss: 0.1032 - val_accuracy: 0.9592\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9274 - val_loss: 0.1050 - val_accuracy: 0.9579\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9299 - val_loss: 0.1018 - val_accuracy: 0.9593\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9302 - val_loss: 0.1205 - val_accuracy: 0.9515\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9318 - val_loss: 0.1119 - val_accuracy: 0.9548\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9305 - val_loss: 0.0998 - val_accuracy: 0.9606\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9329 - val_loss: 0.0930 - val_accuracy: 0.9618\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9324 - val_loss: 0.1085 - val_accuracy: 0.9559\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9345 - val_loss: 0.1137 - val_accuracy: 0.9511\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9364 - val_loss: 0.0985 - val_accuracy: 0.9602\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9357 - val_loss: 0.1332 - val_accuracy: 0.9448\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9362 - val_loss: 0.0906 - val_accuracy: 0.9634\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 0.9352 - val_loss: 0.1019 - val_accuracy: 0.9588\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1531 - accuracy: 0.9376 - val_loss: 0.1221 - val_accuracy: 0.9488\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1509 - accuracy: 0.9386 - val_loss: 0.1077 - val_accuracy: 0.9562\n",
      "Epoch 94/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9383 - val_loss: 0.1064 - val_accuracy: 0.9566\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9391 - val_loss: 0.1254 - val_accuracy: 0.9471\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9398 - val_loss: 0.1029 - val_accuracy: 0.9568\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9411 - val_loss: 0.0902 - val_accuracy: 0.9627\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9413 - val_loss: 0.0994 - val_accuracy: 0.9581\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9403 - val_loss: 0.0988 - val_accuracy: 0.9591\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9424 - val_loss: 0.0969 - val_accuracy: 0.9595\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9437 - val_loss: 0.1043 - val_accuracy: 0.9557\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9426 - val_loss: 0.0922 - val_accuracy: 0.9617\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9444 - val_loss: 0.1046 - val_accuracy: 0.9538\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9428 - val_loss: 0.1153 - val_accuracy: 0.9515\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9445 - val_loss: 0.1134 - val_accuracy: 0.9516\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9448 - val_loss: 0.1113 - val_accuracy: 0.9525\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9467 - val_loss: 0.0968 - val_accuracy: 0.9588\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9473 - val_loss: 0.1112 - val_accuracy: 0.9528\n",
      "Epoch 109/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1323 - accuracy: 0.9487 - val_loss: 0.0809 - val_accuracy: 0.9659\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9472 - val_loss: 0.1122 - val_accuracy: 0.9509\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9474 - val_loss: 0.0735 - val_accuracy: 0.9704\n",
      "Epoch 112/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9472 - val_loss: 0.1010 - val_accuracy: 0.9571\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9482 - val_loss: 0.1029 - val_accuracy: 0.9562\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1320 - accuracy: 0.9487 - val_loss: 0.0901 - val_accuracy: 0.9612\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9479 - val_loss: 0.0936 - val_accuracy: 0.9594\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9489 - val_loss: 0.1131 - val_accuracy: 0.9513\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 0.9496 - val_loss: 0.0994 - val_accuracy: 0.9582\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9506 - val_loss: 0.0927 - val_accuracy: 0.9594\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9506 - val_loss: 0.0927 - val_accuracy: 0.9607\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9501 - val_loss: 0.1168 - val_accuracy: 0.9483\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 0.9508 - val_loss: 0.1099 - val_accuracy: 0.9524\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9510 - val_loss: 0.0847 - val_accuracy: 0.9642\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9507 - val_loss: 0.1021 - val_accuracy: 0.9556\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9519 - val_loss: 0.1204 - val_accuracy: 0.9474\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9497 - val_loss: 0.1012 - val_accuracy: 0.9564\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9517 - val_loss: 0.0920 - val_accuracy: 0.9608\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9520 - val_loss: 0.0974 - val_accuracy: 0.9581\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9528 - val_loss: 0.0865 - val_accuracy: 0.9627\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9520 - val_loss: 0.0808 - val_accuracy: 0.9654\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9549 - val_loss: 0.0895 - val_accuracy: 0.9610\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9527 - val_loss: 0.0879 - val_accuracy: 0.9610\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1189 - accuracy: 0.9549 - val_loss: 0.0804 - val_accuracy: 0.9649\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9558 - val_loss: 0.1021 - val_accuracy: 0.9571\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9552 - val_loss: 0.0907 - val_accuracy: 0.9608\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9560 - val_loss: 0.0888 - val_accuracy: 0.9607\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9550 - val_loss: 0.0816 - val_accuracy: 0.9632\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9554 - val_loss: 0.0929 - val_accuracy: 0.9594\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9555 - val_loss: 0.0880 - val_accuracy: 0.9625\n",
      "Epoch 139/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9557 - val_loss: 0.1043 - val_accuracy: 0.9556\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9567 - val_loss: 0.0941 - val_accuracy: 0.9587\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1169 - accuracy: 0.9556 - val_loss: 0.0943 - val_accuracy: 0.9598\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9593 - val_loss: 0.0766 - val_accuracy: 0.9678\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9559 - val_loss: 0.1012 - val_accuracy: 0.9559\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9565 - val_loss: 0.0793 - val_accuracy: 0.9663\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9576 - val_loss: 0.0906 - val_accuracy: 0.9608\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9587 - val_loss: 0.0969 - val_accuracy: 0.9585\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9565 - val_loss: 0.0838 - val_accuracy: 0.9648\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9572 - val_loss: 0.0886 - val_accuracy: 0.9609\n",
      "Epoch 149/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1117 - accuracy: 0.9584 - val_loss: 0.0748 - val_accuracy: 0.9679\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9591 - val_loss: 0.0883 - val_accuracy: 0.9617\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9597 - val_loss: 0.0933 - val_accuracy: 0.9591\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9587 - val_loss: 0.0971 - val_accuracy: 0.9579\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9590 - val_loss: 0.0689 - val_accuracy: 0.9691\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9590 - val_loss: 0.1062 - val_accuracy: 0.9559\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9586 - val_loss: 0.1122 - val_accuracy: 0.9508\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.9605 - val_loss: 0.0846 - val_accuracy: 0.9649\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9593 - val_loss: 0.1023 - val_accuracy: 0.9585\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9564 - val_loss: 0.0747 - val_accuracy: 0.9665\n",
      "Epoch 159/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9599 - val_loss: 0.0718 - val_accuracy: 0.9686\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9597 - val_loss: 0.0861 - val_accuracy: 0.9619\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9594 - val_loss: 0.0840 - val_accuracy: 0.9642\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 0.9612 - val_loss: 0.0866 - val_accuracy: 0.9630\n",
      "Epoch 163/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9615 - val_loss: 0.0810 - val_accuracy: 0.9639\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9593 - val_loss: 0.0754 - val_accuracy: 0.9666\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9614 - val_loss: 0.0871 - val_accuracy: 0.9619\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9628 - val_loss: 0.0655 - val_accuracy: 0.9710\n",
      "Epoch 167/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9632 - val_loss: 0.0917 - val_accuracy: 0.9613\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9620 - val_loss: 0.0863 - val_accuracy: 0.9643\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9622 - val_loss: 0.0853 - val_accuracy: 0.9633\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9618 - val_loss: 0.0900 - val_accuracy: 0.9615\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1021 - accuracy: 0.9630 - val_loss: 0.0627 - val_accuracy: 0.9725\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9611 - val_loss: 0.0841 - val_accuracy: 0.9634\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9615 - val_loss: 0.0812 - val_accuracy: 0.9653\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9629 - val_loss: 0.0793 - val_accuracy: 0.9659\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9628 - val_loss: 0.0878 - val_accuracy: 0.9632\n",
      "Epoch 176/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9613 - val_loss: 0.0886 - val_accuracy: 0.9617\n",
      "Epoch 177/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9639 - val_loss: 0.0844 - val_accuracy: 0.9642\n",
      "Epoch 178/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9634 - val_loss: 0.0912 - val_accuracy: 0.9605\n",
      "Epoch 179/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9631 - val_loss: 0.0846 - val_accuracy: 0.9635\n",
      "Epoch 180/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9631 - val_loss: 0.0703 - val_accuracy: 0.9701\n",
      "Epoch 181/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9631 - val_loss: 0.0819 - val_accuracy: 0.9639\n",
      "Epoch 182/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 0.9633 - val_loss: 0.0802 - val_accuracy: 0.9664\n",
      "Epoch 183/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9633 - val_loss: 0.0774 - val_accuracy: 0.9675\n",
      "Epoch 184/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9638 - val_loss: 0.0893 - val_accuracy: 0.9635\n",
      "Epoch 185/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9633 - val_loss: 0.0799 - val_accuracy: 0.9653\n",
      "Epoch 186/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9635 - val_loss: 0.0697 - val_accuracy: 0.9694\n",
      "Epoch 187/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9639 - val_loss: 0.0767 - val_accuracy: 0.9683\n",
      "Epoch 188/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9639 - val_loss: 0.0744 - val_accuracy: 0.9674\n",
      "Epoch 189/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9647 - val_loss: 0.0776 - val_accuracy: 0.9670\n",
      "Epoch 190/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9644 - val_loss: 0.0806 - val_accuracy: 0.9652\n",
      "Epoch 191/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9648 - val_loss: 0.0823 - val_accuracy: 0.9646\n",
      "Epoch 192/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0951 - accuracy: 0.9652 - val_loss: 0.0788 - val_accuracy: 0.9672\n",
      "Epoch 193/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9651 - val_loss: 0.0831 - val_accuracy: 0.9634\n",
      "Epoch 194/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9641 - val_loss: 0.0749 - val_accuracy: 0.9672\n",
      "Epoch 195/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9654 - val_loss: 0.0792 - val_accuracy: 0.9655\n",
      "Epoch 196/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9633 - val_loss: 0.0688 - val_accuracy: 0.9706\n",
      "Epoch 197/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0927 - accuracy: 0.9659 - val_loss: 0.0707 - val_accuracy: 0.9695\n",
      "Epoch 198/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9669 - val_loss: 0.0789 - val_accuracy: 0.9669\n",
      "Epoch 199/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9640 - val_loss: 0.0727 - val_accuracy: 0.9678\n",
      "Epoch 200/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9642 - val_loss: 0.0693 - val_accuracy: 0.9705\n",
      "Epoch 201/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9665 - val_loss: 0.0813 - val_accuracy: 0.9658\n",
      "Epoch 202/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9659 - val_loss: 0.0803 - val_accuracy: 0.9655\n",
      "Epoch 203/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9645 - val_loss: 0.0705 - val_accuracy: 0.9705\n",
      "Epoch 204/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9660 - val_loss: 0.0698 - val_accuracy: 0.9700\n",
      "Epoch 205/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9655 - val_loss: 0.0715 - val_accuracy: 0.9689\n",
      "Epoch 206/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9664 - val_loss: 0.0673 - val_accuracy: 0.9704\n",
      "Epoch 207/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9661 - val_loss: 0.0670 - val_accuracy: 0.9699\n",
      "Epoch 208/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9662 - val_loss: 0.0648 - val_accuracy: 0.9727\n",
      "Epoch 209/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 0.9668 - val_loss: 0.0659 - val_accuracy: 0.9701\n",
      "Epoch 210/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9658 - val_loss: 0.0625 - val_accuracy: 0.9721\n",
      "Epoch 211/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9663 - val_loss: 0.0649 - val_accuracy: 0.9720\n",
      "Epoch 212/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9656 - val_loss: 0.0696 - val_accuracy: 0.9713\n",
      "Epoch 213/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9671 - val_loss: 0.0764 - val_accuracy: 0.9686\n",
      "Epoch 214/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9663 - val_loss: 0.0814 - val_accuracy: 0.9676\n",
      "Epoch 215/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9664 - val_loss: 0.0739 - val_accuracy: 0.9685\n",
      "Epoch 216/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9681 - val_loss: 0.0652 - val_accuracy: 0.9714\n",
      "Epoch 217/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9663 - val_loss: 0.0734 - val_accuracy: 0.9689\n",
      "Epoch 218/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.9663 - val_loss: 0.0729 - val_accuracy: 0.9686\n",
      "Epoch 219/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9667 - val_loss: 0.0772 - val_accuracy: 0.9679\n",
      "Epoch 220/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9692 - val_loss: 0.0764 - val_accuracy: 0.9678\n",
      "Epoch 221/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9676 - val_loss: 0.0830 - val_accuracy: 0.9653\n",
      "Epoch 222/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9678 - val_loss: 0.0702 - val_accuracy: 0.9699\n",
      "Epoch 223/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9672 - val_loss: 0.0702 - val_accuracy: 0.9700\n",
      "Epoch 224/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9681 - val_loss: 0.0748 - val_accuracy: 0.9688\n",
      "Epoch 225/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9676 - val_loss: 0.0705 - val_accuracy: 0.9696\n",
      "Epoch 226/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9684 - val_loss: 0.0710 - val_accuracy: 0.9703\n",
      "Epoch 227/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9686 - val_loss: 0.0817 - val_accuracy: 0.9660\n",
      "Epoch 228/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9685 - val_loss: 0.0638 - val_accuracy: 0.9723\n",
      "Epoch 229/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9676 - val_loss: 0.0679 - val_accuracy: 0.9707\n",
      "Epoch 230/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9686 - val_loss: 0.0711 - val_accuracy: 0.9696\n",
      "Epoch 231/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9692 - val_loss: 0.0640 - val_accuracy: 0.9727\n",
      "Epoch 232/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9694 - val_loss: 0.0691 - val_accuracy: 0.9705\n",
      "Epoch 233/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9689 - val_loss: 0.0631 - val_accuracy: 0.9727\n",
      "Epoch 234/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9696 - val_loss: 0.0686 - val_accuracy: 0.9717\n",
      "Epoch 235/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9682 - val_loss: 0.0624 - val_accuracy: 0.9728\n",
      "Epoch 236/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9681 - val_loss: 0.0617 - val_accuracy: 0.9737\n",
      "Epoch 237/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9704 - val_loss: 0.0939 - val_accuracy: 0.9624\n",
      "Epoch 238/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9701 - val_loss: 0.0862 - val_accuracy: 0.9645\n",
      "Epoch 239/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9694 - val_loss: 0.0720 - val_accuracy: 0.9705\n",
      "Epoch 240/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9696 - val_loss: 0.0738 - val_accuracy: 0.9694\n",
      "Epoch 241/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9702 - val_loss: 0.0588 - val_accuracy: 0.9744\n",
      "Epoch 242/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9696 - val_loss: 0.0872 - val_accuracy: 0.9653\n",
      "Epoch 243/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9697 - val_loss: 0.0745 - val_accuracy: 0.9690\n",
      "Epoch 244/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9708 - val_loss: 0.0793 - val_accuracy: 0.9687\n",
      "Epoch 245/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9702 - val_loss: 0.0681 - val_accuracy: 0.9717\n",
      "Epoch 246/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0827 - accuracy: 0.9702 - val_loss: 0.0569 - val_accuracy: 0.9747\n",
      "Epoch 247/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9704 - val_loss: 0.0693 - val_accuracy: 0.9708\n",
      "Epoch 248/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0827 - accuracy: 0.9702 - val_loss: 0.0716 - val_accuracy: 0.9710\n",
      "Epoch 249/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9711 - val_loss: 0.0686 - val_accuracy: 0.9717\n",
      "Epoch 250/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0815 - accuracy: 0.9703 - val_loss: 0.0735 - val_accuracy: 0.9700\n",
      "Epoch 251/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9701 - val_loss: 0.0599 - val_accuracy: 0.9743\n",
      "Epoch 252/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9709 - val_loss: 0.0822 - val_accuracy: 0.9669\n",
      "Epoch 253/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9698 - val_loss: 0.0642 - val_accuracy: 0.9727\n",
      "Epoch 254/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9710 - val_loss: 0.0701 - val_accuracy: 0.9711\n",
      "Epoch 255/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9711 - val_loss: 0.0890 - val_accuracy: 0.9644\n",
      "Epoch 256/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9718 - val_loss: 0.0730 - val_accuracy: 0.9691\n",
      "Epoch 257/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9712 - val_loss: 0.0576 - val_accuracy: 0.9741\n",
      "Epoch 258/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9717 - val_loss: 0.0671 - val_accuracy: 0.9724\n",
      "Epoch 259/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9702 - val_loss: 0.0824 - val_accuracy: 0.9662\n",
      "Epoch 260/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9714 - val_loss: 0.0535 - val_accuracy: 0.9754\n",
      "Epoch 261/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9703 - val_loss: 0.0684 - val_accuracy: 0.9713\n",
      "Epoch 262/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9719 - val_loss: 0.0635 - val_accuracy: 0.9737\n",
      "Epoch 263/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9710 - val_loss: 0.0547 - val_accuracy: 0.9758\n",
      "Epoch 264/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9703 - val_loss: 0.0669 - val_accuracy: 0.9723\n",
      "Epoch 265/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9717 - val_loss: 0.0548 - val_accuracy: 0.9755\n",
      "Epoch 266/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9721 - val_loss: 0.0822 - val_accuracy: 0.9674\n",
      "Epoch 267/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9712 - val_loss: 0.0688 - val_accuracy: 0.9719\n",
      "Epoch 268/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9718 - val_loss: 0.0545 - val_accuracy: 0.9753\n",
      "Epoch 269/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9714 - val_loss: 0.0595 - val_accuracy: 0.9751\n",
      "Epoch 270/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9725 - val_loss: 0.0555 - val_accuracy: 0.9759\n",
      "Epoch 271/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9720 - val_loss: 0.0772 - val_accuracy: 0.9693\n",
      "Epoch 272/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9713 - val_loss: 0.0607 - val_accuracy: 0.9726\n",
      "Epoch 273/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9719 - val_loss: 0.0569 - val_accuracy: 0.9746\n",
      "Epoch 274/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9729 - val_loss: 0.0646 - val_accuracy: 0.9721\n",
      "Epoch 275/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9727 - val_loss: 0.0629 - val_accuracy: 0.9727\n",
      "Epoch 276/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9717 - val_loss: 0.0584 - val_accuracy: 0.9746\n",
      "Epoch 277/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9717 - val_loss: 0.0612 - val_accuracy: 0.9730\n",
      "Epoch 278/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9696 - val_loss: 0.0641 - val_accuracy: 0.9721\n",
      "Epoch 279/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9729 - val_loss: 0.0626 - val_accuracy: 0.9733\n",
      "Epoch 280/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9738 - val_loss: 0.0836 - val_accuracy: 0.9669\n",
      "Epoch 281/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9722 - val_loss: 0.0645 - val_accuracy: 0.9735\n",
      "Epoch 282/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9734 - val_loss: 0.0571 - val_accuracy: 0.9759\n",
      "Epoch 283/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9722 - val_loss: 0.0695 - val_accuracy: 0.9709\n",
      "Epoch 284/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9736 - val_loss: 0.0740 - val_accuracy: 0.9698\n",
      "Epoch 285/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9721 - val_loss: 0.0738 - val_accuracy: 0.9699\n",
      "Epoch 286/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9718 - val_loss: 0.0634 - val_accuracy: 0.9728\n",
      "Epoch 287/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9720 - val_loss: 0.0701 - val_accuracy: 0.9719\n",
      "Epoch 288/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9745 - val_loss: 0.0622 - val_accuracy: 0.9736\n",
      "Epoch 289/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9724 - val_loss: 0.0619 - val_accuracy: 0.9748\n",
      "Epoch 290/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9725 - val_loss: 0.0531 - val_accuracy: 0.9764\n",
      "Epoch 291/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9731 - val_loss: 0.0659 - val_accuracy: 0.9730\n",
      "Epoch 292/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9738 - val_loss: 0.0576 - val_accuracy: 0.9753\n",
      "Epoch 293/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9736 - val_loss: 0.0885 - val_accuracy: 0.9648\n",
      "Epoch 294/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9731 - val_loss: 0.0629 - val_accuracy: 0.9735\n",
      "Epoch 295/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9738 - val_loss: 0.0808 - val_accuracy: 0.9672\n",
      "Epoch 296/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9734 - val_loss: 0.0695 - val_accuracy: 0.9727\n",
      "Epoch 297/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9735 - val_loss: 0.0665 - val_accuracy: 0.9725\n",
      "Epoch 298/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9737 - val_loss: 0.0559 - val_accuracy: 0.9756\n",
      "Epoch 299/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9737 - val_loss: 0.0623 - val_accuracy: 0.9741\n",
      "Epoch 300/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9745 - val_loss: 0.0673 - val_accuracy: 0.9720\n",
      "Epoch 301/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9739 - val_loss: 0.0711 - val_accuracy: 0.9714\n",
      "Epoch 302/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9739 - val_loss: 0.0757 - val_accuracy: 0.9698\n",
      "Epoch 303/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9740 - val_loss: 0.0616 - val_accuracy: 0.9743\n",
      "Epoch 304/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9753 - val_loss: 0.0645 - val_accuracy: 0.9730\n",
      "Epoch 305/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9735 - val_loss: 0.0576 - val_accuracy: 0.9750\n",
      "Epoch 306/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9737 - val_loss: 0.0543 - val_accuracy: 0.9761\n",
      "Epoch 307/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9746 - val_loss: 0.0744 - val_accuracy: 0.9707\n",
      "Epoch 308/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9737 - val_loss: 0.0558 - val_accuracy: 0.9764\n",
      "Epoch 309/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9752 - val_loss: 0.0566 - val_accuracy: 0.9756\n",
      "Epoch 310/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9733 - val_loss: 0.0657 - val_accuracy: 0.9730\n",
      "Epoch 311/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9745 - val_loss: 0.0573 - val_accuracy: 0.9759\n",
      "Epoch 312/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9744 - val_loss: 0.0629 - val_accuracy: 0.9747\n",
      "Epoch 313/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9755 - val_loss: 0.0696 - val_accuracy: 0.9721\n",
      "Epoch 314/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9743 - val_loss: 0.0591 - val_accuracy: 0.9747\n",
      "Epoch 315/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9738 - val_loss: 0.0582 - val_accuracy: 0.9765\n",
      "Epoch 316/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9738 - val_loss: 0.0741 - val_accuracy: 0.9705\n",
      "Epoch 317/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9746 - val_loss: 0.0645 - val_accuracy: 0.9727\n",
      "Epoch 318/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9742 - val_loss: 0.0657 - val_accuracy: 0.9727\n",
      "Epoch 319/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9743 - val_loss: 0.0559 - val_accuracy: 0.9765\n",
      "Epoch 320/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9740 - val_loss: 0.0564 - val_accuracy: 0.9758\n",
      "Epoch 321/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9739 - val_loss: 0.0802 - val_accuracy: 0.9693\n",
      "Epoch 322/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9745 - val_loss: 0.0758 - val_accuracy: 0.9697\n",
      "Epoch 323/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9742 - val_loss: 0.0631 - val_accuracy: 0.9736\n",
      "Epoch 324/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9750 - val_loss: 0.0626 - val_accuracy: 0.9743\n",
      "Epoch 325/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9753 - val_loss: 0.0676 - val_accuracy: 0.9727\n",
      "Epoch 326/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9755 - val_loss: 0.0666 - val_accuracy: 0.9721\n",
      "Epoch 327/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9752 - val_loss: 0.0549 - val_accuracy: 0.9769\n",
      "Epoch 328/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9746 - val_loss: 0.0611 - val_accuracy: 0.9747\n",
      "Epoch 329/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9752 - val_loss: 0.0584 - val_accuracy: 0.9760\n",
      "Epoch 330/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9744 - val_loss: 0.0635 - val_accuracy: 0.9741\n",
      "Epoch 331/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9751 - val_loss: 0.0621 - val_accuracy: 0.9749\n",
      "Epoch 332/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9758 - val_loss: 0.0592 - val_accuracy: 0.9750\n",
      "Epoch 333/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9756 - val_loss: 0.0559 - val_accuracy: 0.9764\n",
      "Epoch 334/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9759 - val_loss: 0.0659 - val_accuracy: 0.9737\n",
      "Epoch 335/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9756 - val_loss: 0.0731 - val_accuracy: 0.9716\n",
      "Epoch 336/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9758 - val_loss: 0.0644 - val_accuracy: 0.9733\n",
      "Epoch 337/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9740 - val_loss: 0.0605 - val_accuracy: 0.9754\n",
      "Epoch 338/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9761 - val_loss: 0.0582 - val_accuracy: 0.9763\n",
      "Epoch 339/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9750 - val_loss: 0.0642 - val_accuracy: 0.9738\n",
      "Epoch 340/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9755 - val_loss: 0.0626 - val_accuracy: 0.9754\n",
      "Epoch 341/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9748 - val_loss: 0.0719 - val_accuracy: 0.9721\n",
      "Epoch 342/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9749 - val_loss: 0.0794 - val_accuracy: 0.9700\n",
      "Epoch 343/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9755 - val_loss: 0.0842 - val_accuracy: 0.9687\n",
      "Epoch 344/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9749 - val_loss: 0.0722 - val_accuracy: 0.9725\n",
      "Epoch 345/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9750 - val_loss: 0.0668 - val_accuracy: 0.9730\n",
      "Epoch 346/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9756 - val_loss: 0.0621 - val_accuracy: 0.9743\n",
      "Epoch 347/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9752 - val_loss: 0.0604 - val_accuracy: 0.9755\n",
      "Epoch 348/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9759 - val_loss: 0.0513 - val_accuracy: 0.9774\n",
      "Epoch 349/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9758 - val_loss: 0.0702 - val_accuracy: 0.9726\n",
      "Epoch 350/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.9765 - val_loss: 0.0675 - val_accuracy: 0.9728\n",
      "Epoch 351/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0694 - accuracy: 0.9757 - val_loss: 0.0739 - val_accuracy: 0.9713\n",
      "Epoch 352/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9756 - val_loss: 0.0688 - val_accuracy: 0.9729\n",
      "Epoch 353/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9742 - val_loss: 0.0522 - val_accuracy: 0.9758\n",
      "Epoch 354/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9764 - val_loss: 0.0632 - val_accuracy: 0.9750\n",
      "Epoch 355/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9761 - val_loss: 0.0592 - val_accuracy: 0.9756\n",
      "Epoch 356/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9759 - val_loss: 0.0595 - val_accuracy: 0.9760\n",
      "Epoch 357/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9758 - val_loss: 0.0747 - val_accuracy: 0.9713\n",
      "Epoch 358/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9761 - val_loss: 0.0639 - val_accuracy: 0.9740\n",
      "Epoch 359/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9766 - val_loss: 0.0670 - val_accuracy: 0.9740\n",
      "Epoch 360/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9753 - val_loss: 0.0645 - val_accuracy: 0.9740\n",
      "Epoch 361/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9752 - val_loss: 0.0652 - val_accuracy: 0.9741\n",
      "Epoch 362/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9751 - val_loss: 0.0535 - val_accuracy: 0.9770\n",
      "Epoch 363/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9757 - val_loss: 0.0770 - val_accuracy: 0.9699\n",
      "Epoch 364/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9758 - val_loss: 0.0607 - val_accuracy: 0.9749\n",
      "Epoch 365/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9756 - val_loss: 0.0658 - val_accuracy: 0.9738\n",
      "Epoch 366/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9754 - val_loss: 0.0624 - val_accuracy: 0.9749\n",
      "Epoch 367/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9773 - val_loss: 0.0547 - val_accuracy: 0.9770\n",
      "Epoch 368/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9765 - val_loss: 0.0709 - val_accuracy: 0.9729\n",
      "Epoch 369/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9760 - val_loss: 0.0774 - val_accuracy: 0.9709\n",
      "Epoch 370/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9757 - val_loss: 0.0643 - val_accuracy: 0.9747\n",
      "Epoch 371/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9766 - val_loss: 0.0664 - val_accuracy: 0.9736\n",
      "Epoch 372/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9769 - val_loss: 0.0545 - val_accuracy: 0.9770\n",
      "Epoch 373/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.0751 - val_accuracy: 0.9723\n",
      "Epoch 374/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9755 - val_loss: 0.0787 - val_accuracy: 0.9700\n",
      "Epoch 375/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9754 - val_loss: 0.0655 - val_accuracy: 0.9744\n",
      "Epoch 376/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9763 - val_loss: 0.0697 - val_accuracy: 0.9723\n",
      "Epoch 377/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9766 - val_loss: 0.0534 - val_accuracy: 0.9764\n",
      "Epoch 378/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9757 - val_loss: 0.0522 - val_accuracy: 0.9766\n",
      "Epoch 379/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9753 - val_loss: 0.0615 - val_accuracy: 0.9750\n",
      "Epoch 380/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9770 - val_loss: 0.0530 - val_accuracy: 0.9769\n",
      "Epoch 381/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9761 - val_loss: 0.0635 - val_accuracy: 0.9749\n",
      "Epoch 382/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9759 - val_loss: 0.0635 - val_accuracy: 0.9750\n",
      "Epoch 383/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9761 - val_loss: 0.0547 - val_accuracy: 0.9768\n",
      "Epoch 384/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9763 - val_loss: 0.0730 - val_accuracy: 0.9724\n",
      "Epoch 385/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9767 - val_loss: 0.0665 - val_accuracy: 0.9738\n",
      "Epoch 386/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.9757 - val_loss: 0.0676 - val_accuracy: 0.9731\n",
      "Epoch 387/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9773 - val_loss: 0.0574 - val_accuracy: 0.9773\n",
      "Epoch 388/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.0686 - val_accuracy: 0.9735\n",
      "Epoch 389/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9755 - val_loss: 0.0664 - val_accuracy: 0.9743\n",
      "Epoch 390/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9765 - val_loss: 0.0606 - val_accuracy: 0.9750\n",
      "Epoch 391/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9764 - val_loss: 0.0664 - val_accuracy: 0.9744\n",
      "Epoch 392/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9760 - val_loss: 0.0607 - val_accuracy: 0.9753\n",
      "Epoch 393/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9763 - val_loss: 0.0622 - val_accuracy: 0.9743\n",
      "Epoch 394/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9764 - val_loss: 0.0607 - val_accuracy: 0.9755\n",
      "Epoch 395/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9773 - val_loss: 0.0678 - val_accuracy: 0.9744\n",
      "Epoch 396/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0659 - accuracy: 0.9760 - val_loss: 0.0529 - val_accuracy: 0.9774\n",
      "Epoch 397/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9774 - val_loss: 0.0516 - val_accuracy: 0.9779\n",
      "Epoch 398/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9765 - val_loss: 0.0668 - val_accuracy: 0.9738\n",
      "Epoch 399/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 0.0507 - val_accuracy: 0.9770\n",
      "Epoch 400/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9766 - val_loss: 0.0560 - val_accuracy: 0.9770\n",
      "Epoch 401/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9763 - val_loss: 0.0583 - val_accuracy: 0.9758\n",
      "Epoch 402/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9771 - val_loss: 0.0584 - val_accuracy: 0.9765\n",
      "Epoch 403/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9763 - val_loss: 0.0631 - val_accuracy: 0.9749\n",
      "Epoch 404/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.0689 - val_accuracy: 0.9731\n",
      "Epoch 405/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9773 - val_loss: 0.0576 - val_accuracy: 0.9759\n",
      "Epoch 406/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9756 - val_loss: 0.0554 - val_accuracy: 0.9765\n",
      "Epoch 407/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9780 - val_loss: 0.0684 - val_accuracy: 0.9746\n",
      "Epoch 408/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9771 - val_loss: 0.0661 - val_accuracy: 0.9740\n",
      "Epoch 409/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9773 - val_loss: 0.0632 - val_accuracy: 0.9746\n",
      "Epoch 410/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9775 - val_loss: 0.0618 - val_accuracy: 0.9758\n",
      "Epoch 411/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 0.0675 - val_accuracy: 0.9738\n",
      "Epoch 412/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9781 - val_loss: 0.0683 - val_accuracy: 0.9740\n",
      "Epoch 413/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9771 - val_loss: 0.0720 - val_accuracy: 0.9730\n",
      "Epoch 414/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9785 - val_loss: 0.0511 - val_accuracy: 0.9766\n",
      "Epoch 415/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 0.0523 - val_accuracy: 0.9780\n",
      "Epoch 416/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9777 - val_loss: 0.0538 - val_accuracy: 0.9768\n",
      "Epoch 417/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9768 - val_loss: 0.0561 - val_accuracy: 0.9769\n",
      "Epoch 418/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 0.0538 - val_accuracy: 0.9776\n",
      "Epoch 419/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9759 - val_loss: 0.0611 - val_accuracy: 0.9755\n",
      "Epoch 420/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9771 - val_loss: 0.0584 - val_accuracy: 0.9769\n",
      "Epoch 421/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9767 - val_loss: 0.0569 - val_accuracy: 0.9766\n",
      "Epoch 422/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9782 - val_loss: 0.0535 - val_accuracy: 0.9777\n",
      "Epoch 423/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9765 - val_loss: 0.0608 - val_accuracy: 0.9760\n",
      "Epoch 424/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9776 - val_loss: 0.0527 - val_accuracy: 0.9767\n",
      "Epoch 425/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9776 - val_loss: 0.0546 - val_accuracy: 0.9766\n",
      "Epoch 426/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9767 - val_loss: 0.0672 - val_accuracy: 0.9739\n",
      "Epoch 427/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9758 - val_loss: 0.0702 - val_accuracy: 0.9731\n",
      "Epoch 428/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9778 - val_loss: 0.0756 - val_accuracy: 0.9701\n",
      "Epoch 429/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9771 - val_loss: 0.0587 - val_accuracy: 0.9758\n",
      "Epoch 430/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9777 - val_loss: 0.0537 - val_accuracy: 0.9768\n",
      "Epoch 431/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9777 - val_loss: 0.0684 - val_accuracy: 0.9740\n",
      "Epoch 432/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9766 - val_loss: 0.0652 - val_accuracy: 0.9750\n",
      "Epoch 433/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.0616 - val_accuracy: 0.9754\n",
      "Epoch 434/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9772 - val_loss: 0.0647 - val_accuracy: 0.9741\n",
      "Epoch 435/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9780 - val_loss: 0.0602 - val_accuracy: 0.9761\n",
      "Epoch 436/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9772 - val_loss: 0.0698 - val_accuracy: 0.9743\n",
      "Epoch 437/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9772 - val_loss: 0.0782 - val_accuracy: 0.9717\n",
      "Epoch 438/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 0.0598 - val_accuracy: 0.9763\n",
      "Epoch 439/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9772 - val_loss: 0.0551 - val_accuracy: 0.9776\n",
      "Epoch 440/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9777 - val_loss: 0.0751 - val_accuracy: 0.9728\n",
      "Epoch 441/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9778 - val_loss: 0.0552 - val_accuracy: 0.9765\n",
      "Epoch 442/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.0578 - val_accuracy: 0.9767\n",
      "Epoch 443/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9779 - val_loss: 0.0647 - val_accuracy: 0.9753\n",
      "Epoch 444/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9771 - val_loss: 0.0650 - val_accuracy: 0.9749\n",
      "Epoch 445/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9784 - val_loss: 0.0670 - val_accuracy: 0.9747\n",
      "Epoch 446/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9784 - val_loss: 0.0621 - val_accuracy: 0.9763\n",
      "Epoch 447/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9776 - val_loss: 0.0586 - val_accuracy: 0.9765\n",
      "Epoch 448/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9776 - val_loss: 0.0647 - val_accuracy: 0.9750\n",
      "Epoch 449/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9781 - val_loss: 0.0630 - val_accuracy: 0.9755\n",
      "Epoch 450/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9773 - val_loss: 0.0534 - val_accuracy: 0.9776\n",
      "Epoch 451/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9788 - val_loss: 0.0574 - val_accuracy: 0.9770\n",
      "Epoch 452/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9777 - val_loss: 0.0515 - val_accuracy: 0.9775\n",
      "Epoch 453/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9776 - val_loss: 0.0481 - val_accuracy: 0.9784\n",
      "Epoch 454/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9766 - val_loss: 0.0556 - val_accuracy: 0.9767\n",
      "Epoch 455/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9783 - val_loss: 0.0597 - val_accuracy: 0.9774\n",
      "Epoch 456/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9778 - val_loss: 0.0630 - val_accuracy: 0.9749\n",
      "Epoch 457/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9776 - val_loss: 0.0575 - val_accuracy: 0.9760\n",
      "Epoch 458/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9780 - val_loss: 0.0563 - val_accuracy: 0.9776\n",
      "Epoch 459/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9770 - val_loss: 0.0578 - val_accuracy: 0.9763\n",
      "Epoch 460/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9785 - val_loss: 0.0530 - val_accuracy: 0.9764\n",
      "Epoch 461/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9783 - val_loss: 0.0551 - val_accuracy: 0.9776\n",
      "Epoch 462/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9781 - val_loss: 0.0579 - val_accuracy: 0.9775\n",
      "Epoch 463/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9785 - val_loss: 0.0641 - val_accuracy: 0.9751\n",
      "Epoch 464/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9784 - val_loss: 0.0539 - val_accuracy: 0.9784\n",
      "Epoch 465/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9777 - val_loss: 0.0590 - val_accuracy: 0.9773\n",
      "Epoch 466/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9784 - val_loss: 0.0577 - val_accuracy: 0.9766\n",
      "Epoch 467/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9776 - val_loss: 0.0680 - val_accuracy: 0.9738\n",
      "Epoch 468/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9788 - val_loss: 0.0553 - val_accuracy: 0.9770\n",
      "Epoch 469/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9783 - val_loss: 0.0565 - val_accuracy: 0.9769\n",
      "Epoch 470/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9775 - val_loss: 0.0567 - val_accuracy: 0.9769\n",
      "Epoch 471/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9777 - val_loss: 0.0553 - val_accuracy: 0.9773\n",
      "Epoch 472/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 0.0719 - val_accuracy: 0.9728\n",
      "Epoch 473/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9782 - val_loss: 0.0604 - val_accuracy: 0.9760\n",
      "Epoch 474/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9776 - val_loss: 0.0554 - val_accuracy: 0.9776\n",
      "Epoch 475/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.0557 - val_accuracy: 0.9776\n",
      "Epoch 476/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9777 - val_loss: 0.0654 - val_accuracy: 0.9749\n",
      "Epoch 477/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9779 - val_loss: 0.0648 - val_accuracy: 0.9754\n",
      "Epoch 478/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9776 - val_loss: 0.0573 - val_accuracy: 0.9770\n",
      "Epoch 479/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9784 - val_loss: 0.0537 - val_accuracy: 0.9778\n",
      "Epoch 480/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9777 - val_loss: 0.0573 - val_accuracy: 0.9769\n",
      "Epoch 481/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9776 - val_loss: 0.0670 - val_accuracy: 0.9748\n",
      "Epoch 482/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9779 - val_loss: 0.0608 - val_accuracy: 0.9765\n",
      "Epoch 483/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9793 - val_loss: 0.0664 - val_accuracy: 0.9751\n",
      "Epoch 484/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9788 - val_loss: 0.0625 - val_accuracy: 0.9754\n",
      "Epoch 485/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9773 - val_loss: 0.0615 - val_accuracy: 0.9756\n",
      "Epoch 486/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9779 - val_loss: 0.0546 - val_accuracy: 0.9773\n",
      "Epoch 487/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9781 - val_loss: 0.0613 - val_accuracy: 0.9764\n",
      "Epoch 488/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9782 - val_loss: 0.0642 - val_accuracy: 0.9753\n",
      "Epoch 489/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9783 - val_loss: 0.0506 - val_accuracy: 0.9791\n",
      "Epoch 490/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9786 - val_loss: 0.0628 - val_accuracy: 0.9760\n",
      "Epoch 491/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9781 - val_loss: 0.0507 - val_accuracy: 0.9767\n",
      "Epoch 492/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9772 - val_loss: 0.0612 - val_accuracy: 0.9759\n",
      "Epoch 493/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9780 - val_loss: 0.0592 - val_accuracy: 0.9763\n",
      "Epoch 494/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9783 - val_loss: 0.0578 - val_accuracy: 0.9773\n",
      "Epoch 495/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9786 - val_loss: 0.0552 - val_accuracy: 0.9769\n",
      "Epoch 496/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9781 - val_loss: 0.0577 - val_accuracy: 0.9773\n",
      "Epoch 497/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9787 - val_loss: 0.0549 - val_accuracy: 0.9774\n",
      "Epoch 498/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9779 - val_loss: 0.0641 - val_accuracy: 0.9756\n",
      "Epoch 499/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9784 - val_loss: 0.0613 - val_accuracy: 0.9755\n",
      "Epoch 500/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9789 - val_loss: 0.0517 - val_accuracy: 0.9779\n",
      "Epoch 501/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9786 - val_loss: 0.0515 - val_accuracy: 0.9779\n",
      "Epoch 502/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9785 - val_loss: 0.0543 - val_accuracy: 0.9784\n",
      "Epoch 503/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9782 - val_loss: 0.0557 - val_accuracy: 0.9771\n",
      "Epoch 504/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9779 - val_loss: 0.0685 - val_accuracy: 0.9743\n",
      "Epoch 505/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9785 - val_loss: 0.0659 - val_accuracy: 0.9744\n",
      "Epoch 506/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9792 - val_loss: 0.0523 - val_accuracy: 0.9782\n",
      "Epoch 507/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9788 - val_loss: 0.0691 - val_accuracy: 0.9749\n",
      "Epoch 508/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9785 - val_loss: 0.0575 - val_accuracy: 0.9764\n",
      "Epoch 509/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9771 - val_loss: 0.0525 - val_accuracy: 0.9774\n",
      "Epoch 510/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9792 - val_loss: 0.0631 - val_accuracy: 0.9761\n",
      "Epoch 511/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9783 - val_loss: 0.0596 - val_accuracy: 0.9751\n",
      "Epoch 512/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9785 - val_loss: 0.0644 - val_accuracy: 0.9754\n",
      "Epoch 513/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9783 - val_loss: 0.0598 - val_accuracy: 0.9761\n",
      "Epoch 514/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9786 - val_loss: 0.0601 - val_accuracy: 0.9756\n",
      "Epoch 515/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9789 - val_loss: 0.0542 - val_accuracy: 0.9774\n",
      "Epoch 516/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9778 - val_loss: 0.0561 - val_accuracy: 0.9771\n",
      "Epoch 517/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9788 - val_loss: 0.0573 - val_accuracy: 0.9777\n",
      "Epoch 518/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9792 - val_loss: 0.0596 - val_accuracy: 0.9766\n",
      "Epoch 519/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9785 - val_loss: 0.0553 - val_accuracy: 0.9766\n",
      "Epoch 520/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9789 - val_loss: 0.0618 - val_accuracy: 0.9757\n",
      "Epoch 521/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9794 - val_loss: 0.0576 - val_accuracy: 0.9782\n",
      "Epoch 522/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9796 - val_loss: 0.0508 - val_accuracy: 0.9790\n",
      "Epoch 523/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9795 - val_loss: 0.0643 - val_accuracy: 0.9756\n",
      "Epoch 524/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9791 - val_loss: 0.0562 - val_accuracy: 0.9781\n",
      "Epoch 525/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9793 - val_loss: 0.0551 - val_accuracy: 0.9777\n",
      "Epoch 526/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9785 - val_loss: 0.0606 - val_accuracy: 0.9756\n",
      "Epoch 527/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 0.0708 - val_accuracy: 0.9740\n",
      "Epoch 528/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9797 - val_loss: 0.0523 - val_accuracy: 0.9775\n",
      "Epoch 529/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.0590 - val_accuracy: 0.9761\n",
      "Epoch 530/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9791 - val_loss: 0.0572 - val_accuracy: 0.9765\n",
      "Epoch 531/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9783 - val_loss: 0.0511 - val_accuracy: 0.9775\n",
      "Epoch 532/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9787 - val_loss: 0.0528 - val_accuracy: 0.9779\n",
      "Epoch 533/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9781 - val_loss: 0.0613 - val_accuracy: 0.9766\n",
      "Epoch 534/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9794 - val_loss: 0.0486 - val_accuracy: 0.9778\n",
      "Epoch 535/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9778 - val_loss: 0.0586 - val_accuracy: 0.9760\n",
      "Epoch 536/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9785 - val_loss: 0.0628 - val_accuracy: 0.9756\n",
      "Epoch 537/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9800 - val_loss: 0.0543 - val_accuracy: 0.9771\n",
      "Epoch 538/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9777 - val_loss: 0.0582 - val_accuracy: 0.9769\n",
      "Epoch 539/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9789 - val_loss: 0.0515 - val_accuracy: 0.9784\n",
      "Epoch 540/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9779 - val_loss: 0.0554 - val_accuracy: 0.9771\n",
      "Epoch 541/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9791 - val_loss: 0.0555 - val_accuracy: 0.9773\n",
      "Epoch 542/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9796 - val_loss: 0.0621 - val_accuracy: 0.9757\n",
      "Epoch 543/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9792 - val_loss: 0.0525 - val_accuracy: 0.9774\n",
      "Epoch 544/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9787 - val_loss: 0.0510 - val_accuracy: 0.9775\n",
      "Epoch 545/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9793 - val_loss: 0.0618 - val_accuracy: 0.9760\n",
      "Epoch 546/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9804 - val_loss: 0.0588 - val_accuracy: 0.9774\n",
      "Epoch 547/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9790 - val_loss: 0.0599 - val_accuracy: 0.9759\n",
      "Epoch 548/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9789 - val_loss: 0.0532 - val_accuracy: 0.9780\n",
      "Epoch 549/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9795 - val_loss: 0.0589 - val_accuracy: 0.9767\n",
      "Epoch 550/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9786 - val_loss: 0.0520 - val_accuracy: 0.9775\n",
      "Epoch 551/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9782 - val_loss: 0.0544 - val_accuracy: 0.9770\n",
      "Epoch 552/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9790 - val_loss: 0.0637 - val_accuracy: 0.9757\n",
      "Epoch 553/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0558 - accuracy: 0.9803 - val_loss: 0.0573 - val_accuracy: 0.9766\n",
      "Epoch 554/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9799 - val_loss: 0.0580 - val_accuracy: 0.9765\n",
      "Epoch 555/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9794 - val_loss: 0.0538 - val_accuracy: 0.9769\n",
      "Epoch 556/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9786 - val_loss: 0.0529 - val_accuracy: 0.9774\n",
      "Epoch 557/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9786 - val_loss: 0.0562 - val_accuracy: 0.9775\n",
      "Epoch 558/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9794 - val_loss: 0.0657 - val_accuracy: 0.9750\n",
      "Epoch 559/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9792 - val_loss: 0.0584 - val_accuracy: 0.9766\n",
      "Epoch 560/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9791 - val_loss: 0.0536 - val_accuracy: 0.9775\n",
      "Epoch 561/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9785 - val_loss: 0.0539 - val_accuracy: 0.9768\n",
      "Epoch 562/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9796 - val_loss: 0.0462 - val_accuracy: 0.9790\n",
      "Epoch 563/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9797 - val_loss: 0.0558 - val_accuracy: 0.9766\n",
      "Epoch 564/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9794 - val_loss: 0.0539 - val_accuracy: 0.9782\n",
      "Epoch 565/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9782 - val_loss: 0.0652 - val_accuracy: 0.9758\n",
      "Epoch 566/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.0620 - val_accuracy: 0.9758\n",
      "Epoch 567/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9794 - val_loss: 0.0558 - val_accuracy: 0.9770\n",
      "Epoch 568/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9794 - val_loss: 0.0629 - val_accuracy: 0.9750\n",
      "Epoch 569/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9795 - val_loss: 0.0541 - val_accuracy: 0.9769\n",
      "Epoch 570/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9800 - val_loss: 0.0539 - val_accuracy: 0.9771\n",
      "Epoch 571/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9785 - val_loss: 0.0620 - val_accuracy: 0.9757\n",
      "Epoch 572/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9791 - val_loss: 0.0565 - val_accuracy: 0.9765\n",
      "Epoch 573/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9798 - val_loss: 0.0502 - val_accuracy: 0.9774\n",
      "Epoch 574/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9789 - val_loss: 0.0667 - val_accuracy: 0.9747\n",
      "Epoch 575/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9794 - val_loss: 0.0608 - val_accuracy: 0.9769\n",
      "Epoch 576/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9785 - val_loss: 0.0593 - val_accuracy: 0.9773\n",
      "Epoch 577/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9788 - val_loss: 0.0611 - val_accuracy: 0.9764\n",
      "Epoch 578/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9783 - val_loss: 0.0536 - val_accuracy: 0.9761\n",
      "Epoch 579/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9795 - val_loss: 0.0563 - val_accuracy: 0.9765\n",
      "Epoch 580/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9783 - val_loss: 0.0556 - val_accuracy: 0.9767\n",
      "Epoch 581/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9803 - val_loss: 0.0628 - val_accuracy: 0.9758\n",
      "Epoch 582/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9796 - val_loss: 0.0781 - val_accuracy: 0.9736\n",
      "Epoch 583/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9787 - val_loss: 0.0702 - val_accuracy: 0.9740\n",
      "Epoch 584/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 0.0592 - val_accuracy: 0.9763\n",
      "Epoch 585/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9791 - val_loss: 0.0502 - val_accuracy: 0.9786\n",
      "Epoch 586/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9799 - val_loss: 0.0529 - val_accuracy: 0.9768\n",
      "Epoch 587/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9796 - val_loss: 0.0665 - val_accuracy: 0.9757\n",
      "Epoch 588/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9792 - val_loss: 0.0576 - val_accuracy: 0.9769\n",
      "Epoch 589/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9796 - val_loss: 0.0497 - val_accuracy: 0.9773\n",
      "Epoch 590/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9796 - val_loss: 0.0537 - val_accuracy: 0.9776\n",
      "Epoch 591/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9790 - val_loss: 0.0518 - val_accuracy: 0.9774\n",
      "Epoch 592/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9790 - val_loss: 0.0496 - val_accuracy: 0.9781\n",
      "Epoch 593/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9802 - val_loss: 0.0591 - val_accuracy: 0.9768\n",
      "Epoch 594/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9790 - val_loss: 0.0621 - val_accuracy: 0.9763\n",
      "Epoch 595/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9799 - val_loss: 0.0544 - val_accuracy: 0.9776\n",
      "Epoch 596/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9800 - val_loss: 0.0611 - val_accuracy: 0.9763\n",
      "Epoch 597/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9795 - val_loss: 0.0610 - val_accuracy: 0.9764\n",
      "Epoch 598/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.9796 - val_loss: 0.0513 - val_accuracy: 0.9765\n",
      "Epoch 599/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9795 - val_loss: 0.0512 - val_accuracy: 0.9782\n",
      "Epoch 600/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9795 - val_loss: 0.0645 - val_accuracy: 0.9761\n",
      "Epoch 601/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9802 - val_loss: 0.0604 - val_accuracy: 0.9764\n",
      "Epoch 602/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9795 - val_loss: 0.0509 - val_accuracy: 0.9776\n",
      "Epoch 603/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9808 - val_loss: 0.0609 - val_accuracy: 0.9763\n",
      "Epoch 604/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.0623 - val_accuracy: 0.9754\n",
      "Epoch 605/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9800 - val_loss: 0.0548 - val_accuracy: 0.9774\n",
      "Epoch 606/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9799 - val_loss: 0.0518 - val_accuracy: 0.9785\n",
      "Epoch 607/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9796 - val_loss: 0.0549 - val_accuracy: 0.9771\n",
      "Epoch 608/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9794 - val_loss: 0.0579 - val_accuracy: 0.9777\n",
      "Epoch 609/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9796 - val_loss: 0.0562 - val_accuracy: 0.9781\n",
      "Epoch 610/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9794 - val_loss: 0.0563 - val_accuracy: 0.9773\n",
      "Epoch 611/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9796 - val_loss: 0.0498 - val_accuracy: 0.9779\n",
      "Epoch 612/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9794 - val_loss: 0.0521 - val_accuracy: 0.9778\n",
      "Epoch 613/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9801 - val_loss: 0.0571 - val_accuracy: 0.9777\n",
      "Epoch 614/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9789 - val_loss: 0.0542 - val_accuracy: 0.9768\n",
      "Epoch 615/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9804 - val_loss: 0.0506 - val_accuracy: 0.9777\n",
      "Epoch 616/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9795 - val_loss: 0.0533 - val_accuracy: 0.9776\n",
      "Epoch 617/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9805 - val_loss: 0.0630 - val_accuracy: 0.9758\n",
      "Epoch 618/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9802 - val_loss: 0.0592 - val_accuracy: 0.9770\n",
      "Epoch 619/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9804 - val_loss: 0.0623 - val_accuracy: 0.9758\n",
      "Epoch 620/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9796 - val_loss: 0.0568 - val_accuracy: 0.9775\n",
      "Epoch 621/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9800 - val_loss: 0.0490 - val_accuracy: 0.9769\n",
      "Epoch 622/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9797 - val_loss: 0.0625 - val_accuracy: 0.9759\n",
      "Epoch 623/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9791 - val_loss: 0.0618 - val_accuracy: 0.9756\n",
      "Epoch 624/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9802 - val_loss: 0.0588 - val_accuracy: 0.9777\n",
      "Epoch 625/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9796 - val_loss: 0.0611 - val_accuracy: 0.9757\n",
      "Epoch 626/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9809 - val_loss: 0.0611 - val_accuracy: 0.9768\n",
      "Epoch 627/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9803 - val_loss: 0.0565 - val_accuracy: 0.9773\n",
      "Epoch 628/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9792 - val_loss: 0.0584 - val_accuracy: 0.9769\n",
      "Epoch 629/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9803 - val_loss: 0.0560 - val_accuracy: 0.9767\n",
      "Epoch 630/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9788 - val_loss: 0.0561 - val_accuracy: 0.9755\n",
      "Epoch 631/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9793 - val_loss: 0.0689 - val_accuracy: 0.9753\n",
      "Epoch 632/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9800 - val_loss: 0.0538 - val_accuracy: 0.9778\n",
      "Epoch 633/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9793 - val_loss: 0.0555 - val_accuracy: 0.9771\n",
      "Epoch 634/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9798 - val_loss: 0.0616 - val_accuracy: 0.9755\n",
      "Epoch 635/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9797 - val_loss: 0.0643 - val_accuracy: 0.9757\n",
      "Epoch 636/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9807 - val_loss: 0.0572 - val_accuracy: 0.9776\n",
      "Epoch 637/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9798 - val_loss: 0.0587 - val_accuracy: 0.9776\n",
      "Epoch 638/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9793 - val_loss: 0.0548 - val_accuracy: 0.9777\n",
      "Epoch 639/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9802 - val_loss: 0.0612 - val_accuracy: 0.9764\n",
      "Epoch 640/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9788 - val_loss: 0.0613 - val_accuracy: 0.9758\n",
      "Epoch 641/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9808 - val_loss: 0.0512 - val_accuracy: 0.9780\n",
      "Epoch 642/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9799 - val_loss: 0.0530 - val_accuracy: 0.9778\n",
      "Epoch 643/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9799 - val_loss: 0.0492 - val_accuracy: 0.9771\n",
      "Epoch 644/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9803 - val_loss: 0.0639 - val_accuracy: 0.9757\n",
      "Epoch 645/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9795 - val_loss: 0.0568 - val_accuracy: 0.9776\n",
      "Epoch 646/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.0508 - val_accuracy: 0.9758\n",
      "Epoch 647/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9795 - val_loss: 0.0568 - val_accuracy: 0.9770\n",
      "Epoch 648/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9802 - val_loss: 0.0593 - val_accuracy: 0.9768\n",
      "Epoch 649/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9807 - val_loss: 0.0627 - val_accuracy: 0.9760\n",
      "Epoch 650/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 0.0666 - val_accuracy: 0.9753\n",
      "Epoch 651/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9790 - val_loss: 0.0531 - val_accuracy: 0.9779\n",
      "Epoch 652/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9799 - val_loss: 0.0559 - val_accuracy: 0.9773\n",
      "Epoch 653/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9809 - val_loss: 0.0566 - val_accuracy: 0.9777\n",
      "Epoch 654/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0540 - accuracy: 0.9805 - val_loss: 0.0688 - val_accuracy: 0.9748\n",
      "Epoch 655/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9802 - val_loss: 0.0559 - val_accuracy: 0.9768\n",
      "Epoch 656/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9806 - val_loss: 0.0529 - val_accuracy: 0.9775\n",
      "Epoch 657/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9803 - val_loss: 0.0607 - val_accuracy: 0.9765\n",
      "Epoch 658/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9811 - val_loss: 0.0638 - val_accuracy: 0.9751\n",
      "Epoch 659/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9806 - val_loss: 0.0520 - val_accuracy: 0.9781\n",
      "Epoch 660/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9799 - val_loss: 0.0538 - val_accuracy: 0.9774\n",
      "Epoch 661/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9796 - val_loss: 0.0616 - val_accuracy: 0.9763\n",
      "Epoch 662/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9805 - val_loss: 0.0681 - val_accuracy: 0.9756\n",
      "Epoch 663/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9799 - val_loss: 0.0626 - val_accuracy: 0.9754\n",
      "Epoch 664/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9803 - val_loss: 0.0653 - val_accuracy: 0.9761\n",
      "Epoch 665/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9819 - val_loss: 0.0612 - val_accuracy: 0.9760\n",
      "Epoch 666/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9802 - val_loss: 0.0553 - val_accuracy: 0.9771\n",
      "Epoch 667/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9800 - val_loss: 0.0542 - val_accuracy: 0.9775\n",
      "Epoch 668/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9793 - val_loss: 0.0534 - val_accuracy: 0.9781\n",
      "Epoch 669/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0480 - val_accuracy: 0.9791\n",
      "Epoch 670/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9799 - val_loss: 0.0559 - val_accuracy: 0.9778\n",
      "Epoch 671/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9802 - val_loss: 0.0571 - val_accuracy: 0.9769\n",
      "Epoch 672/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9800 - val_loss: 0.0620 - val_accuracy: 0.9756\n",
      "Epoch 673/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9796 - val_loss: 0.0506 - val_accuracy: 0.9791\n",
      "Epoch 674/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9807 - val_loss: 0.0519 - val_accuracy: 0.9785\n",
      "Epoch 675/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9804 - val_loss: 0.0560 - val_accuracy: 0.9769\n",
      "Epoch 676/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9800 - val_loss: 0.0528 - val_accuracy: 0.9770\n",
      "Epoch 677/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9799 - val_loss: 0.0545 - val_accuracy: 0.9775\n",
      "Epoch 678/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.0549 - val_accuracy: 0.9768\n",
      "Epoch 679/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9806 - val_loss: 0.0632 - val_accuracy: 0.9758\n",
      "Epoch 680/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9803 - val_loss: 0.0653 - val_accuracy: 0.9751\n",
      "Epoch 681/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9795 - val_loss: 0.0502 - val_accuracy: 0.9773\n",
      "Epoch 682/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9804 - val_loss: 0.0611 - val_accuracy: 0.9767\n",
      "Epoch 683/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9788 - val_loss: 0.0550 - val_accuracy: 0.9767\n",
      "Epoch 684/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9807 - val_loss: 0.0573 - val_accuracy: 0.9767\n",
      "Epoch 685/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9803 - val_loss: 0.0544 - val_accuracy: 0.9779\n",
      "Epoch 686/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 0.0574 - val_accuracy: 0.9769\n",
      "Epoch 687/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0544 - val_accuracy: 0.9780\n",
      "Epoch 688/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9803 - val_loss: 0.0574 - val_accuracy: 0.9765\n",
      "Epoch 689/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9808 - val_loss: 0.0573 - val_accuracy: 0.9769\n",
      "Epoch 690/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9797 - val_loss: 0.0612 - val_accuracy: 0.9763\n",
      "Epoch 691/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9809 - val_loss: 0.0527 - val_accuracy: 0.9767\n",
      "Epoch 692/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 0.0541 - val_accuracy: 0.9784\n",
      "Epoch 693/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9803 - val_loss: 0.0504 - val_accuracy: 0.9786\n",
      "Epoch 694/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9798 - val_loss: 0.0695 - val_accuracy: 0.9753\n",
      "Epoch 695/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9806 - val_loss: 0.0707 - val_accuracy: 0.9746\n",
      "Epoch 696/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9805 - val_loss: 0.0624 - val_accuracy: 0.9759\n",
      "Epoch 697/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9803 - val_loss: 0.0577 - val_accuracy: 0.9778\n",
      "Epoch 698/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9798 - val_loss: 0.0629 - val_accuracy: 0.9765\n",
      "Epoch 699/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0517 - accuracy: 0.9815 - val_loss: 0.0716 - val_accuracy: 0.9751\n",
      "Epoch 700/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9800 - val_loss: 0.0678 - val_accuracy: 0.9757\n",
      "Epoch 701/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.0560 - val_accuracy: 0.9774\n",
      "Epoch 702/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9812 - val_loss: 0.0587 - val_accuracy: 0.9763\n",
      "Epoch 703/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9803 - val_loss: 0.0492 - val_accuracy: 0.9780\n",
      "Epoch 704/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.0583 - val_accuracy: 0.9777\n",
      "Epoch 705/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9812 - val_loss: 0.0549 - val_accuracy: 0.9775\n",
      "Epoch 706/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9804 - val_loss: 0.0556 - val_accuracy: 0.9775\n",
      "Epoch 707/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9799 - val_loss: 0.0578 - val_accuracy: 0.9771\n",
      "Epoch 708/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9815 - val_loss: 0.0663 - val_accuracy: 0.9753\n",
      "Epoch 709/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9795 - val_loss: 0.0563 - val_accuracy: 0.9780\n",
      "Epoch 710/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9811 - val_loss: 0.0577 - val_accuracy: 0.9775\n",
      "Epoch 711/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9813 - val_loss: 0.0733 - val_accuracy: 0.9751\n",
      "Epoch 712/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9789 - val_loss: 0.0518 - val_accuracy: 0.9782\n",
      "Epoch 713/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.0568 - val_accuracy: 0.9765\n",
      "Epoch 714/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9805 - val_loss: 0.0609 - val_accuracy: 0.9771\n",
      "Epoch 715/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9801 - val_loss: 0.0557 - val_accuracy: 0.9786\n",
      "Epoch 716/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9808 - val_loss: 0.0531 - val_accuracy: 0.9782\n",
      "Epoch 717/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9818 - val_loss: 0.0481 - val_accuracy: 0.9773\n",
      "Epoch 718/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9799 - val_loss: 0.0537 - val_accuracy: 0.9775\n",
      "Epoch 719/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9808 - val_loss: 0.0512 - val_accuracy: 0.9775\n",
      "Epoch 720/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9805 - val_loss: 0.0624 - val_accuracy: 0.9770\n",
      "Epoch 721/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9802 - val_loss: 0.0651 - val_accuracy: 0.9764\n",
      "Epoch 722/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9811 - val_loss: 0.0520 - val_accuracy: 0.9768\n",
      "Epoch 723/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9806 - val_loss: 0.0624 - val_accuracy: 0.9766\n",
      "Epoch 724/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9796 - val_loss: 0.0550 - val_accuracy: 0.9773\n",
      "Epoch 725/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9800 - val_loss: 0.0572 - val_accuracy: 0.9777\n",
      "Epoch 726/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.0693 - val_accuracy: 0.9750\n",
      "Epoch 727/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9806 - val_loss: 0.0525 - val_accuracy: 0.9774\n",
      "Epoch 728/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9805 - val_loss: 0.0614 - val_accuracy: 0.9763\n",
      "Epoch 729/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9819 - val_loss: 0.0495 - val_accuracy: 0.9781\n",
      "Epoch 730/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9822 - val_loss: 0.0557 - val_accuracy: 0.9776\n",
      "Epoch 731/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9809 - val_loss: 0.0535 - val_accuracy: 0.9779\n",
      "Epoch 732/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9806 - val_loss: 0.0625 - val_accuracy: 0.9764\n",
      "Epoch 733/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9804 - val_loss: 0.0570 - val_accuracy: 0.9777\n",
      "Epoch 734/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9806 - val_loss: 0.0686 - val_accuracy: 0.9755\n",
      "Epoch 735/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0532 - val_accuracy: 0.9784\n",
      "Epoch 736/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9813 - val_loss: 0.0542 - val_accuracy: 0.9770\n",
      "Epoch 737/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9811 - val_loss: 0.0665 - val_accuracy: 0.9755\n",
      "Epoch 738/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9809 - val_loss: 0.0555 - val_accuracy: 0.9776\n",
      "Epoch 739/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9805 - val_loss: 0.0548 - val_accuracy: 0.9771\n",
      "Epoch 740/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.0551 - val_accuracy: 0.9779\n",
      "Epoch 741/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9811 - val_loss: 0.0574 - val_accuracy: 0.9766\n",
      "Epoch 742/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9809 - val_loss: 0.0518 - val_accuracy: 0.9787\n",
      "Epoch 743/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9818 - val_loss: 0.0692 - val_accuracy: 0.9753\n",
      "Epoch 744/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9812 - val_loss: 0.0637 - val_accuracy: 0.9761\n",
      "Epoch 745/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9808 - val_loss: 0.0526 - val_accuracy: 0.9782\n",
      "Epoch 746/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9813 - val_loss: 0.0601 - val_accuracy: 0.9770\n",
      "Epoch 747/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9809 - val_loss: 0.0564 - val_accuracy: 0.9784\n",
      "Epoch 748/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9807 - val_loss: 0.0552 - val_accuracy: 0.9773\n",
      "Epoch 749/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9811 - val_loss: 0.0566 - val_accuracy: 0.9779\n",
      "Epoch 750/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9815 - val_loss: 0.0584 - val_accuracy: 0.9776\n",
      "Epoch 751/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9807 - val_loss: 0.0539 - val_accuracy: 0.9779\n",
      "Epoch 752/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9814 - val_loss: 0.0753 - val_accuracy: 0.9747\n",
      "Epoch 753/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9803 - val_loss: 0.0589 - val_accuracy: 0.9773\n",
      "Epoch 754/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9802 - val_loss: 0.0650 - val_accuracy: 0.9758\n",
      "Epoch 755/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.0549 - val_accuracy: 0.9773\n",
      "Epoch 756/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9804 - val_loss: 0.0532 - val_accuracy: 0.9778\n",
      "Epoch 757/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9819 - val_loss: 0.0632 - val_accuracy: 0.9770\n",
      "Epoch 758/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9825 - val_loss: 0.0514 - val_accuracy: 0.9779\n",
      "Epoch 759/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9816 - val_loss: 0.0514 - val_accuracy: 0.9785\n",
      "Epoch 760/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9811 - val_loss: 0.0607 - val_accuracy: 0.9766\n",
      "Epoch 761/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9801 - val_loss: 0.0537 - val_accuracy: 0.9774\n",
      "Epoch 762/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9809 - val_loss: 0.0535 - val_accuracy: 0.9777\n",
      "Epoch 763/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9811 - val_loss: 0.0519 - val_accuracy: 0.9763\n",
      "Epoch 764/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9808 - val_loss: 0.0548 - val_accuracy: 0.9771\n",
      "Epoch 765/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.0581 - val_accuracy: 0.9769\n",
      "Epoch 766/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9814 - val_loss: 0.0596 - val_accuracy: 0.9769\n",
      "Epoch 767/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9812 - val_loss: 0.0524 - val_accuracy: 0.9779\n",
      "Epoch 768/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9819 - val_loss: 0.0590 - val_accuracy: 0.9773\n",
      "Epoch 769/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9811 - val_loss: 0.0511 - val_accuracy: 0.9782\n",
      "Epoch 770/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9805 - val_loss: 0.0547 - val_accuracy: 0.9768\n",
      "Epoch 771/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9819 - val_loss: 0.0538 - val_accuracy: 0.9779\n",
      "Epoch 772/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9807 - val_loss: 0.0551 - val_accuracy: 0.9775\n",
      "Epoch 773/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9808 - val_loss: 0.0623 - val_accuracy: 0.9769\n",
      "Epoch 774/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 0.0495 - val_accuracy: 0.9778\n",
      "Epoch 775/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9816 - val_loss: 0.0576 - val_accuracy: 0.9778\n",
      "Epoch 776/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9813 - val_loss: 0.0592 - val_accuracy: 0.9775\n",
      "Epoch 777/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9818 - val_loss: 0.0567 - val_accuracy: 0.9771\n",
      "Epoch 778/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9824 - val_loss: 0.0614 - val_accuracy: 0.9760\n",
      "Epoch 779/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9802 - val_loss: 0.0581 - val_accuracy: 0.9771\n",
      "Epoch 780/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9811 - val_loss: 0.0550 - val_accuracy: 0.9768\n",
      "Epoch 781/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.0494 - val_accuracy: 0.9782\n",
      "Epoch 782/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9810 - val_loss: 0.0546 - val_accuracy: 0.9777\n",
      "Epoch 783/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9824 - val_loss: 0.0561 - val_accuracy: 0.9765\n",
      "Epoch 784/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9811 - val_loss: 0.0594 - val_accuracy: 0.9768\n",
      "Epoch 785/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9816 - val_loss: 0.0671 - val_accuracy: 0.9751\n",
      "Epoch 786/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9816 - val_loss: 0.0564 - val_accuracy: 0.9769\n",
      "Epoch 787/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9820 - val_loss: 0.0516 - val_accuracy: 0.9781\n",
      "Epoch 788/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9818 - val_loss: 0.0545 - val_accuracy: 0.9781\n",
      "Epoch 789/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9815 - val_loss: 0.0526 - val_accuracy: 0.9776\n",
      "Epoch 790/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 0.0595 - val_accuracy: 0.9765\n",
      "Epoch 791/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9807 - val_loss: 0.0555 - val_accuracy: 0.9777\n",
      "Epoch 792/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9816 - val_loss: 0.0624 - val_accuracy: 0.9770\n",
      "Epoch 793/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9812 - val_loss: 0.0588 - val_accuracy: 0.9777\n",
      "Epoch 794/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9818 - val_loss: 0.0559 - val_accuracy: 0.9763\n",
      "Epoch 795/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9813 - val_loss: 0.0554 - val_accuracy: 0.9770\n",
      "Epoch 796/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9819 - val_loss: 0.0678 - val_accuracy: 0.9748\n",
      "Epoch 797/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9813 - val_loss: 0.0563 - val_accuracy: 0.9773\n",
      "Epoch 798/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9813 - val_loss: 0.0618 - val_accuracy: 0.9767\n",
      "Epoch 799/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9827 - val_loss: 0.0645 - val_accuracy: 0.9768\n",
      "Epoch 800/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9815 - val_loss: 0.0541 - val_accuracy: 0.9764\n",
      "Epoch 801/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9814 - val_loss: 0.0663 - val_accuracy: 0.9765\n",
      "Epoch 802/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9819 - val_loss: 0.0538 - val_accuracy: 0.9784\n",
      "Epoch 803/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 0.0634 - val_accuracy: 0.9768\n",
      "Epoch 804/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9815 - val_loss: 0.0592 - val_accuracy: 0.9770\n",
      "Epoch 805/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9817 - val_loss: 0.0588 - val_accuracy: 0.9771\n",
      "Epoch 806/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9822 - val_loss: 0.0535 - val_accuracy: 0.9776\n",
      "Epoch 807/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9817 - val_loss: 0.0555 - val_accuracy: 0.9780\n",
      "Epoch 808/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9814 - val_loss: 0.0532 - val_accuracy: 0.9768\n",
      "Epoch 809/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9816 - val_loss: 0.0557 - val_accuracy: 0.9776\n",
      "Epoch 810/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9813 - val_loss: 0.0593 - val_accuracy: 0.9768\n",
      "Epoch 811/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9825 - val_loss: 0.0561 - val_accuracy: 0.9776\n",
      "Epoch 812/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9801 - val_loss: 0.0549 - val_accuracy: 0.9764\n",
      "Epoch 813/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9812 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
      "Epoch 814/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9816 - val_loss: 0.0516 - val_accuracy: 0.9780\n",
      "Epoch 815/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9813 - val_loss: 0.0633 - val_accuracy: 0.9766\n",
      "Epoch 816/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9810 - val_loss: 0.0610 - val_accuracy: 0.9768\n",
      "Epoch 817/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9811 - val_loss: 0.0553 - val_accuracy: 0.9776\n",
      "Epoch 818/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9825 - val_loss: 0.0525 - val_accuracy: 0.9778\n",
      "Epoch 819/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9817 - val_loss: 0.0552 - val_accuracy: 0.9781\n",
      "Epoch 820/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9828 - val_loss: 0.0544 - val_accuracy: 0.9763\n",
      "Epoch 821/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9817 - val_loss: 0.0695 - val_accuracy: 0.9760\n",
      "Epoch 822/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9815 - val_loss: 0.0660 - val_accuracy: 0.9765\n",
      "Epoch 823/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.0558 - val_accuracy: 0.9769\n",
      "Epoch 824/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9824 - val_loss: 0.0561 - val_accuracy: 0.9768\n",
      "Epoch 825/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9813 - val_loss: 0.0589 - val_accuracy: 0.9777\n",
      "Epoch 826/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9810 - val_loss: 0.0553 - val_accuracy: 0.9773\n",
      "Epoch 827/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9817 - val_loss: 0.0589 - val_accuracy: 0.9776\n",
      "Epoch 828/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9807 - val_loss: 0.0587 - val_accuracy: 0.9782\n",
      "Epoch 829/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 0.0522 - val_accuracy: 0.9788\n",
      "Epoch 830/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9827 - val_loss: 0.0546 - val_accuracy: 0.9774\n",
      "Epoch 831/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9813 - val_loss: 0.0603 - val_accuracy: 0.9765\n",
      "Epoch 832/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9834 - val_loss: 0.0559 - val_accuracy: 0.9778\n",
      "Epoch 833/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9816 - val_loss: 0.0545 - val_accuracy: 0.9781\n",
      "Epoch 834/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9807 - val_loss: 0.0607 - val_accuracy: 0.9764\n",
      "Epoch 835/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9819 - val_loss: 0.0654 - val_accuracy: 0.9768\n",
      "Epoch 836/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9820 - val_loss: 0.0600 - val_accuracy: 0.9774\n",
      "Epoch 837/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9821 - val_loss: 0.0517 - val_accuracy: 0.9790\n",
      "Epoch 838/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9814 - val_loss: 0.0554 - val_accuracy: 0.9777\n",
      "Epoch 839/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9809 - val_loss: 0.0546 - val_accuracy: 0.9778\n",
      "Epoch 840/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9821 - val_loss: 0.0613 - val_accuracy: 0.9773\n",
      "Epoch 841/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9827 - val_loss: 0.0510 - val_accuracy: 0.9778\n",
      "Epoch 842/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9814 - val_loss: 0.0536 - val_accuracy: 0.9777\n",
      "Epoch 843/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9811 - val_loss: 0.0620 - val_accuracy: 0.9765\n",
      "Epoch 844/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9814 - val_loss: 0.0622 - val_accuracy: 0.9771\n",
      "Epoch 845/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9812 - val_loss: 0.0494 - val_accuracy: 0.9780\n",
      "Epoch 846/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.0625 - val_accuracy: 0.9764\n",
      "Epoch 847/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9811 - val_loss: 0.0593 - val_accuracy: 0.9771\n",
      "Epoch 848/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9812 - val_loss: 0.0543 - val_accuracy: 0.9774\n",
      "Epoch 849/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9812 - val_loss: 0.0570 - val_accuracy: 0.9778\n",
      "Epoch 850/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9811 - val_loss: 0.0608 - val_accuracy: 0.9767\n",
      "Epoch 851/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9821 - val_loss: 0.0505 - val_accuracy: 0.9777\n",
      "Epoch 852/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9815 - val_loss: 0.0590 - val_accuracy: 0.9779\n",
      "Epoch 853/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9826 - val_loss: 0.0543 - val_accuracy: 0.9779\n",
      "Epoch 854/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9823 - val_loss: 0.0507 - val_accuracy: 0.9785\n",
      "Epoch 855/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 0.0534 - val_accuracy: 0.9766\n",
      "Epoch 856/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0508 - accuracy: 0.9809 - val_loss: 0.0590 - val_accuracy: 0.9759\n",
      "Epoch 857/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9813 - val_loss: 0.0548 - val_accuracy: 0.9781\n",
      "Epoch 858/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.0527 - val_accuracy: 0.9761\n",
      "Epoch 859/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9814 - val_loss: 0.0570 - val_accuracy: 0.9776\n",
      "Epoch 860/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9816 - val_loss: 0.0544 - val_accuracy: 0.9777\n",
      "Epoch 861/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9817 - val_loss: 0.0631 - val_accuracy: 0.9766\n",
      "Epoch 862/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.9821 - val_loss: 0.0581 - val_accuracy: 0.9785\n",
      "Epoch 863/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 0.0611 - val_accuracy: 0.9768\n",
      "Epoch 864/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0474 - accuracy: 0.9829 - val_loss: 0.0567 - val_accuracy: 0.9771\n",
      "Epoch 865/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9818 - val_loss: 0.0530 - val_accuracy: 0.9788\n",
      "Epoch 866/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9821 - val_loss: 0.0683 - val_accuracy: 0.9761\n",
      "Epoch 867/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0511 - accuracy: 0.9815 - val_loss: 0.0527 - val_accuracy: 0.9777\n",
      "Epoch 868/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0491 - accuracy: 0.9820 - val_loss: 0.0517 - val_accuracy: 0.9777\n",
      "Epoch 869/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9822 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
      "Epoch 870/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9810 - val_loss: 0.0616 - val_accuracy: 0.9776\n",
      "Epoch 871/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9808 - val_loss: 0.0664 - val_accuracy: 0.9751\n",
      "Epoch 872/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0491 - accuracy: 0.9824 - val_loss: 0.0557 - val_accuracy: 0.9776\n",
      "Epoch 873/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9822 - val_loss: 0.0606 - val_accuracy: 0.9773\n",
      "Epoch 874/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9816 - val_loss: 0.0537 - val_accuracy: 0.9778\n",
      "Epoch 875/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0493 - accuracy: 0.9817 - val_loss: 0.0602 - val_accuracy: 0.9768\n",
      "Epoch 876/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9814 - val_loss: 0.0602 - val_accuracy: 0.9775\n",
      "Epoch 877/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9811 - val_loss: 0.0578 - val_accuracy: 0.9777\n",
      "Epoch 878/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9819 - val_loss: 0.0531 - val_accuracy: 0.9782\n",
      "Epoch 879/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9810 - val_loss: 0.0626 - val_accuracy: 0.9767\n",
      "Epoch 880/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.9824 - val_loss: 0.0579 - val_accuracy: 0.9787\n",
      "Epoch 881/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9819 - val_loss: 0.0580 - val_accuracy: 0.9778\n",
      "Epoch 882/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9817 - val_loss: 0.0583 - val_accuracy: 0.9774\n",
      "Epoch 883/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9816 - val_loss: 0.0653 - val_accuracy: 0.9763\n",
      "Epoch 884/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9807 - val_loss: 0.0497 - val_accuracy: 0.9784\n",
      "Epoch 885/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9815 - val_loss: 0.0522 - val_accuracy: 0.9775\n",
      "Epoch 886/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.0595 - val_accuracy: 0.9769\n",
      "Epoch 887/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9821 - val_loss: 0.0625 - val_accuracy: 0.9768\n",
      "Epoch 888/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9812 - val_loss: 0.0542 - val_accuracy: 0.9774\n",
      "Epoch 889/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9824 - val_loss: 0.0630 - val_accuracy: 0.9764\n",
      "Epoch 890/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9812 - val_loss: 0.0541 - val_accuracy: 0.9786\n",
      "Epoch 891/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9823 - val_loss: 0.0542 - val_accuracy: 0.9786\n",
      "Epoch 892/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9816 - val_loss: 0.0539 - val_accuracy: 0.9777\n",
      "Epoch 893/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.0527 - val_accuracy: 0.9773\n",
      "Epoch 894/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9823 - val_loss: 0.0530 - val_accuracy: 0.9776\n",
      "Epoch 895/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9814 - val_loss: 0.0597 - val_accuracy: 0.9768\n",
      "Epoch 896/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 0.0589 - val_accuracy: 0.9770\n",
      "Epoch 897/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9816 - val_loss: 0.0629 - val_accuracy: 0.9770\n",
      "Epoch 898/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9824 - val_loss: 0.0574 - val_accuracy: 0.9784\n",
      "Epoch 899/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9826 - val_loss: 0.0690 - val_accuracy: 0.9749\n",
      "Epoch 900/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9819 - val_loss: 0.0569 - val_accuracy: 0.9776\n",
      "Epoch 901/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.9826 - val_loss: 0.0660 - val_accuracy: 0.9767\n",
      "Epoch 902/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9814 - val_loss: 0.0618 - val_accuracy: 0.9767\n",
      "Epoch 903/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9813 - val_loss: 0.0568 - val_accuracy: 0.9778\n",
      "Epoch 904/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9818 - val_loss: 0.0558 - val_accuracy: 0.9778\n",
      "Epoch 905/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 0.0562 - val_accuracy: 0.9778\n",
      "Epoch 906/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9822 - val_loss: 0.0634 - val_accuracy: 0.9769\n",
      "Epoch 907/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9821 - val_loss: 0.0696 - val_accuracy: 0.9766\n",
      "Epoch 908/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9826 - val_loss: 0.0596 - val_accuracy: 0.9776\n",
      "Epoch 909/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9818 - val_loss: 0.0530 - val_accuracy: 0.9788\n",
      "Epoch 910/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9826 - val_loss: 0.0607 - val_accuracy: 0.9760\n",
      "Epoch 911/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9815 - val_loss: 0.0562 - val_accuracy: 0.9775\n",
      "Epoch 912/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9821 - val_loss: 0.0522 - val_accuracy: 0.9780\n",
      "Epoch 913/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9815 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
      "Epoch 914/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9825 - val_loss: 0.0557 - val_accuracy: 0.9770\n",
      "Epoch 915/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9818 - val_loss: 0.0543 - val_accuracy: 0.9785\n",
      "Epoch 916/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9824 - val_loss: 0.0570 - val_accuracy: 0.9786\n",
      "Epoch 917/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9828 - val_loss: 0.0536 - val_accuracy: 0.9771\n",
      "Epoch 918/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9818 - val_loss: 0.0546 - val_accuracy: 0.9769\n",
      "Epoch 919/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9815 - val_loss: 0.0580 - val_accuracy: 0.9779\n",
      "Epoch 920/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9822 - val_loss: 0.0571 - val_accuracy: 0.9773\n",
      "Epoch 921/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9825 - val_loss: 0.0560 - val_accuracy: 0.9781\n",
      "Epoch 922/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9822 - val_loss: 0.0603 - val_accuracy: 0.9767\n",
      "Epoch 923/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9825 - val_loss: 0.0556 - val_accuracy: 0.9779\n",
      "Epoch 924/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9811 - val_loss: 0.0584 - val_accuracy: 0.9775\n",
      "Epoch 925/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9826 - val_loss: 0.0620 - val_accuracy: 0.9770\n",
      "Epoch 926/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9823 - val_loss: 0.0556 - val_accuracy: 0.9774\n",
      "Epoch 927/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9816 - val_loss: 0.0583 - val_accuracy: 0.9771\n",
      "Epoch 928/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9824 - val_loss: 0.0550 - val_accuracy: 0.9767\n",
      "Epoch 929/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9825 - val_loss: 0.0558 - val_accuracy: 0.9777\n",
      "Epoch 930/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9828 - val_loss: 0.0610 - val_accuracy: 0.9767\n",
      "Epoch 931/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9822 - val_loss: 0.0601 - val_accuracy: 0.9756\n",
      "Epoch 932/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9824 - val_loss: 0.0523 - val_accuracy: 0.9781\n",
      "Epoch 933/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9816 - val_loss: 0.0591 - val_accuracy: 0.9770\n",
      "Epoch 934/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9827 - val_loss: 0.0632 - val_accuracy: 0.9759\n",
      "Epoch 935/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.0582 - val_accuracy: 0.9776\n",
      "Epoch 936/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9820 - val_loss: 0.0496 - val_accuracy: 0.9784\n",
      "Epoch 937/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9810 - val_loss: 0.0576 - val_accuracy: 0.9769\n",
      "Epoch 938/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9821 - val_loss: 0.0566 - val_accuracy: 0.9778\n",
      "Epoch 939/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9825 - val_loss: 0.0530 - val_accuracy: 0.9779\n",
      "Epoch 940/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9828 - val_loss: 0.0656 - val_accuracy: 0.9759\n",
      "Epoch 941/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9816 - val_loss: 0.0687 - val_accuracy: 0.9760\n",
      "Epoch 942/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9822 - val_loss: 0.0670 - val_accuracy: 0.9756\n",
      "Epoch 943/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9822 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
      "Epoch 944/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9817 - val_loss: 0.0506 - val_accuracy: 0.9778\n",
      "Epoch 945/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9811 - val_loss: 0.0645 - val_accuracy: 0.9753\n",
      "Epoch 946/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9822 - val_loss: 0.0565 - val_accuracy: 0.9775\n",
      "Epoch 947/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9825 - val_loss: 0.0543 - val_accuracy: 0.9777\n",
      "Epoch 948/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9823 - val_loss: 0.0512 - val_accuracy: 0.9776\n",
      "Epoch 949/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9828 - val_loss: 0.0595 - val_accuracy: 0.9778\n",
      "Epoch 950/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9808 - val_loss: 0.0586 - val_accuracy: 0.9780\n",
      "Epoch 951/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9821 - val_loss: 0.0583 - val_accuracy: 0.9771\n",
      "Epoch 952/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9818 - val_loss: 0.0562 - val_accuracy: 0.9767\n",
      "Epoch 953/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9832 - val_loss: 0.0569 - val_accuracy: 0.9773\n",
      "Epoch 954/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9825 - val_loss: 0.0624 - val_accuracy: 0.9773\n",
      "Epoch 955/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9828 - val_loss: 0.0529 - val_accuracy: 0.9775\n",
      "Epoch 956/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.0567 - val_accuracy: 0.9771\n",
      "Epoch 957/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9821 - val_loss: 0.0638 - val_accuracy: 0.9768\n",
      "Epoch 958/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9816 - val_loss: 0.0578 - val_accuracy: 0.9764\n",
      "Epoch 959/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9828 - val_loss: 0.0652 - val_accuracy: 0.9761\n",
      "Epoch 960/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9826 - val_loss: 0.0561 - val_accuracy: 0.9779\n",
      "Epoch 961/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9822 - val_loss: 0.0585 - val_accuracy: 0.9780\n",
      "Epoch 962/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9822 - val_loss: 0.0496 - val_accuracy: 0.9787\n",
      "Epoch 963/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0467 - accuracy: 0.9826 - val_loss: 0.0549 - val_accuracy: 0.9776\n",
      "Epoch 964/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9824 - val_loss: 0.0552 - val_accuracy: 0.9777\n",
      "Epoch 965/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9822 - val_loss: 0.0548 - val_accuracy: 0.9771\n",
      "Epoch 966/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9824 - val_loss: 0.0583 - val_accuracy: 0.9771\n",
      "Epoch 967/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9824 - val_loss: 0.0579 - val_accuracy: 0.9773\n",
      "Epoch 968/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9824 - val_loss: 0.0532 - val_accuracy: 0.9778\n",
      "Epoch 969/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9822 - val_loss: 0.0588 - val_accuracy: 0.9763\n",
      "Epoch 970/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9822 - val_loss: 0.0596 - val_accuracy: 0.9774\n",
      "Epoch 971/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9815 - val_loss: 0.0631 - val_accuracy: 0.9765\n",
      "Epoch 972/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9814 - val_loss: 0.0596 - val_accuracy: 0.9781\n",
      "Epoch 973/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9830 - val_loss: 0.0498 - val_accuracy: 0.9791\n",
      "Epoch 974/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9817 - val_loss: 0.0538 - val_accuracy: 0.9768\n",
      "Epoch 975/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9809 - val_loss: 0.0537 - val_accuracy: 0.9779\n",
      "Epoch 976/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9822 - val_loss: 0.0703 - val_accuracy: 0.9753\n",
      "Epoch 977/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9814 - val_loss: 0.0596 - val_accuracy: 0.9768\n",
      "Epoch 978/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9824 - val_loss: 0.0542 - val_accuracy: 0.9777\n",
      "Epoch 979/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9824 - val_loss: 0.0702 - val_accuracy: 0.9761\n",
      "Epoch 980/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.0563 - val_accuracy: 0.9769\n",
      "Epoch 981/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9818 - val_loss: 0.0522 - val_accuracy: 0.9788\n",
      "Epoch 982/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9824 - val_loss: 0.0551 - val_accuracy: 0.9771\n",
      "Epoch 983/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.0527 - val_accuracy: 0.9780\n",
      "Epoch 984/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9824 - val_loss: 0.0553 - val_accuracy: 0.9771\n",
      "Epoch 985/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9824 - val_loss: 0.0689 - val_accuracy: 0.9755\n",
      "Epoch 986/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9826 - val_loss: 0.0558 - val_accuracy: 0.9778\n",
      "Epoch 987/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9821 - val_loss: 0.0523 - val_accuracy: 0.9782\n",
      "Epoch 988/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9826 - val_loss: 0.0551 - val_accuracy: 0.9770\n",
      "Epoch 989/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9827 - val_loss: 0.0590 - val_accuracy: 0.9765\n",
      "Epoch 990/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9819 - val_loss: 0.0607 - val_accuracy: 0.9775\n",
      "Epoch 991/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9830 - val_loss: 0.0580 - val_accuracy: 0.9776\n",
      "Epoch 992/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9827 - val_loss: 0.0576 - val_accuracy: 0.9777\n",
      "Epoch 993/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9830 - val_loss: 0.0504 - val_accuracy: 0.9770\n",
      "Epoch 994/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 0.0569 - val_accuracy: 0.9778\n",
      "Epoch 995/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9818 - val_loss: 0.0570 - val_accuracy: 0.9765\n",
      "Epoch 996/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9825 - val_loss: 0.0535 - val_accuracy: 0.9781\n",
      "Epoch 997/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9824 - val_loss: 0.0571 - val_accuracy: 0.9775\n",
      "Epoch 998/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9821 - val_loss: 0.0596 - val_accuracy: 0.9759\n",
      "Epoch 999/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9819 - val_loss: 0.0522 - val_accuracy: 0.9775\n",
      "Epoch 1000/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9815 - val_loss: 0.0608 - val_accuracy: 0.9766\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 940us/step\n",
      "xtrain: (85868, 59), ytrain: (85868,)\n",
      "xvalid: (9011, 59), yvalid: (9011,)\n",
      "xtest: (9012, 59), ytest: (9012,)\n",
      "\n",
      "classification_report_Fold=1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Normal 0       1.00      0.98      0.99      8725\n",
      " Anomalous 1       0.59      0.87      0.71       287\n",
      "\n",
      "    accuracy                           0.98      9012\n",
      "   macro avg       0.79      0.93      0.85      9012\n",
      "weighted avg       0.98      0.98      0.98      9012\n",
      "\n",
      "confusion_matrix_Fold=1:\n",
      "\n",
      "True Negatives:  8553\n",
      "False Positives:  172\n",
      "False Negatives:  36\n",
      "True Positives:  251\n",
      "accuracy_score_Fold=1:\n",
      " 8804 \n",
      "\n",
      "End running time Fold=1: 210214_092303 ,-------------------------- \n",
      "\n",
      "Start running time Data Augmentation_Fold=2: 210214_092303 ,-------------------------- \n",
      "\n",
      "Data Augmentation MSE Label1, iter2==> mean: 1.110064921240261e-05, min: 3.897988961917731e-06, max: 0.0002312187141438627\n",
      "End running time Data Augmentation_Fold=2: 210214_094233 ,-------------------------- \n",
      "\n",
      "\n",
      " Start running time Fold=2: 210214_094233 ,-------------------------- \n",
      "\n",
      "\n",
      " Number of Final yXtrain_Fold=2 labeled 0: 69796\n",
      "Number of Final yXtrain_Fold=2 labeled 1: 16072\n",
      "Number of Final yXtrain_Fold=2 labeled 2: 0 \n",
      "\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.4919 - accuracy: 0.7971 - val_loss: 0.2338 - val_accuracy: 0.9665\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8210 - val_loss: 0.2295 - val_accuracy: 0.9627\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8232 - val_loss: 0.2419 - val_accuracy: 0.9544\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8252 - val_loss: 0.2117 - val_accuracy: 0.9558\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8273 - val_loss: 0.2176 - val_accuracy: 0.9553\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8266 - val_loss: 0.2194 - val_accuracy: 0.9534\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8293 - val_loss: 0.2060 - val_accuracy: 0.9551\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8323 - val_loss: 0.2041 - val_accuracy: 0.9523\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8335 - val_loss: 0.2275 - val_accuracy: 0.9442\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8335 - val_loss: 0.2457 - val_accuracy: 0.9444\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8345 - val_loss: 0.2024 - val_accuracy: 0.9534\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.8334 - val_loss: 0.2116 - val_accuracy: 0.9481\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8359 - val_loss: 0.2213 - val_accuracy: 0.9455\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8367 - val_loss: 0.2235 - val_accuracy: 0.9426\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8399 - val_loss: 0.2112 - val_accuracy: 0.9452\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3632 - accuracy: 0.8386 - val_loss: 0.2135 - val_accuracy: 0.9445\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3576 - accuracy: 0.8417 - val_loss: 0.1870 - val_accuracy: 0.9512\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3543 - accuracy: 0.8415 - val_loss: 0.1953 - val_accuracy: 0.9481\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3519 - accuracy: 0.8420 - val_loss: 0.1792 - val_accuracy: 0.9534\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8454 - val_loss: 0.2110 - val_accuracy: 0.9396\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3403 - accuracy: 0.8476 - val_loss: 0.1772 - val_accuracy: 0.9528\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8480 - val_loss: 0.1790 - val_accuracy: 0.9509\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8486 - val_loss: 0.1943 - val_accuracy: 0.9440\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8507 - val_loss: 0.1974 - val_accuracy: 0.9389\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8519 - val_loss: 0.2061 - val_accuracy: 0.9367\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3221 - accuracy: 0.8535 - val_loss: 0.1841 - val_accuracy: 0.9454\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.8536 - val_loss: 0.2130 - val_accuracy: 0.9296\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3113 - accuracy: 0.8580 - val_loss: 0.1900 - val_accuracy: 0.9400\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3089 - accuracy: 0.8581 - val_loss: 0.1767 - val_accuracy: 0.9464\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3044 - accuracy: 0.8606 - val_loss: 0.1942 - val_accuracy: 0.9357\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.3022 - accuracy: 0.8612 - val_loss: 0.1827 - val_accuracy: 0.9395\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2955 - accuracy: 0.8649 - val_loss: 0.1742 - val_accuracy: 0.9446\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2903 - accuracy: 0.8675 - val_loss: 0.1908 - val_accuracy: 0.9354\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2878 - accuracy: 0.8676 - val_loss: 0.1888 - val_accuracy: 0.9344\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.8713 - val_loss: 0.1597 - val_accuracy: 0.9484\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8706 - val_loss: 0.1661 - val_accuracy: 0.9454\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8743 - val_loss: 0.1519 - val_accuracy: 0.9495\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8731 - val_loss: 0.1963 - val_accuracy: 0.9241\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8764 - val_loss: 0.1729 - val_accuracy: 0.9384\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.8791 - val_loss: 0.1760 - val_accuracy: 0.9349\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.8820 - val_loss: 0.1568 - val_accuracy: 0.9475\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.8829 - val_loss: 0.1898 - val_accuracy: 0.9274\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.8831 - val_loss: 0.1547 - val_accuracy: 0.9473\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2542 - accuracy: 0.8843 - val_loss: 0.1834 - val_accuracy: 0.9286\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.8879 - val_loss: 0.1489 - val_accuracy: 0.9496\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.8881 - val_loss: 0.1578 - val_accuracy: 0.9425\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.8915 - val_loss: 0.1612 - val_accuracy: 0.9387\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2424 - accuracy: 0.8933 - val_loss: 0.1869 - val_accuracy: 0.9213\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.8965 - val_loss: 0.1395 - val_accuracy: 0.9512\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.8966 - val_loss: 0.1360 - val_accuracy: 0.9527\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9006 - val_loss: 0.1572 - val_accuracy: 0.9401\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.8999 - val_loss: 0.1580 - val_accuracy: 0.9383\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2274 - accuracy: 0.9009 - val_loss: 0.1467 - val_accuracy: 0.9440\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2262 - accuracy: 0.9025 - val_loss: 0.1548 - val_accuracy: 0.9416\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2233 - accuracy: 0.9057 - val_loss: 0.1730 - val_accuracy: 0.9260\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9054 - val_loss: 0.1345 - val_accuracy: 0.9504\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.9058 - val_loss: 0.1322 - val_accuracy: 0.9516\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9103 - val_loss: 0.1380 - val_accuracy: 0.9466\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2160 - accuracy: 0.9069 - val_loss: 0.1329 - val_accuracy: 0.9509\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9133 - val_loss: 0.1369 - val_accuracy: 0.9484\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9116 - val_loss: 0.1498 - val_accuracy: 0.9387\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9146 - val_loss: 0.1402 - val_accuracy: 0.9444\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9120 - val_loss: 0.1360 - val_accuracy: 0.9450\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9134 - val_loss: 0.1579 - val_accuracy: 0.9329\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1994 - accuracy: 0.9159 - val_loss: 0.1260 - val_accuracy: 0.9516\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.9170 - val_loss: 0.1278 - val_accuracy: 0.9498\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.9165 - val_loss: 0.1229 - val_accuracy: 0.9497\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1940 - accuracy: 0.9173 - val_loss: 0.1562 - val_accuracy: 0.9350\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9171 - val_loss: 0.1382 - val_accuracy: 0.9436\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9197 - val_loss: 0.1389 - val_accuracy: 0.9418\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1887 - accuracy: 0.9201 - val_loss: 0.1249 - val_accuracy: 0.9487\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9203 - val_loss: 0.1462 - val_accuracy: 0.9397\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9219 - val_loss: 0.1166 - val_accuracy: 0.9528\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9228 - val_loss: 0.1350 - val_accuracy: 0.9448\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9238 - val_loss: 0.1151 - val_accuracy: 0.9525\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.9253 - val_loss: 0.1041 - val_accuracy: 0.9574\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.9246 - val_loss: 0.1240 - val_accuracy: 0.9471\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9247 - val_loss: 0.1199 - val_accuracy: 0.9492\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9272 - val_loss: 0.1072 - val_accuracy: 0.9557\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1764 - accuracy: 0.9275 - val_loss: 0.1405 - val_accuracy: 0.9426\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1718 - accuracy: 0.9282 - val_loss: 0.1095 - val_accuracy: 0.9542\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9286 - val_loss: 0.1219 - val_accuracy: 0.9476\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9308 - val_loss: 0.0997 - val_accuracy: 0.9595\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9292 - val_loss: 0.0977 - val_accuracy: 0.9592\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9285 - val_loss: 0.1062 - val_accuracy: 0.9547\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.9317 - val_loss: 0.1079 - val_accuracy: 0.9538\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9321 - val_loss: 0.1201 - val_accuracy: 0.9475\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 0.9350 - val_loss: 0.0994 - val_accuracy: 0.9564\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9336 - val_loss: 0.1296 - val_accuracy: 0.9447\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9333 - val_loss: 0.1059 - val_accuracy: 0.9562\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9352 - val_loss: 0.0999 - val_accuracy: 0.9559\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9365 - val_loss: 0.1205 - val_accuracy: 0.9493\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1541 - accuracy: 0.9378 - val_loss: 0.1158 - val_accuracy: 0.9508\n",
      "Epoch 94/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9360 - val_loss: 0.1180 - val_accuracy: 0.9486\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9373 - val_loss: 0.0954 - val_accuracy: 0.9607\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9359 - val_loss: 0.1238 - val_accuracy: 0.9460\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9393 - val_loss: 0.1092 - val_accuracy: 0.9534\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9397 - val_loss: 0.1094 - val_accuracy: 0.9527\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9398 - val_loss: 0.1067 - val_accuracy: 0.9525\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9402 - val_loss: 0.1122 - val_accuracy: 0.9519\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9422 - val_loss: 0.1304 - val_accuracy: 0.9447\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9412 - val_loss: 0.0816 - val_accuracy: 0.9652\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9415 - val_loss: 0.1094 - val_accuracy: 0.9524\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9416 - val_loss: 0.1053 - val_accuracy: 0.9542\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9437 - val_loss: 0.0940 - val_accuracy: 0.9594\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9423 - val_loss: 0.1098 - val_accuracy: 0.9521\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9438 - val_loss: 0.1109 - val_accuracy: 0.9516\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9464 - val_loss: 0.1004 - val_accuracy: 0.9546\n",
      "Epoch 109/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 0.9447 - val_loss: 0.0966 - val_accuracy: 0.9565\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9458 - val_loss: 0.0964 - val_accuracy: 0.9572\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9448 - val_loss: 0.0827 - val_accuracy: 0.9640\n",
      "Epoch 112/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9454 - val_loss: 0.0944 - val_accuracy: 0.9585\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9468 - val_loss: 0.1020 - val_accuracy: 0.9556\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9472 - val_loss: 0.0996 - val_accuracy: 0.9583\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9459 - val_loss: 0.0899 - val_accuracy: 0.9603\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9475 - val_loss: 0.1280 - val_accuracy: 0.9458\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9474 - val_loss: 0.0944 - val_accuracy: 0.9593\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9480 - val_loss: 0.0919 - val_accuracy: 0.9592\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9489 - val_loss: 0.0935 - val_accuracy: 0.9574\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9477 - val_loss: 0.1073 - val_accuracy: 0.9525\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9497 - val_loss: 0.1036 - val_accuracy: 0.9541\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9498 - val_loss: 0.0797 - val_accuracy: 0.9634\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9493 - val_loss: 0.0835 - val_accuracy: 0.9635\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9501 - val_loss: 0.1064 - val_accuracy: 0.9534\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9512 - val_loss: 0.1036 - val_accuracy: 0.9536\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9512 - val_loss: 0.0916 - val_accuracy: 0.9594\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9512 - val_loss: 0.1067 - val_accuracy: 0.9544\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9503 - val_loss: 0.0913 - val_accuracy: 0.9595\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1236 - accuracy: 0.9521 - val_loss: 0.1068 - val_accuracy: 0.9535\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9523 - val_loss: 0.0975 - val_accuracy: 0.9558\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9522 - val_loss: 0.0815 - val_accuracy: 0.9633\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9539 - val_loss: 0.0873 - val_accuracy: 0.9599\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9550 - val_loss: 0.1113 - val_accuracy: 0.9527\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9523 - val_loss: 0.0869 - val_accuracy: 0.9597\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1182 - accuracy: 0.9537 - val_loss: 0.0921 - val_accuracy: 0.9592\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9525 - val_loss: 0.0900 - val_accuracy: 0.9592\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1195 - accuracy: 0.9537 - val_loss: 0.0956 - val_accuracy: 0.9575\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9549 - val_loss: 0.0849 - val_accuracy: 0.9609\n",
      "Epoch 139/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9554 - val_loss: 0.0982 - val_accuracy: 0.9581\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9555 - val_loss: 0.0939 - val_accuracy: 0.9587\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9534 - val_loss: 0.0958 - val_accuracy: 0.9577\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9557 - val_loss: 0.0736 - val_accuracy: 0.9673\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9545 - val_loss: 0.1029 - val_accuracy: 0.9544\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9550 - val_loss: 0.0772 - val_accuracy: 0.9647\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9562 - val_loss: 0.0955 - val_accuracy: 0.9576\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9547 - val_loss: 0.1073 - val_accuracy: 0.9528\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9567 - val_loss: 0.0832 - val_accuracy: 0.9634\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9568 - val_loss: 0.0905 - val_accuracy: 0.9608\n",
      "Epoch 149/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9558 - val_loss: 0.0850 - val_accuracy: 0.9617\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9581 - val_loss: 0.0745 - val_accuracy: 0.9668\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9579 - val_loss: 0.1071 - val_accuracy: 0.9549\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9568 - val_loss: 0.0784 - val_accuracy: 0.9632\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9577 - val_loss: 0.0802 - val_accuracy: 0.9638\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9572 - val_loss: 0.1047 - val_accuracy: 0.9548\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9565 - val_loss: 0.1146 - val_accuracy: 0.9521\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9587 - val_loss: 0.0788 - val_accuracy: 0.9659\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9574 - val_loss: 0.0933 - val_accuracy: 0.9578\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9597 - val_loss: 0.0690 - val_accuracy: 0.9716\n",
      "Epoch 159/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.9598 - val_loss: 0.0830 - val_accuracy: 0.9637\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9599 - val_loss: 0.0709 - val_accuracy: 0.9690\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.9578 - val_loss: 0.0866 - val_accuracy: 0.9615\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9601 - val_loss: 0.0981 - val_accuracy: 0.9587\n",
      "Epoch 163/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9607 - val_loss: 0.0780 - val_accuracy: 0.9655\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.9591 - val_loss: 0.0804 - val_accuracy: 0.9658\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9589 - val_loss: 0.0917 - val_accuracy: 0.9612\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9609 - val_loss: 0.0875 - val_accuracy: 0.9622\n",
      "Epoch 167/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9618 - val_loss: 0.1055 - val_accuracy: 0.9548\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9587 - val_loss: 0.0918 - val_accuracy: 0.9603\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1038 - accuracy: 0.9615 - val_loss: 0.0985 - val_accuracy: 0.9578\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9621 - val_loss: 0.0921 - val_accuracy: 0.9609\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9608 - val_loss: 0.0837 - val_accuracy: 0.9623\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9611 - val_loss: 0.0717 - val_accuracy: 0.9688\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9617 - val_loss: 0.0758 - val_accuracy: 0.9676\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9615 - val_loss: 0.0909 - val_accuracy: 0.9597\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9617 - val_loss: 0.1032 - val_accuracy: 0.9553\n",
      "Epoch 176/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9608 - val_loss: 0.0964 - val_accuracy: 0.9604\n",
      "Epoch 177/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9629 - val_loss: 0.0864 - val_accuracy: 0.9642\n",
      "Epoch 178/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9635 - val_loss: 0.0821 - val_accuracy: 0.9627\n",
      "Epoch 179/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9630 - val_loss: 0.0826 - val_accuracy: 0.9648\n",
      "Epoch 180/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9627 - val_loss: 0.0859 - val_accuracy: 0.9620\n",
      "Epoch 181/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0999 - accuracy: 0.9621 - val_loss: 0.0784 - val_accuracy: 0.9673\n",
      "Epoch 182/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9621 - val_loss: 0.0659 - val_accuracy: 0.9719\n",
      "Epoch 183/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 0.9629 - val_loss: 0.0679 - val_accuracy: 0.9710\n",
      "Epoch 184/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9637 - val_loss: 0.0715 - val_accuracy: 0.9693\n",
      "Epoch 185/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9645 - val_loss: 0.0770 - val_accuracy: 0.9665\n",
      "Epoch 186/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9638 - val_loss: 0.0786 - val_accuracy: 0.9663\n",
      "Epoch 187/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0974 - accuracy: 0.9635 - val_loss: 0.0779 - val_accuracy: 0.9657\n",
      "Epoch 188/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.9648 - val_loss: 0.0859 - val_accuracy: 0.9634\n",
      "Epoch 189/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9635 - val_loss: 0.0761 - val_accuracy: 0.9670\n",
      "Epoch 190/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9639 - val_loss: 0.0858 - val_accuracy: 0.9629\n",
      "Epoch 191/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9652 - val_loss: 0.0870 - val_accuracy: 0.9634\n",
      "Epoch 192/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0945 - accuracy: 0.9650 - val_loss: 0.0837 - val_accuracy: 0.9650\n",
      "Epoch 193/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9628 - val_loss: 0.0833 - val_accuracy: 0.9650\n",
      "Epoch 194/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9646 - val_loss: 0.0730 - val_accuracy: 0.9677\n",
      "Epoch 195/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9654 - val_loss: 0.0803 - val_accuracy: 0.9665\n",
      "Epoch 196/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9647 - val_loss: 0.0820 - val_accuracy: 0.9663\n",
      "Epoch 197/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9648 - val_loss: 0.0753 - val_accuracy: 0.9674\n",
      "Epoch 198/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9644 - val_loss: 0.1114 - val_accuracy: 0.9552\n",
      "Epoch 199/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9657 - val_loss: 0.0889 - val_accuracy: 0.9629\n",
      "Epoch 200/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9660 - val_loss: 0.0778 - val_accuracy: 0.9669\n",
      "Epoch 201/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9647 - val_loss: 0.0731 - val_accuracy: 0.9687\n",
      "Epoch 202/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9663 - val_loss: 0.0789 - val_accuracy: 0.9665\n",
      "Epoch 203/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9658 - val_loss: 0.0712 - val_accuracy: 0.9703\n",
      "Epoch 204/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9673 - val_loss: 0.0689 - val_accuracy: 0.9710\n",
      "Epoch 205/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0920 - accuracy: 0.9665 - val_loss: 0.0956 - val_accuracy: 0.9605\n",
      "Epoch 206/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9636 - val_loss: 0.0853 - val_accuracy: 0.9636\n",
      "Epoch 207/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9666 - val_loss: 0.0664 - val_accuracy: 0.9720\n",
      "Epoch 208/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 0.9663 - val_loss: 0.0696 - val_accuracy: 0.9710\n",
      "Epoch 209/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9681 - val_loss: 0.0823 - val_accuracy: 0.9653\n",
      "Epoch 210/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9688 - val_loss: 0.0714 - val_accuracy: 0.9686\n",
      "Epoch 211/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0904 - accuracy: 0.9660 - val_loss: 0.0706 - val_accuracy: 0.9695\n",
      "Epoch 212/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9673 - val_loss: 0.0754 - val_accuracy: 0.9676\n",
      "Epoch 213/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9672 - val_loss: 0.0754 - val_accuracy: 0.9673\n",
      "Epoch 214/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9666 - val_loss: 0.0924 - val_accuracy: 0.9622\n",
      "Epoch 215/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9673 - val_loss: 0.0681 - val_accuracy: 0.9709\n",
      "Epoch 216/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9682 - val_loss: 0.0741 - val_accuracy: 0.9693\n",
      "Epoch 217/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9677 - val_loss: 0.0664 - val_accuracy: 0.9721\n",
      "Epoch 218/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9675 - val_loss: 0.0750 - val_accuracy: 0.9691\n",
      "Epoch 219/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9681 - val_loss: 0.0836 - val_accuracy: 0.9656\n",
      "Epoch 220/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9690 - val_loss: 0.0727 - val_accuracy: 0.9686\n",
      "Epoch 221/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9685 - val_loss: 0.0668 - val_accuracy: 0.9730\n",
      "Epoch 222/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9677 - val_loss: 0.0738 - val_accuracy: 0.9699\n",
      "Epoch 223/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9671 - val_loss: 0.0706 - val_accuracy: 0.9698\n",
      "Epoch 224/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9680 - val_loss: 0.0770 - val_accuracy: 0.9690\n",
      "Epoch 225/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9680 - val_loss: 0.0778 - val_accuracy: 0.9675\n",
      "Epoch 226/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9693 - val_loss: 0.0761 - val_accuracy: 0.9689\n",
      "Epoch 227/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9688 - val_loss: 0.0902 - val_accuracy: 0.9628\n",
      "Epoch 228/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9688 - val_loss: 0.0856 - val_accuracy: 0.9647\n",
      "Epoch 229/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9690 - val_loss: 0.0762 - val_accuracy: 0.9683\n",
      "Epoch 230/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9696 - val_loss: 0.0787 - val_accuracy: 0.9664\n",
      "Epoch 231/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9681 - val_loss: 0.0815 - val_accuracy: 0.9665\n",
      "Epoch 232/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9683 - val_loss: 0.0699 - val_accuracy: 0.9701\n",
      "Epoch 233/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9681 - val_loss: 0.0690 - val_accuracy: 0.9713\n",
      "Epoch 234/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9702 - val_loss: 0.0764 - val_accuracy: 0.9688\n",
      "Epoch 235/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9684 - val_loss: 0.0605 - val_accuracy: 0.9731\n",
      "Epoch 236/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9683 - val_loss: 0.0582 - val_accuracy: 0.9747\n",
      "Epoch 237/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9685 - val_loss: 0.1002 - val_accuracy: 0.9596\n",
      "Epoch 238/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9703 - val_loss: 0.0753 - val_accuracy: 0.9690\n",
      "Epoch 239/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9692 - val_loss: 0.0696 - val_accuracy: 0.9715\n",
      "Epoch 240/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9696 - val_loss: 0.0705 - val_accuracy: 0.9696\n",
      "Epoch 241/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9708 - val_loss: 0.0710 - val_accuracy: 0.9701\n",
      "Epoch 242/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.0906 - val_accuracy: 0.9626\n",
      "Epoch 243/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9705 - val_loss: 0.0769 - val_accuracy: 0.9682\n",
      "Epoch 244/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0827 - accuracy: 0.9703 - val_loss: 0.0769 - val_accuracy: 0.9683\n",
      "Epoch 245/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9692 - val_loss: 0.0770 - val_accuracy: 0.9673\n",
      "Epoch 246/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9706 - val_loss: 0.0617 - val_accuracy: 0.9725\n",
      "Epoch 247/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9696 - val_loss: 0.0657 - val_accuracy: 0.9726\n",
      "Epoch 248/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9696 - val_loss: 0.0734 - val_accuracy: 0.9704\n",
      "Epoch 249/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9699 - val_loss: 0.0597 - val_accuracy: 0.9748\n",
      "Epoch 250/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0803 - accuracy: 0.9705 - val_loss: 0.0767 - val_accuracy: 0.9686\n",
      "Epoch 251/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9713 - val_loss: 0.0619 - val_accuracy: 0.9747\n",
      "Epoch 252/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9700 - val_loss: 0.0761 - val_accuracy: 0.9678\n",
      "Epoch 253/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9703 - val_loss: 0.0847 - val_accuracy: 0.9660\n",
      "Epoch 254/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9700 - val_loss: 0.0906 - val_accuracy: 0.9640\n",
      "Epoch 255/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9704 - val_loss: 0.0716 - val_accuracy: 0.9708\n",
      "Epoch 256/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9715 - val_loss: 0.0677 - val_accuracy: 0.9724\n",
      "Epoch 257/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9699 - val_loss: 0.0701 - val_accuracy: 0.9723\n",
      "Epoch 258/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9719 - val_loss: 0.0633 - val_accuracy: 0.9727\n",
      "Epoch 259/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9707 - val_loss: 0.0612 - val_accuracy: 0.9741\n",
      "Epoch 260/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9706 - val_loss: 0.0687 - val_accuracy: 0.9713\n",
      "Epoch 261/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9703 - val_loss: 0.0764 - val_accuracy: 0.9679\n",
      "Epoch 262/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9715 - val_loss: 0.0696 - val_accuracy: 0.9716\n",
      "Epoch 263/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9715 - val_loss: 0.0676 - val_accuracy: 0.9703\n",
      "Epoch 264/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9711 - val_loss: 0.0714 - val_accuracy: 0.9714\n",
      "Epoch 265/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9719 - val_loss: 0.0808 - val_accuracy: 0.9668\n",
      "Epoch 266/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9710 - val_loss: 0.0740 - val_accuracy: 0.9696\n",
      "Epoch 267/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9717 - val_loss: 0.0665 - val_accuracy: 0.9714\n",
      "Epoch 268/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9731 - val_loss: 0.0625 - val_accuracy: 0.9741\n",
      "Epoch 269/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9712 - val_loss: 0.0651 - val_accuracy: 0.9730\n",
      "Epoch 270/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9723 - val_loss: 0.0617 - val_accuracy: 0.9733\n",
      "Epoch 271/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9728 - val_loss: 0.0801 - val_accuracy: 0.9683\n",
      "Epoch 272/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9717 - val_loss: 0.0649 - val_accuracy: 0.9731\n",
      "Epoch 273/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9729 - val_loss: 0.0664 - val_accuracy: 0.9723\n",
      "Epoch 274/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9723 - val_loss: 0.0734 - val_accuracy: 0.9710\n",
      "Epoch 275/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9723 - val_loss: 0.0672 - val_accuracy: 0.9733\n",
      "Epoch 276/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9709 - val_loss: 0.0776 - val_accuracy: 0.9680\n",
      "Epoch 277/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9716 - val_loss: 0.0565 - val_accuracy: 0.9764\n",
      "Epoch 278/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9713 - val_loss: 0.0648 - val_accuracy: 0.9727\n",
      "Epoch 279/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9721 - val_loss: 0.0709 - val_accuracy: 0.9714\n",
      "Epoch 280/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9732 - val_loss: 0.0898 - val_accuracy: 0.9648\n",
      "Epoch 281/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.9714 - val_loss: 0.0651 - val_accuracy: 0.9733\n",
      "Epoch 282/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9730 - val_loss: 0.0783 - val_accuracy: 0.9688\n",
      "Epoch 283/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9736 - val_loss: 0.0704 - val_accuracy: 0.9726\n",
      "Epoch 284/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9731 - val_loss: 0.0779 - val_accuracy: 0.9683\n",
      "Epoch 285/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9732 - val_loss: 0.0889 - val_accuracy: 0.9640\n",
      "Epoch 286/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9721 - val_loss: 0.0708 - val_accuracy: 0.9707\n",
      "Epoch 287/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9733 - val_loss: 0.0669 - val_accuracy: 0.9707\n",
      "Epoch 288/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9730 - val_loss: 0.0791 - val_accuracy: 0.9690\n",
      "Epoch 289/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9735 - val_loss: 0.0655 - val_accuracy: 0.9728\n",
      "Epoch 290/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9723 - val_loss: 0.0699 - val_accuracy: 0.9723\n",
      "Epoch 291/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9734 - val_loss: 0.0785 - val_accuracy: 0.9682\n",
      "Epoch 292/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9729 - val_loss: 0.0649 - val_accuracy: 0.9737\n",
      "Epoch 293/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9734 - val_loss: 0.0819 - val_accuracy: 0.9677\n",
      "Epoch 294/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9722 - val_loss: 0.0594 - val_accuracy: 0.9745\n",
      "Epoch 295/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9738 - val_loss: 0.0716 - val_accuracy: 0.9706\n",
      "Epoch 296/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9733 - val_loss: 0.0754 - val_accuracy: 0.9698\n",
      "Epoch 297/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9744 - val_loss: 0.0669 - val_accuracy: 0.9725\n",
      "Epoch 298/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9731 - val_loss: 0.0704 - val_accuracy: 0.9709\n",
      "Epoch 299/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9729 - val_loss: 0.0602 - val_accuracy: 0.9746\n",
      "Epoch 300/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9745 - val_loss: 0.0806 - val_accuracy: 0.9676\n",
      "Epoch 301/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9723 - val_loss: 0.0802 - val_accuracy: 0.9686\n",
      "Epoch 302/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9727 - val_loss: 0.0760 - val_accuracy: 0.9684\n",
      "Epoch 303/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9731 - val_loss: 0.0669 - val_accuracy: 0.9725\n",
      "Epoch 304/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9745 - val_loss: 0.0673 - val_accuracy: 0.9727\n",
      "Epoch 305/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9732 - val_loss: 0.0706 - val_accuracy: 0.9716\n",
      "Epoch 306/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9735 - val_loss: 0.0732 - val_accuracy: 0.9704\n",
      "Epoch 307/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9739 - val_loss: 0.0676 - val_accuracy: 0.9734\n",
      "Epoch 308/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9742 - val_loss: 0.0757 - val_accuracy: 0.9694\n",
      "Epoch 309/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9740 - val_loss: 0.0638 - val_accuracy: 0.9740\n",
      "Epoch 310/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9728 - val_loss: 0.0650 - val_accuracy: 0.9744\n",
      "Epoch 311/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9754 - val_loss: 0.0722 - val_accuracy: 0.9704\n",
      "Epoch 312/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9759 - val_loss: 0.0738 - val_accuracy: 0.9696\n",
      "Epoch 313/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9741 - val_loss: 0.0790 - val_accuracy: 0.9690\n",
      "Epoch 314/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9724 - val_loss: 0.0559 - val_accuracy: 0.9766\n",
      "Epoch 315/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9731 - val_loss: 0.0598 - val_accuracy: 0.9753\n",
      "Epoch 316/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9737 - val_loss: 0.0622 - val_accuracy: 0.9737\n",
      "Epoch 317/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9740 - val_loss: 0.0623 - val_accuracy: 0.9739\n",
      "Epoch 318/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9754 - val_loss: 0.0732 - val_accuracy: 0.9700\n",
      "Epoch 319/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9748 - val_loss: 0.0632 - val_accuracy: 0.9741\n",
      "Epoch 320/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9742 - val_loss: 0.0725 - val_accuracy: 0.9710\n",
      "Epoch 321/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9745 - val_loss: 0.0696 - val_accuracy: 0.9727\n",
      "Epoch 322/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9753 - val_loss: 0.0733 - val_accuracy: 0.9694\n",
      "Epoch 323/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9742 - val_loss: 0.0634 - val_accuracy: 0.9746\n",
      "Epoch 324/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9754 - val_loss: 0.0660 - val_accuracy: 0.9734\n",
      "Epoch 325/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9759 - val_loss: 0.0714 - val_accuracy: 0.9715\n",
      "Epoch 326/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9742 - val_loss: 0.0638 - val_accuracy: 0.9731\n",
      "Epoch 327/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9743 - val_loss: 0.0690 - val_accuracy: 0.9725\n",
      "Epoch 328/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9738 - val_loss: 0.0633 - val_accuracy: 0.9729\n",
      "Epoch 329/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9740 - val_loss: 0.0704 - val_accuracy: 0.9729\n",
      "Epoch 330/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9756 - val_loss: 0.0583 - val_accuracy: 0.9764\n",
      "Epoch 331/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9756 - val_loss: 0.0617 - val_accuracy: 0.9759\n",
      "Epoch 332/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9746 - val_loss: 0.0692 - val_accuracy: 0.9728\n",
      "Epoch 333/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9743 - val_loss: 0.0577 - val_accuracy: 0.9769\n",
      "Epoch 334/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9755 - val_loss: 0.0681 - val_accuracy: 0.9728\n",
      "Epoch 335/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9748 - val_loss: 0.0639 - val_accuracy: 0.9740\n",
      "Epoch 336/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9753 - val_loss: 0.0567 - val_accuracy: 0.9757\n",
      "Epoch 337/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9757 - val_loss: 0.0664 - val_accuracy: 0.9731\n",
      "Epoch 338/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9753 - val_loss: 0.0698 - val_accuracy: 0.9723\n",
      "Epoch 339/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9758 - val_loss: 0.0721 - val_accuracy: 0.9708\n",
      "Epoch 340/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9744 - val_loss: 0.0620 - val_accuracy: 0.9743\n",
      "Epoch 341/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9754 - val_loss: 0.0729 - val_accuracy: 0.9707\n",
      "Epoch 342/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9741 - val_loss: 0.0721 - val_accuracy: 0.9720\n",
      "Epoch 343/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9763 - val_loss: 0.0620 - val_accuracy: 0.9746\n",
      "Epoch 344/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9759 - val_loss: 0.0607 - val_accuracy: 0.9737\n",
      "Epoch 345/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9758 - val_loss: 0.0682 - val_accuracy: 0.9729\n",
      "Epoch 346/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9755 - val_loss: 0.0708 - val_accuracy: 0.9724\n",
      "Epoch 347/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9764 - val_loss: 0.0839 - val_accuracy: 0.9686\n",
      "Epoch 348/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9745 - val_loss: 0.0594 - val_accuracy: 0.9763\n",
      "Epoch 349/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9770 - val_loss: 0.0678 - val_accuracy: 0.9734\n",
      "Epoch 350/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9760 - val_loss: 0.0570 - val_accuracy: 0.9761\n",
      "Epoch 351/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0688 - accuracy: 0.9761 - val_loss: 0.0614 - val_accuracy: 0.9741\n",
      "Epoch 352/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9757 - val_loss: 0.0631 - val_accuracy: 0.9747\n",
      "Epoch 353/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9764 - val_loss: 0.0629 - val_accuracy: 0.9739\n",
      "Epoch 354/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9753 - val_loss: 0.0692 - val_accuracy: 0.9724\n",
      "Epoch 355/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9751 - val_loss: 0.0682 - val_accuracy: 0.9734\n",
      "Epoch 356/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9751 - val_loss: 0.0682 - val_accuracy: 0.9720\n",
      "Epoch 357/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9770 - val_loss: 0.0685 - val_accuracy: 0.9726\n",
      "Epoch 358/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9773 - val_loss: 0.0663 - val_accuracy: 0.9736\n",
      "Epoch 359/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9756 - val_loss: 0.0589 - val_accuracy: 0.9758\n",
      "Epoch 360/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9752 - val_loss: 0.0652 - val_accuracy: 0.9730\n",
      "Epoch 361/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9748 - val_loss: 0.0630 - val_accuracy: 0.9751\n",
      "Epoch 362/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9759 - val_loss: 0.0582 - val_accuracy: 0.9750\n",
      "Epoch 363/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9743 - val_loss: 0.0692 - val_accuracy: 0.9708\n",
      "Epoch 364/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9763 - val_loss: 0.0694 - val_accuracy: 0.9726\n",
      "Epoch 365/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9771 - val_loss: 0.0578 - val_accuracy: 0.9764\n",
      "Epoch 366/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9759 - val_loss: 0.0697 - val_accuracy: 0.9714\n",
      "Epoch 367/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9749 - val_loss: 0.0556 - val_accuracy: 0.9771\n",
      "Epoch 368/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9758 - val_loss: 0.0596 - val_accuracy: 0.9755\n",
      "Epoch 369/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 0.0576 - val_accuracy: 0.9751\n",
      "Epoch 370/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9761 - val_loss: 0.0644 - val_accuracy: 0.9740\n",
      "Epoch 371/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9757 - val_loss: 0.0633 - val_accuracy: 0.9743\n",
      "Epoch 372/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9762 - val_loss: 0.0692 - val_accuracy: 0.9729\n",
      "Epoch 373/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9762 - val_loss: 0.0755 - val_accuracy: 0.9705\n",
      "Epoch 374/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9767 - val_loss: 0.0584 - val_accuracy: 0.9766\n",
      "Epoch 375/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9777 - val_loss: 0.0636 - val_accuracy: 0.9746\n",
      "Epoch 376/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9767 - val_loss: 0.0548 - val_accuracy: 0.9773\n",
      "Epoch 377/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9777 - val_loss: 0.0598 - val_accuracy: 0.9761\n",
      "Epoch 378/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9765 - val_loss: 0.0730 - val_accuracy: 0.9707\n",
      "Epoch 379/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9761 - val_loss: 0.0646 - val_accuracy: 0.9747\n",
      "Epoch 380/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9767 - val_loss: 0.0626 - val_accuracy: 0.9743\n",
      "Epoch 381/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9769 - val_loss: 0.0758 - val_accuracy: 0.9699\n",
      "Epoch 382/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9757 - val_loss: 0.0590 - val_accuracy: 0.9749\n",
      "Epoch 383/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9778 - val_loss: 0.0669 - val_accuracy: 0.9729\n",
      "Epoch 384/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9766 - val_loss: 0.0837 - val_accuracy: 0.9684\n",
      "Epoch 385/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9767 - val_loss: 0.0792 - val_accuracy: 0.9693\n",
      "Epoch 386/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9772 - val_loss: 0.0677 - val_accuracy: 0.9738\n",
      "Epoch 387/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9775 - val_loss: 0.0532 - val_accuracy: 0.9782\n",
      "Epoch 388/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9758 - val_loss: 0.0670 - val_accuracy: 0.9740\n",
      "Epoch 389/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9774 - val_loss: 0.0646 - val_accuracy: 0.9745\n",
      "Epoch 390/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9772 - val_loss: 0.0592 - val_accuracy: 0.9756\n",
      "Epoch 391/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9769 - val_loss: 0.0651 - val_accuracy: 0.9736\n",
      "Epoch 392/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9771 - val_loss: 0.0629 - val_accuracy: 0.9749\n",
      "Epoch 393/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9773 - val_loss: 0.0583 - val_accuracy: 0.9765\n",
      "Epoch 394/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9772 - val_loss: 0.0586 - val_accuracy: 0.9760\n",
      "Epoch 395/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9773 - val_loss: 0.0689 - val_accuracy: 0.9727\n",
      "Epoch 396/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9768 - val_loss: 0.0560 - val_accuracy: 0.9773\n",
      "Epoch 397/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9777 - val_loss: 0.0576 - val_accuracy: 0.9768\n",
      "Epoch 398/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9778 - val_loss: 0.0597 - val_accuracy: 0.9753\n",
      "Epoch 399/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9776 - val_loss: 0.0540 - val_accuracy: 0.9767\n",
      "Epoch 400/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9776 - val_loss: 0.0571 - val_accuracy: 0.9764\n",
      "Epoch 401/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9765 - val_loss: 0.0641 - val_accuracy: 0.9754\n",
      "Epoch 402/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9766 - val_loss: 0.0584 - val_accuracy: 0.9766\n",
      "Epoch 403/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9767 - val_loss: 0.0768 - val_accuracy: 0.9713\n",
      "Epoch 404/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9757 - val_loss: 0.0706 - val_accuracy: 0.9731\n",
      "Epoch 405/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9778 - val_loss: 0.0583 - val_accuracy: 0.9756\n",
      "Epoch 406/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9773 - val_loss: 0.0691 - val_accuracy: 0.9724\n",
      "Epoch 407/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9770 - val_loss: 0.0654 - val_accuracy: 0.9740\n",
      "Epoch 408/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9773 - val_loss: 0.0682 - val_accuracy: 0.9741\n",
      "Epoch 409/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9784 - val_loss: 0.0594 - val_accuracy: 0.9759\n",
      "Epoch 410/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9783 - val_loss: 0.0649 - val_accuracy: 0.9744\n",
      "Epoch 411/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9767 - val_loss: 0.0721 - val_accuracy: 0.9725\n",
      "Epoch 412/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9770 - val_loss: 0.0569 - val_accuracy: 0.9775\n",
      "Epoch 413/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9768 - val_loss: 0.0703 - val_accuracy: 0.9730\n",
      "Epoch 414/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.0563 - val_accuracy: 0.9767\n",
      "Epoch 415/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9779 - val_loss: 0.0567 - val_accuracy: 0.9765\n",
      "Epoch 416/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9779 - val_loss: 0.0673 - val_accuracy: 0.9741\n",
      "Epoch 417/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9782 - val_loss: 0.0588 - val_accuracy: 0.9764\n",
      "Epoch 418/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9771 - val_loss: 0.0574 - val_accuracy: 0.9769\n",
      "Epoch 419/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9767 - val_loss: 0.0595 - val_accuracy: 0.9756\n",
      "Epoch 420/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9779 - val_loss: 0.0606 - val_accuracy: 0.9767\n",
      "Epoch 421/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9782 - val_loss: 0.0794 - val_accuracy: 0.9695\n",
      "Epoch 422/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9775 - val_loss: 0.0597 - val_accuracy: 0.9759\n",
      "Epoch 423/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9770 - val_loss: 0.0709 - val_accuracy: 0.9730\n",
      "Epoch 424/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9768 - val_loss: 0.0682 - val_accuracy: 0.9737\n",
      "Epoch 425/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9772 - val_loss: 0.0561 - val_accuracy: 0.9768\n",
      "Epoch 426/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9790 - val_loss: 0.0626 - val_accuracy: 0.9748\n",
      "Epoch 427/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.0627 - val_accuracy: 0.9751\n",
      "Epoch 428/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9777 - val_loss: 0.0690 - val_accuracy: 0.9729\n",
      "Epoch 429/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9778 - val_loss: 0.0620 - val_accuracy: 0.9753\n",
      "Epoch 430/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9772 - val_loss: 0.0607 - val_accuracy: 0.9751\n",
      "Epoch 431/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9785 - val_loss: 0.0654 - val_accuracy: 0.9739\n",
      "Epoch 432/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9772 - val_loss: 0.0534 - val_accuracy: 0.9778\n",
      "Epoch 433/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9779 - val_loss: 0.0642 - val_accuracy: 0.9757\n",
      "Epoch 434/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9770 - val_loss: 0.0533 - val_accuracy: 0.9777\n",
      "Epoch 435/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9789 - val_loss: 0.0569 - val_accuracy: 0.9770\n",
      "Epoch 436/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9775 - val_loss: 0.0602 - val_accuracy: 0.9750\n",
      "Epoch 437/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9781 - val_loss: 0.0648 - val_accuracy: 0.9750\n",
      "Epoch 438/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9790 - val_loss: 0.0642 - val_accuracy: 0.9748\n",
      "Epoch 439/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9783 - val_loss: 0.0660 - val_accuracy: 0.9750\n",
      "Epoch 440/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9786 - val_loss: 0.0696 - val_accuracy: 0.9731\n",
      "Epoch 441/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9770 - val_loss: 0.0692 - val_accuracy: 0.9737\n",
      "Epoch 442/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9772 - val_loss: 0.0550 - val_accuracy: 0.9776\n",
      "Epoch 443/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9783 - val_loss: 0.0702 - val_accuracy: 0.9734\n",
      "Epoch 444/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9784 - val_loss: 0.0505 - val_accuracy: 0.9791\n",
      "Epoch 445/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 0.0604 - val_accuracy: 0.9757\n",
      "Epoch 446/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9787 - val_loss: 0.0666 - val_accuracy: 0.9743\n",
      "Epoch 447/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9784 - val_loss: 0.0631 - val_accuracy: 0.9759\n",
      "Epoch 448/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9779 - val_loss: 0.0564 - val_accuracy: 0.9767\n",
      "Epoch 449/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9773 - val_loss: 0.0556 - val_accuracy: 0.9769\n",
      "Epoch 450/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9784 - val_loss: 0.0569 - val_accuracy: 0.9763\n",
      "Epoch 451/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9785 - val_loss: 0.0646 - val_accuracy: 0.9746\n",
      "Epoch 452/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0625 - accuracy: 0.9778 - val_loss: 0.0691 - val_accuracy: 0.9731\n",
      "Epoch 453/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9782 - val_loss: 0.0623 - val_accuracy: 0.9755\n",
      "Epoch 454/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9782 - val_loss: 0.0599 - val_accuracy: 0.9760\n",
      "Epoch 455/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9791 - val_loss: 0.0644 - val_accuracy: 0.9756\n",
      "Epoch 456/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9786 - val_loss: 0.0653 - val_accuracy: 0.9748\n",
      "Epoch 457/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9789 - val_loss: 0.0518 - val_accuracy: 0.9782\n",
      "Epoch 458/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9770 - val_loss: 0.0602 - val_accuracy: 0.9768\n",
      "Epoch 459/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9781 - val_loss: 0.0607 - val_accuracy: 0.9766\n",
      "Epoch 460/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9784 - val_loss: 0.0598 - val_accuracy: 0.9774\n",
      "Epoch 461/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9789 - val_loss: 0.0590 - val_accuracy: 0.9758\n",
      "Epoch 462/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9776 - val_loss: 0.0559 - val_accuracy: 0.9769\n",
      "Epoch 463/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9781 - val_loss: 0.0626 - val_accuracy: 0.9751\n",
      "Epoch 464/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9779 - val_loss: 0.0517 - val_accuracy: 0.9778\n",
      "Epoch 465/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.0690 - val_accuracy: 0.9729\n",
      "Epoch 466/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9795 - val_loss: 0.0551 - val_accuracy: 0.9773\n",
      "Epoch 467/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9771 - val_loss: 0.0779 - val_accuracy: 0.9715\n",
      "Epoch 468/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9785 - val_loss: 0.0636 - val_accuracy: 0.9761\n",
      "Epoch 469/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9782 - val_loss: 0.0691 - val_accuracy: 0.9734\n",
      "Epoch 470/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.0713 - val_accuracy: 0.9726\n",
      "Epoch 471/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.0588 - val_accuracy: 0.9764\n",
      "Epoch 472/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9793 - val_loss: 0.0619 - val_accuracy: 0.9755\n",
      "Epoch 473/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 0.0567 - val_accuracy: 0.9767\n",
      "Epoch 474/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9791 - val_loss: 0.0772 - val_accuracy: 0.9714\n",
      "Epoch 475/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9791 - val_loss: 0.0608 - val_accuracy: 0.9760\n",
      "Epoch 476/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9772 - val_loss: 0.0579 - val_accuracy: 0.9767\n",
      "Epoch 477/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9788 - val_loss: 0.0589 - val_accuracy: 0.9756\n",
      "Epoch 478/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9782 - val_loss: 0.0583 - val_accuracy: 0.9767\n",
      "Epoch 479/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9797 - val_loss: 0.0562 - val_accuracy: 0.9774\n",
      "Epoch 480/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9783 - val_loss: 0.0626 - val_accuracy: 0.9766\n",
      "Epoch 481/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9788 - val_loss: 0.0717 - val_accuracy: 0.9735\n",
      "Epoch 482/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9779 - val_loss: 0.0561 - val_accuracy: 0.9759\n",
      "Epoch 483/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9797 - val_loss: 0.0590 - val_accuracy: 0.9774\n",
      "Epoch 484/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9776 - val_loss: 0.0639 - val_accuracy: 0.9758\n",
      "Epoch 485/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9792 - val_loss: 0.0544 - val_accuracy: 0.9787\n",
      "Epoch 486/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9784 - val_loss: 0.0606 - val_accuracy: 0.9758\n",
      "Epoch 487/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9788 - val_loss: 0.0580 - val_accuracy: 0.9767\n",
      "Epoch 488/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9795 - val_loss: 0.0601 - val_accuracy: 0.9763\n",
      "Epoch 489/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9786 - val_loss: 0.0581 - val_accuracy: 0.9765\n",
      "Epoch 490/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9785 - val_loss: 0.0640 - val_accuracy: 0.9749\n",
      "Epoch 491/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9788 - val_loss: 0.0592 - val_accuracy: 0.9754\n",
      "Epoch 492/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9789 - val_loss: 0.0655 - val_accuracy: 0.9748\n",
      "Epoch 493/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9784 - val_loss: 0.0590 - val_accuracy: 0.9761\n",
      "Epoch 494/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9793 - val_loss: 0.0580 - val_accuracy: 0.9775\n",
      "Epoch 495/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9786 - val_loss: 0.0595 - val_accuracy: 0.9760\n",
      "Epoch 496/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9784 - val_loss: 0.0609 - val_accuracy: 0.9765\n",
      "Epoch 497/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9786 - val_loss: 0.0594 - val_accuracy: 0.9763\n",
      "Epoch 498/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9794 - val_loss: 0.0593 - val_accuracy: 0.9776\n",
      "Epoch 499/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9777 - val_loss: 0.0806 - val_accuracy: 0.9708\n",
      "Epoch 500/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9784 - val_loss: 0.0522 - val_accuracy: 0.9784\n",
      "Epoch 501/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.0604 - val_accuracy: 0.9758\n",
      "Epoch 502/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9792 - val_loss: 0.0594 - val_accuracy: 0.9759\n",
      "Epoch 503/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9795 - val_loss: 0.0548 - val_accuracy: 0.9777\n",
      "Epoch 504/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9800 - val_loss: 0.0629 - val_accuracy: 0.9756\n",
      "Epoch 505/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9798 - val_loss: 0.0507 - val_accuracy: 0.9789\n",
      "Epoch 506/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9801 - val_loss: 0.0597 - val_accuracy: 0.9757\n",
      "Epoch 507/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9790 - val_loss: 0.0700 - val_accuracy: 0.9738\n",
      "Epoch 508/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9789 - val_loss: 0.0525 - val_accuracy: 0.9784\n",
      "Epoch 509/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9793 - val_loss: 0.0612 - val_accuracy: 0.9761\n",
      "Epoch 510/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9798 - val_loss: 0.0659 - val_accuracy: 0.9750\n",
      "Epoch 511/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9793 - val_loss: 0.0573 - val_accuracy: 0.9758\n",
      "Epoch 512/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9783 - val_loss: 0.0590 - val_accuracy: 0.9771\n",
      "Epoch 513/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9796 - val_loss: 0.0670 - val_accuracy: 0.9750\n",
      "Epoch 514/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9794 - val_loss: 0.0530 - val_accuracy: 0.9775\n",
      "Epoch 515/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9792 - val_loss: 0.0552 - val_accuracy: 0.9781\n",
      "Epoch 516/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9791 - val_loss: 0.0601 - val_accuracy: 0.9771\n",
      "Epoch 517/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9786 - val_loss: 0.0656 - val_accuracy: 0.9746\n",
      "Epoch 518/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9790 - val_loss: 0.0605 - val_accuracy: 0.9756\n",
      "Epoch 519/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9785 - val_loss: 0.0598 - val_accuracy: 0.9763\n",
      "Epoch 520/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9794 - val_loss: 0.0580 - val_accuracy: 0.9769\n",
      "Epoch 521/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9799 - val_loss: 0.0687 - val_accuracy: 0.9747\n",
      "Epoch 522/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9794 - val_loss: 0.0668 - val_accuracy: 0.9749\n",
      "Epoch 523/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9804 - val_loss: 0.0644 - val_accuracy: 0.9748\n",
      "Epoch 524/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9796 - val_loss: 0.0637 - val_accuracy: 0.9759\n",
      "Epoch 525/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9798 - val_loss: 0.0750 - val_accuracy: 0.9727\n",
      "Epoch 526/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9786 - val_loss: 0.0583 - val_accuracy: 0.9760\n",
      "Epoch 527/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9795 - val_loss: 0.0689 - val_accuracy: 0.9749\n",
      "Epoch 528/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9782 - val_loss: 0.0578 - val_accuracy: 0.9769\n",
      "Epoch 529/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9799 - val_loss: 0.0600 - val_accuracy: 0.9760\n",
      "Epoch 530/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9791 - val_loss: 0.0588 - val_accuracy: 0.9769\n",
      "Epoch 531/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9804 - val_loss: 0.0558 - val_accuracy: 0.9765\n",
      "Epoch 532/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9796 - val_loss: 0.0712 - val_accuracy: 0.9738\n",
      "Epoch 533/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9803 - val_loss: 0.0536 - val_accuracy: 0.9779\n",
      "Epoch 534/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9792 - val_loss: 0.0576 - val_accuracy: 0.9769\n",
      "Epoch 535/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 0.0556 - val_accuracy: 0.9780\n",
      "Epoch 536/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9789 - val_loss: 0.0632 - val_accuracy: 0.9757\n",
      "Epoch 537/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9788 - val_loss: 0.0630 - val_accuracy: 0.9748\n",
      "Epoch 538/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9804 - val_loss: 0.0622 - val_accuracy: 0.9759\n",
      "Epoch 539/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9794 - val_loss: 0.0613 - val_accuracy: 0.9761\n",
      "Epoch 540/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9794 - val_loss: 0.0553 - val_accuracy: 0.9769\n",
      "Epoch 541/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9796 - val_loss: 0.0621 - val_accuracy: 0.9757\n",
      "Epoch 542/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9802 - val_loss: 0.0569 - val_accuracy: 0.9778\n",
      "Epoch 543/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9790 - val_loss: 0.0570 - val_accuracy: 0.9766\n",
      "Epoch 544/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9794 - val_loss: 0.0696 - val_accuracy: 0.9748\n",
      "Epoch 545/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.0609 - val_accuracy: 0.9760\n",
      "Epoch 546/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9790 - val_loss: 0.0580 - val_accuracy: 0.9769\n",
      "Epoch 547/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0621 - val_accuracy: 0.9755\n",
      "Epoch 548/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9806 - val_loss: 0.0619 - val_accuracy: 0.9745\n",
      "Epoch 549/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9791 - val_loss: 0.0692 - val_accuracy: 0.9743\n",
      "Epoch 550/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9799 - val_loss: 0.0780 - val_accuracy: 0.9716\n",
      "Epoch 551/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 0.0601 - val_accuracy: 0.9765\n",
      "Epoch 552/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9796 - val_loss: 0.0567 - val_accuracy: 0.9775\n",
      "Epoch 553/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0558 - accuracy: 0.9802 - val_loss: 0.0574 - val_accuracy: 0.9776\n",
      "Epoch 554/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9803 - val_loss: 0.0566 - val_accuracy: 0.9765\n",
      "Epoch 555/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9802 - val_loss: 0.0601 - val_accuracy: 0.9763\n",
      "Epoch 556/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9797 - val_loss: 0.0632 - val_accuracy: 0.9764\n",
      "Epoch 557/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9793 - val_loss: 0.0687 - val_accuracy: 0.9746\n",
      "Epoch 558/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9796 - val_loss: 0.0727 - val_accuracy: 0.9736\n",
      "Epoch 559/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9789 - val_loss: 0.0682 - val_accuracy: 0.9749\n",
      "Epoch 560/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9796 - val_loss: 0.0651 - val_accuracy: 0.9750\n",
      "Epoch 561/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9801 - val_loss: 0.0650 - val_accuracy: 0.9753\n",
      "Epoch 562/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9802 - val_loss: 0.0505 - val_accuracy: 0.9782\n",
      "Epoch 563/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9795 - val_loss: 0.0626 - val_accuracy: 0.9763\n",
      "Epoch 564/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9801 - val_loss: 0.0680 - val_accuracy: 0.9753\n",
      "Epoch 565/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9799 - val_loss: 0.0590 - val_accuracy: 0.9769\n",
      "Epoch 566/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9795 - val_loss: 0.0575 - val_accuracy: 0.9766\n",
      "Epoch 567/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9809 - val_loss: 0.0732 - val_accuracy: 0.9736\n",
      "Epoch 568/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9807 - val_loss: 0.0623 - val_accuracy: 0.9761\n",
      "Epoch 569/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9801 - val_loss: 0.0632 - val_accuracy: 0.9751\n",
      "Epoch 570/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9795 - val_loss: 0.0598 - val_accuracy: 0.9771\n",
      "Epoch 571/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9797 - val_loss: 0.0545 - val_accuracy: 0.9773\n",
      "Epoch 572/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9797 - val_loss: 0.0673 - val_accuracy: 0.9750\n",
      "Epoch 573/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9791 - val_loss: 0.0574 - val_accuracy: 0.9769\n",
      "Epoch 574/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9797 - val_loss: 0.0729 - val_accuracy: 0.9730\n",
      "Epoch 575/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.0723 - val_accuracy: 0.9729\n",
      "Epoch 576/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9799 - val_loss: 0.0544 - val_accuracy: 0.9771\n",
      "Epoch 577/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0675 - val_accuracy: 0.9753\n",
      "Epoch 578/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9786 - val_loss: 0.0717 - val_accuracy: 0.9745\n",
      "Epoch 579/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9803 - val_loss: 0.0596 - val_accuracy: 0.9763\n",
      "Epoch 580/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 0.0731 - val_accuracy: 0.9737\n",
      "Epoch 581/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 0.0610 - val_accuracy: 0.9763\n",
      "Epoch 582/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9792 - val_loss: 0.0558 - val_accuracy: 0.9774\n",
      "Epoch 583/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9795 - val_loss: 0.0592 - val_accuracy: 0.9768\n",
      "Epoch 584/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9788 - val_loss: 0.0607 - val_accuracy: 0.9763\n",
      "Epoch 585/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9808 - val_loss: 0.0756 - val_accuracy: 0.9718\n",
      "Epoch 586/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9796 - val_loss: 0.0639 - val_accuracy: 0.9756\n",
      "Epoch 587/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 0.0594 - val_accuracy: 0.9778\n",
      "Epoch 588/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 0.0618 - val_accuracy: 0.9766\n",
      "Epoch 589/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9806 - val_loss: 0.0585 - val_accuracy: 0.9764\n",
      "Epoch 590/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9780 - val_loss: 0.0571 - val_accuracy: 0.9769\n",
      "Epoch 591/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9791 - val_loss: 0.0679 - val_accuracy: 0.9750\n",
      "Epoch 592/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9799 - val_loss: 0.0663 - val_accuracy: 0.9755\n",
      "Epoch 593/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9795 - val_loss: 0.0562 - val_accuracy: 0.9771\n",
      "Epoch 594/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9795 - val_loss: 0.0676 - val_accuracy: 0.9757\n",
      "Epoch 595/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9791 - val_loss: 0.0568 - val_accuracy: 0.9775\n",
      "Epoch 596/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9795 - val_loss: 0.0590 - val_accuracy: 0.9765\n",
      "Epoch 597/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0708 - val_accuracy: 0.9741\n",
      "Epoch 598/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.9795 - val_loss: 0.0586 - val_accuracy: 0.9757\n",
      "Epoch 599/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.0498 - val_accuracy: 0.9780\n",
      "Epoch 600/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9799 - val_loss: 0.0675 - val_accuracy: 0.9756\n",
      "Epoch 601/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9797 - val_loss: 0.0529 - val_accuracy: 0.9776\n",
      "Epoch 602/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9796 - val_loss: 0.0517 - val_accuracy: 0.9788\n",
      "Epoch 603/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 0.0592 - val_accuracy: 0.9767\n",
      "Epoch 604/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 0.0627 - val_accuracy: 0.9761\n",
      "Epoch 605/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 0.0675 - val_accuracy: 0.9757\n",
      "Epoch 606/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9806 - val_loss: 0.0653 - val_accuracy: 0.9759\n",
      "Epoch 607/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9807 - val_loss: 0.0594 - val_accuracy: 0.9776\n",
      "Epoch 608/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9806 - val_loss: 0.0535 - val_accuracy: 0.9774\n",
      "Epoch 609/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9801 - val_loss: 0.0620 - val_accuracy: 0.9761\n",
      "Epoch 610/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9796 - val_loss: 0.0663 - val_accuracy: 0.9770\n",
      "Epoch 611/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9797 - val_loss: 0.0774 - val_accuracy: 0.9734\n",
      "Epoch 612/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9803 - val_loss: 0.0585 - val_accuracy: 0.9770\n",
      "Epoch 613/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9808 - val_loss: 0.0582 - val_accuracy: 0.9770\n",
      "Epoch 614/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9798 - val_loss: 0.0570 - val_accuracy: 0.9784\n",
      "Epoch 615/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9804 - val_loss: 0.0555 - val_accuracy: 0.9776\n",
      "Epoch 616/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.0663 - val_accuracy: 0.9755\n",
      "Epoch 617/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 0.0652 - val_accuracy: 0.9756\n",
      "Epoch 618/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9816 - val_loss: 0.0634 - val_accuracy: 0.9765\n",
      "Epoch 619/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9802 - val_loss: 0.0554 - val_accuracy: 0.9784\n",
      "Epoch 620/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9804 - val_loss: 0.0541 - val_accuracy: 0.9784\n",
      "Epoch 621/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 0.0762 - val_accuracy: 0.9726\n",
      "Epoch 622/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9796 - val_loss: 0.0645 - val_accuracy: 0.9764\n",
      "Epoch 623/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9801 - val_loss: 0.0612 - val_accuracy: 0.9757\n",
      "Epoch 624/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9802 - val_loss: 0.0596 - val_accuracy: 0.9775\n",
      "Epoch 625/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9808 - val_loss: 0.0802 - val_accuracy: 0.9713\n",
      "Epoch 626/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9801 - val_loss: 0.0638 - val_accuracy: 0.9759\n",
      "Epoch 627/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9813 - val_loss: 0.0598 - val_accuracy: 0.9767\n",
      "Epoch 628/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9797 - val_loss: 0.0598 - val_accuracy: 0.9775\n",
      "Epoch 629/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9799 - val_loss: 0.0538 - val_accuracy: 0.9788\n",
      "Epoch 630/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9796 - val_loss: 0.0584 - val_accuracy: 0.9767\n",
      "Epoch 631/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9763\n",
      "Epoch 632/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9803 - val_loss: 0.0580 - val_accuracy: 0.9769\n",
      "Epoch 633/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9806 - val_loss: 0.0638 - val_accuracy: 0.9768\n",
      "Epoch 634/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.0536 - val_accuracy: 0.9769\n",
      "Epoch 635/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.0550 - val_accuracy: 0.9774\n",
      "Epoch 636/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0527 - val_accuracy: 0.9781\n",
      "Epoch 637/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9802 - val_loss: 0.0576 - val_accuracy: 0.9785\n",
      "Epoch 638/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9802 - val_loss: 0.0563 - val_accuracy: 0.9777\n",
      "Epoch 639/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9809 - val_loss: 0.0544 - val_accuracy: 0.9778\n",
      "Epoch 640/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9807 - val_loss: 0.0550 - val_accuracy: 0.9779\n",
      "Epoch 641/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0497 - val_accuracy: 0.9781\n",
      "Epoch 642/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9797 - val_loss: 0.0684 - val_accuracy: 0.9753\n",
      "Epoch 643/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9807 - val_loss: 0.0637 - val_accuracy: 0.9761\n",
      "Epoch 644/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9802 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
      "Epoch 645/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9796 - val_loss: 0.0565 - val_accuracy: 0.9780\n",
      "Epoch 646/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9817 - val_loss: 0.0537 - val_accuracy: 0.9782\n",
      "Epoch 647/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9808 - val_loss: 0.0535 - val_accuracy: 0.9787\n",
      "Epoch 648/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9805 - val_loss: 0.0683 - val_accuracy: 0.9754\n",
      "Epoch 649/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9801 - val_loss: 0.0575 - val_accuracy: 0.9770\n",
      "Epoch 650/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9809 - val_loss: 0.0819 - val_accuracy: 0.9721\n",
      "Epoch 651/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9813 - val_loss: 0.0586 - val_accuracy: 0.9770\n",
      "Epoch 652/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9804 - val_loss: 0.0613 - val_accuracy: 0.9766\n",
      "Epoch 653/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9811 - val_loss: 0.0560 - val_accuracy: 0.9779\n",
      "Epoch 654/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0529 - accuracy: 0.9812 - val_loss: 0.0562 - val_accuracy: 0.9765\n",
      "Epoch 655/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9800 - val_loss: 0.0648 - val_accuracy: 0.9764\n",
      "Epoch 656/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9817 - val_loss: 0.0604 - val_accuracy: 0.9761\n",
      "Epoch 657/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9805 - val_loss: 0.0702 - val_accuracy: 0.9753\n",
      "Epoch 658/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9798 - val_loss: 0.0700 - val_accuracy: 0.9757\n",
      "Epoch 659/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9804 - val_loss: 0.0536 - val_accuracy: 0.9776\n",
      "Epoch 660/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9811 - val_loss: 0.0675 - val_accuracy: 0.9750\n",
      "Epoch 661/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9807 - val_loss: 0.0550 - val_accuracy: 0.9774\n",
      "Epoch 662/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9808 - val_loss: 0.0552 - val_accuracy: 0.9780\n",
      "Epoch 663/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 0.0594 - val_accuracy: 0.9766\n",
      "Epoch 664/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9800 - val_loss: 0.0609 - val_accuracy: 0.9775\n",
      "Epoch 665/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0599 - val_accuracy: 0.9773\n",
      "Epoch 666/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9812 - val_loss: 0.0590 - val_accuracy: 0.9768\n",
      "Epoch 667/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9807 - val_loss: 0.0572 - val_accuracy: 0.9771\n",
      "Epoch 668/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9811 - val_loss: 0.0627 - val_accuracy: 0.9769\n",
      "Epoch 669/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9810 - val_loss: 0.0570 - val_accuracy: 0.9771\n",
      "Epoch 670/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9798 - val_loss: 0.0648 - val_accuracy: 0.9766\n",
      "Epoch 671/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9815 - val_loss: 0.0782 - val_accuracy: 0.9726\n",
      "Epoch 672/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9789 - val_loss: 0.0636 - val_accuracy: 0.9768\n",
      "Epoch 673/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9813 - val_loss: 0.0599 - val_accuracy: 0.9773\n",
      "Epoch 674/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 0.0646 - val_accuracy: 0.9755\n",
      "Epoch 675/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9799 - val_loss: 0.0563 - val_accuracy: 0.9777\n",
      "Epoch 676/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.0561 - val_accuracy: 0.9775\n",
      "Epoch 677/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9814 - val_loss: 0.0602 - val_accuracy: 0.9760\n",
      "Epoch 678/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.0668 - val_accuracy: 0.9754\n",
      "Epoch 679/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9803 - val_loss: 0.0531 - val_accuracy: 0.9780\n",
      "Epoch 680/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9809 - val_loss: 0.0617 - val_accuracy: 0.9770\n",
      "Epoch 681/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9819 - val_loss: 0.0542 - val_accuracy: 0.9785\n",
      "Epoch 682/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9808 - val_loss: 0.0583 - val_accuracy: 0.9779\n",
      "Epoch 683/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9811 - val_loss: 0.0583 - val_accuracy: 0.9780\n",
      "Epoch 684/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9809 - val_loss: 0.0763 - val_accuracy: 0.9726\n",
      "Epoch 685/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9807 - val_loss: 0.0577 - val_accuracy: 0.9782\n",
      "Epoch 686/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9802 - val_loss: 0.0584 - val_accuracy: 0.9773\n",
      "Epoch 687/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9805 - val_loss: 0.0608 - val_accuracy: 0.9781\n",
      "Epoch 688/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9807 - val_loss: 0.0536 - val_accuracy: 0.9785\n",
      "Epoch 689/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9808 - val_loss: 0.0598 - val_accuracy: 0.9763\n",
      "Epoch 690/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9809 - val_loss: 0.0587 - val_accuracy: 0.9767\n",
      "Epoch 691/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9815 - val_loss: 0.0599 - val_accuracy: 0.9773\n",
      "Epoch 692/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9806 - val_loss: 0.0596 - val_accuracy: 0.9768\n",
      "Epoch 693/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.0529 - val_accuracy: 0.9785\n",
      "Epoch 694/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9815 - val_loss: 0.0683 - val_accuracy: 0.9757\n",
      "Epoch 695/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9811 - val_loss: 0.0569 - val_accuracy: 0.9775\n",
      "Epoch 696/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9816 - val_loss: 0.0755 - val_accuracy: 0.9744\n",
      "Epoch 697/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9808 - val_loss: 0.0596 - val_accuracy: 0.9778\n",
      "Epoch 698/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9814 - val_loss: 0.0708 - val_accuracy: 0.9747\n",
      "Epoch 699/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9800 - val_loss: 0.0576 - val_accuracy: 0.9765\n",
      "Epoch 700/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9818 - val_loss: 0.0628 - val_accuracy: 0.9769\n",
      "Epoch 701/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9809 - val_loss: 0.0606 - val_accuracy: 0.9770\n",
      "Epoch 702/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9811 - val_loss: 0.0645 - val_accuracy: 0.9764\n",
      "Epoch 703/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9820 - val_loss: 0.0551 - val_accuracy: 0.9790\n",
      "Epoch 704/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0528 - accuracy: 0.9807 - val_loss: 0.0665 - val_accuracy: 0.9759\n",
      "Epoch 705/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9818 - val_loss: 0.0671 - val_accuracy: 0.9754\n",
      "Epoch 706/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9806 - val_loss: 0.0669 - val_accuracy: 0.9750\n",
      "Epoch 707/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.9794 - val_loss: 0.0588 - val_accuracy: 0.9767\n",
      "Epoch 708/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0528 - accuracy: 0.9804 - val_loss: 0.0665 - val_accuracy: 0.9756\n",
      "Epoch 709/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 0.0589 - val_accuracy: 0.9777\n",
      "Epoch 710/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9809 - val_loss: 0.0630 - val_accuracy: 0.9763\n",
      "Epoch 711/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.0549 - val_accuracy: 0.9781\n",
      "Epoch 712/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9806 - val_loss: 0.0623 - val_accuracy: 0.9769\n",
      "Epoch 713/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0514 - accuracy: 0.9814 - val_loss: 0.0544 - val_accuracy: 0.9776\n",
      "Epoch 714/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9809 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
      "Epoch 715/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 0.0639 - val_accuracy: 0.9767\n",
      "Epoch 716/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.0674 - val_accuracy: 0.9756\n",
      "Epoch 717/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9812 - val_loss: 0.0542 - val_accuracy: 0.9778\n",
      "Epoch 718/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9822 - val_loss: 0.0599 - val_accuracy: 0.9777\n",
      "Epoch 719/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9821 - val_loss: 0.0588 - val_accuracy: 0.9782\n",
      "Epoch 720/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9805 - val_loss: 0.0542 - val_accuracy: 0.9785\n",
      "Epoch 721/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9803 - val_loss: 0.0600 - val_accuracy: 0.9773\n",
      "Epoch 722/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0569 - val_accuracy: 0.9769\n",
      "Epoch 723/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9819 - val_loss: 0.0610 - val_accuracy: 0.9775\n",
      "Epoch 724/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9807 - val_loss: 0.0547 - val_accuracy: 0.9785\n",
      "Epoch 725/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9812 - val_loss: 0.0711 - val_accuracy: 0.9746\n",
      "Epoch 726/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 0.0558 - val_accuracy: 0.9782\n",
      "Epoch 727/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9815 - val_loss: 0.0608 - val_accuracy: 0.9775\n",
      "Epoch 728/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9805 - val_loss: 0.0587 - val_accuracy: 0.9769\n",
      "Epoch 729/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9804 - val_loss: 0.0648 - val_accuracy: 0.9758\n",
      "Epoch 730/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9819 - val_loss: 0.0578 - val_accuracy: 0.9777\n",
      "Epoch 731/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9810 - val_loss: 0.0546 - val_accuracy: 0.9776\n",
      "Epoch 732/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0546 - val_accuracy: 0.9774\n",
      "Epoch 733/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9806 - val_loss: 0.0523 - val_accuracy: 0.9768\n",
      "Epoch 734/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9817 - val_loss: 0.0616 - val_accuracy: 0.9771\n",
      "Epoch 735/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9799 - val_loss: 0.0619 - val_accuracy: 0.9778\n",
      "Epoch 736/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9816 - val_loss: 0.0625 - val_accuracy: 0.9773\n",
      "Epoch 737/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9811 - val_loss: 0.0575 - val_accuracy: 0.9778\n",
      "Epoch 738/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9819 - val_loss: 0.0630 - val_accuracy: 0.9769\n",
      "Epoch 739/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9813 - val_loss: 0.0681 - val_accuracy: 0.9751\n",
      "Epoch 740/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9817 - val_loss: 0.0641 - val_accuracy: 0.9770\n",
      "Epoch 741/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.0608 - val_accuracy: 0.9773\n",
      "Epoch 742/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9814 - val_loss: 0.0581 - val_accuracy: 0.9777\n",
      "Epoch 743/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9810 - val_loss: 0.0666 - val_accuracy: 0.9759\n",
      "Epoch 744/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9820 - val_loss: 0.0580 - val_accuracy: 0.9781\n",
      "Epoch 745/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 0.0629 - val_accuracy: 0.9763\n",
      "Epoch 746/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9818 - val_loss: 0.0581 - val_accuracy: 0.9784\n",
      "Epoch 747/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9815 - val_loss: 0.0618 - val_accuracy: 0.9769\n",
      "Epoch 748/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9811 - val_loss: 0.0683 - val_accuracy: 0.9766\n",
      "Epoch 749/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9820 - val_loss: 0.0569 - val_accuracy: 0.9778\n",
      "Epoch 750/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9811 - val_loss: 0.0661 - val_accuracy: 0.9758\n",
      "Epoch 751/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9805 - val_loss: 0.0649 - val_accuracy: 0.9760\n",
      "Epoch 752/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9819 - val_loss: 0.0642 - val_accuracy: 0.9766\n",
      "Epoch 753/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9818 - val_loss: 0.0619 - val_accuracy: 0.9769\n",
      "Epoch 754/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9807 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
      "Epoch 755/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9815 - val_loss: 0.0657 - val_accuracy: 0.9757\n",
      "Epoch 756/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9765\n",
      "Epoch 757/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9815 - val_loss: 0.0648 - val_accuracy: 0.9769\n",
      "Epoch 758/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9810 - val_loss: 0.0571 - val_accuracy: 0.9770\n",
      "Epoch 759/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9805 - val_loss: 0.0571 - val_accuracy: 0.9776\n",
      "Epoch 760/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9810 - val_loss: 0.0603 - val_accuracy: 0.9778\n",
      "Epoch 761/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9815 - val_loss: 0.0562 - val_accuracy: 0.9781\n",
      "Epoch 762/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9812 - val_loss: 0.0564 - val_accuracy: 0.9774\n",
      "Epoch 763/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9813 - val_loss: 0.0615 - val_accuracy: 0.9773\n",
      "Epoch 764/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9815 - val_loss: 0.0525 - val_accuracy: 0.9788\n",
      "Epoch 765/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9819 - val_loss: 0.0635 - val_accuracy: 0.9767\n",
      "Epoch 766/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9804 - val_loss: 0.0528 - val_accuracy: 0.9773\n",
      "Epoch 767/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9816 - val_loss: 0.0535 - val_accuracy: 0.9777\n",
      "Epoch 768/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 0.0613 - val_accuracy: 0.9775\n",
      "Epoch 769/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9815 - val_loss: 0.0637 - val_accuracy: 0.9767\n",
      "Epoch 770/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9813 - val_loss: 0.0601 - val_accuracy: 0.9765\n",
      "Epoch 771/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9814 - val_loss: 0.0663 - val_accuracy: 0.9770\n",
      "Epoch 772/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9818 - val_loss: 0.0557 - val_accuracy: 0.9777\n",
      "Epoch 773/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9807 - val_loss: 0.0613 - val_accuracy: 0.9761\n",
      "Epoch 774/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9816 - val_loss: 0.0536 - val_accuracy: 0.9780\n",
      "Epoch 775/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9819 - val_loss: 0.0619 - val_accuracy: 0.9773\n",
      "Epoch 776/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9819 - val_loss: 0.0548 - val_accuracy: 0.9790\n",
      "Epoch 777/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9808 - val_loss: 0.0574 - val_accuracy: 0.9781\n",
      "Epoch 778/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9809 - val_loss: 0.0622 - val_accuracy: 0.9763\n",
      "Epoch 779/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9815 - val_loss: 0.0653 - val_accuracy: 0.9763\n",
      "Epoch 780/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9818 - val_loss: 0.0574 - val_accuracy: 0.9769\n",
      "Epoch 781/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.0609 - val_accuracy: 0.9761\n",
      "Epoch 782/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9815 - val_loss: 0.0601 - val_accuracy: 0.9774\n",
      "Epoch 783/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9812 - val_loss: 0.0615 - val_accuracy: 0.9771\n",
      "Epoch 784/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9823 - val_loss: 0.0605 - val_accuracy: 0.9774\n",
      "Epoch 785/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9819 - val_loss: 0.0775 - val_accuracy: 0.9741\n",
      "Epoch 786/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9813 - val_loss: 0.0558 - val_accuracy: 0.9778\n",
      "Epoch 787/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9809 - val_loss: 0.0583 - val_accuracy: 0.9765\n",
      "Epoch 788/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9813 - val_loss: 0.0622 - val_accuracy: 0.9763\n",
      "Epoch 789/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9817 - val_loss: 0.0541 - val_accuracy: 0.9790\n",
      "Epoch 790/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9827 - val_loss: 0.0670 - val_accuracy: 0.9747\n",
      "Epoch 791/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9808 - val_loss: 0.0587 - val_accuracy: 0.9771\n",
      "Epoch 792/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9816 - val_loss: 0.0750 - val_accuracy: 0.9747\n",
      "Epoch 793/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9803 - val_loss: 0.0609 - val_accuracy: 0.9770\n",
      "Epoch 794/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9816 - val_loss: 0.0567 - val_accuracy: 0.9771\n",
      "Epoch 795/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9818 - val_loss: 0.0583 - val_accuracy: 0.9776\n",
      "Epoch 796/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9827 - val_loss: 0.0531 - val_accuracy: 0.9786\n",
      "Epoch 797/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9812 - val_loss: 0.0634 - val_accuracy: 0.9763\n",
      "Epoch 798/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9814 - val_loss: 0.0585 - val_accuracy: 0.9774\n",
      "Epoch 799/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9814 - val_loss: 0.0551 - val_accuracy: 0.9775\n",
      "Epoch 800/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9813 - val_loss: 0.0596 - val_accuracy: 0.9769\n",
      "Epoch 801/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.0588 - val_accuracy: 0.9778\n",
      "Epoch 802/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9827 - val_loss: 0.0542 - val_accuracy: 0.9781\n",
      "Epoch 803/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9828 - val_loss: 0.0556 - val_accuracy: 0.9788\n",
      "Epoch 804/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9809 - val_loss: 0.0652 - val_accuracy: 0.9763\n",
      "Epoch 805/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9818 - val_loss: 0.0620 - val_accuracy: 0.9770\n",
      "Epoch 806/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9821 - val_loss: 0.0558 - val_accuracy: 0.9776\n",
      "Epoch 807/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 0.0598 - val_accuracy: 0.9774\n",
      "Epoch 808/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9822 - val_loss: 0.0666 - val_accuracy: 0.9769\n",
      "Epoch 809/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9806 - val_loss: 0.0581 - val_accuracy: 0.9781\n",
      "Epoch 810/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9818 - val_loss: 0.0633 - val_accuracy: 0.9767\n",
      "Epoch 811/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9812 - val_loss: 0.0585 - val_accuracy: 0.9773\n",
      "Epoch 812/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 0.0593 - val_accuracy: 0.9785\n",
      "Epoch 813/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9815 - val_loss: 0.0549 - val_accuracy: 0.9778\n",
      "Epoch 814/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9819 - val_loss: 0.0563 - val_accuracy: 0.9777\n",
      "Epoch 815/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9822 - val_loss: 0.0563 - val_accuracy: 0.9785\n",
      "Epoch 816/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 0.0571 - val_accuracy: 0.9778\n",
      "Epoch 817/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 0.0554 - val_accuracy: 0.9787\n",
      "Epoch 818/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9818 - val_loss: 0.0760 - val_accuracy: 0.9755\n",
      "Epoch 819/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9811 - val_loss: 0.0650 - val_accuracy: 0.9769\n",
      "Epoch 820/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9814 - val_loss: 0.0546 - val_accuracy: 0.9781\n",
      "Epoch 821/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9817 - val_loss: 0.0641 - val_accuracy: 0.9775\n",
      "Epoch 822/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9816 - val_loss: 0.0545 - val_accuracy: 0.9787\n",
      "Epoch 823/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9819 - val_loss: 0.0582 - val_accuracy: 0.9780\n",
      "Epoch 824/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9822 - val_loss: 0.0583 - val_accuracy: 0.9777\n",
      "Epoch 825/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9822 - val_loss: 0.0517 - val_accuracy: 0.9777\n",
      "Epoch 826/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9819 - val_loss: 0.0597 - val_accuracy: 0.9780\n",
      "Epoch 827/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9818 - val_loss: 0.0598 - val_accuracy: 0.9774\n",
      "Epoch 828/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9819 - val_loss: 0.0554 - val_accuracy: 0.9778\n",
      "Epoch 829/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9813 - val_loss: 0.0573 - val_accuracy: 0.9785\n",
      "Epoch 830/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9821 - val_loss: 0.0546 - val_accuracy: 0.9778\n",
      "Epoch 831/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9816 - val_loss: 0.0562 - val_accuracy: 0.9775\n",
      "Epoch 832/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 0.0570 - val_accuracy: 0.9775\n",
      "Epoch 833/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9818 - val_loss: 0.0581 - val_accuracy: 0.9775\n",
      "Epoch 834/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9814 - val_loss: 0.0666 - val_accuracy: 0.9751\n",
      "Epoch 835/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9808 - val_loss: 0.0605 - val_accuracy: 0.9766\n",
      "Epoch 836/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9825 - val_loss: 0.0688 - val_accuracy: 0.9760\n",
      "Epoch 837/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9826 - val_loss: 0.0601 - val_accuracy: 0.9774\n",
      "Epoch 838/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9816 - val_loss: 0.0602 - val_accuracy: 0.9776\n",
      "Epoch 839/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9820 - val_loss: 0.0662 - val_accuracy: 0.9766\n",
      "Epoch 840/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9812 - val_loss: 0.0593 - val_accuracy: 0.9768\n",
      "Epoch 841/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9830 - val_loss: 0.0522 - val_accuracy: 0.9791\n",
      "Epoch 842/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9828 - val_loss: 0.0575 - val_accuracy: 0.9779\n",
      "Epoch 843/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.0627 - val_accuracy: 0.9777\n",
      "Epoch 844/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9818 - val_loss: 0.0614 - val_accuracy: 0.9770\n",
      "Epoch 845/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9819 - val_loss: 0.0561 - val_accuracy: 0.9778\n",
      "Epoch 846/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9819 - val_loss: 0.0678 - val_accuracy: 0.9759\n",
      "Epoch 847/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9822 - val_loss: 0.0601 - val_accuracy: 0.9787\n",
      "Epoch 848/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9819 - val_loss: 0.0614 - val_accuracy: 0.9768\n",
      "Epoch 849/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9811 - val_loss: 0.0677 - val_accuracy: 0.9756\n",
      "Epoch 850/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9817 - val_loss: 0.0621 - val_accuracy: 0.9767\n",
      "Epoch 851/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 0.0586 - val_accuracy: 0.9781\n",
      "Epoch 852/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9820 - val_loss: 0.0572 - val_accuracy: 0.9761\n",
      "Epoch 853/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9827 - val_loss: 0.0549 - val_accuracy: 0.9763\n",
      "Epoch 854/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9819 - val_loss: 0.0602 - val_accuracy: 0.9777\n",
      "Epoch 855/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9818 - val_loss: 0.0663 - val_accuracy: 0.9770\n",
      "Epoch 856/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9814 - val_loss: 0.0559 - val_accuracy: 0.9786\n",
      "Epoch 857/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9813 - val_loss: 0.0603 - val_accuracy: 0.9774\n",
      "Epoch 858/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9827 - val_loss: 0.0613 - val_accuracy: 0.9771\n",
      "Epoch 859/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9814 - val_loss: 0.0569 - val_accuracy: 0.9765\n",
      "Epoch 860/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9828 - val_loss: 0.0604 - val_accuracy: 0.9771\n",
      "Epoch 861/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9825 - val_loss: 0.0620 - val_accuracy: 0.9774\n",
      "Epoch 862/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9823 - val_loss: 0.0547 - val_accuracy: 0.9774\n",
      "Epoch 863/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9818 - val_loss: 0.0613 - val_accuracy: 0.9773\n",
      "Epoch 864/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.0675 - val_accuracy: 0.9761\n",
      "Epoch 865/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9805 - val_loss: 0.0611 - val_accuracy: 0.9776\n",
      "Epoch 866/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9811 - val_loss: 0.0625 - val_accuracy: 0.9776\n",
      "Epoch 867/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.0624 - val_accuracy: 0.9775\n",
      "Epoch 868/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9819 - val_loss: 0.0642 - val_accuracy: 0.9764\n",
      "Epoch 869/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9818 - val_loss: 0.0534 - val_accuracy: 0.9782\n",
      "Epoch 870/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9817 - val_loss: 0.0611 - val_accuracy: 0.9774\n",
      "Epoch 871/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9831 - val_loss: 0.0625 - val_accuracy: 0.9780\n",
      "Epoch 872/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9814 - val_loss: 0.0645 - val_accuracy: 0.9764\n",
      "Epoch 873/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9821 - val_loss: 0.0694 - val_accuracy: 0.9761\n",
      "Epoch 874/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9821 - val_loss: 0.0697 - val_accuracy: 0.9766\n",
      "Epoch 875/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9824 - val_loss: 0.0668 - val_accuracy: 0.9756\n",
      "Epoch 876/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9814 - val_loss: 0.0616 - val_accuracy: 0.9779\n",
      "Epoch 877/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9828 - val_loss: 0.0615 - val_accuracy: 0.9766\n",
      "Epoch 878/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9817 - val_loss: 0.0671 - val_accuracy: 0.9759\n",
      "Epoch 879/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 0.0631 - val_accuracy: 0.9779\n",
      "Epoch 880/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9825 - val_loss: 0.0547 - val_accuracy: 0.9782\n",
      "Epoch 881/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9812 - val_loss: 0.0592 - val_accuracy: 0.9786\n",
      "Epoch 882/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9830 - val_loss: 0.0602 - val_accuracy: 0.9773\n",
      "Epoch 883/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9826 - val_loss: 0.0544 - val_accuracy: 0.9773\n",
      "Epoch 884/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9822 - val_loss: 0.0586 - val_accuracy: 0.9775\n",
      "Epoch 885/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9820 - val_loss: 0.0759 - val_accuracy: 0.9755\n",
      "Epoch 886/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9815 - val_loss: 0.0646 - val_accuracy: 0.9771\n",
      "Epoch 887/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9809 - val_loss: 0.0535 - val_accuracy: 0.9785\n",
      "Epoch 888/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9824 - val_loss: 0.0564 - val_accuracy: 0.9779\n",
      "Epoch 889/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9823 - val_loss: 0.0542 - val_accuracy: 0.9785\n",
      "Epoch 890/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9821 - val_loss: 0.0577 - val_accuracy: 0.9779\n",
      "Epoch 891/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9819 - val_loss: 0.0648 - val_accuracy: 0.9779\n",
      "Epoch 892/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9814 - val_loss: 0.0573 - val_accuracy: 0.9778\n",
      "Epoch 893/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9801 - val_loss: 0.0598 - val_accuracy: 0.9784\n",
      "Epoch 894/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9820 - val_loss: 0.0570 - val_accuracy: 0.9785\n",
      "Epoch 895/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9826 - val_loss: 0.0687 - val_accuracy: 0.9766\n",
      "Epoch 896/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9828 - val_loss: 0.0570 - val_accuracy: 0.9768\n",
      "Epoch 897/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9817 - val_loss: 0.0640 - val_accuracy: 0.9771\n",
      "Epoch 898/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9823 - val_loss: 0.0613 - val_accuracy: 0.9774\n",
      "Epoch 899/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.0664 - val_accuracy: 0.9765\n",
      "Epoch 900/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9825 - val_loss: 0.0554 - val_accuracy: 0.9784\n",
      "Epoch 901/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9826 - val_loss: 0.0611 - val_accuracy: 0.9770\n",
      "Epoch 902/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9816 - val_loss: 0.0558 - val_accuracy: 0.9773\n",
      "Epoch 903/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9818 - val_loss: 0.0695 - val_accuracy: 0.9759\n",
      "Epoch 904/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9816 - val_loss: 0.0598 - val_accuracy: 0.9781\n",
      "Epoch 905/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9825 - val_loss: 0.0571 - val_accuracy: 0.9781\n",
      "Epoch 906/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.0579 - val_accuracy: 0.9775\n",
      "Epoch 907/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9813 - val_loss: 0.0564 - val_accuracy: 0.9770\n",
      "Epoch 908/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.0556 - val_accuracy: 0.9778\n",
      "Epoch 909/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9818 - val_loss: 0.0545 - val_accuracy: 0.9774\n",
      "Epoch 910/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9823 - val_loss: 0.0548 - val_accuracy: 0.9778\n",
      "Epoch 911/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9823 - val_loss: 0.0580 - val_accuracy: 0.9775\n",
      "Epoch 912/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9817 - val_loss: 0.0592 - val_accuracy: 0.9774\n",
      "Epoch 913/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9823 - val_loss: 0.0627 - val_accuracy: 0.9763\n",
      "Epoch 914/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9814 - val_loss: 0.0738 - val_accuracy: 0.9760\n",
      "Epoch 915/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9815 - val_loss: 0.0674 - val_accuracy: 0.9766\n",
      "Epoch 916/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.0583 - val_accuracy: 0.9779\n",
      "Epoch 917/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9826 - val_loss: 0.0518 - val_accuracy: 0.9792\n",
      "Epoch 918/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 0.0624 - val_accuracy: 0.9771\n",
      "Epoch 919/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9822 - val_loss: 0.0648 - val_accuracy: 0.9776\n",
      "Epoch 920/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9823 - val_loss: 0.0664 - val_accuracy: 0.9767\n",
      "Epoch 921/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9813 - val_loss: 0.0531 - val_accuracy: 0.9785\n",
      "Epoch 922/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9822 - val_loss: 0.0594 - val_accuracy: 0.9784\n",
      "Epoch 923/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9819 - val_loss: 0.0552 - val_accuracy: 0.9782\n",
      "Epoch 924/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9822 - val_loss: 0.0671 - val_accuracy: 0.9765\n",
      "Epoch 925/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9830 - val_loss: 0.0612 - val_accuracy: 0.9771\n",
      "Epoch 926/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9827 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
      "Epoch 927/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9819 - val_loss: 0.0588 - val_accuracy: 0.9779\n",
      "Epoch 928/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9817 - val_loss: 0.0626 - val_accuracy: 0.9775\n",
      "Epoch 929/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9834 - val_loss: 0.0537 - val_accuracy: 0.9780\n",
      "Epoch 930/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9807 - val_loss: 0.0560 - val_accuracy: 0.9779\n",
      "Epoch 931/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9832 - val_loss: 0.0618 - val_accuracy: 0.9769\n",
      "Epoch 932/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9823 - val_loss: 0.0583 - val_accuracy: 0.9775\n",
      "Epoch 933/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9817 - val_loss: 0.0764 - val_accuracy: 0.9747\n",
      "Epoch 934/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9828 - val_loss: 0.0571 - val_accuracy: 0.9777\n",
      "Epoch 935/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9830 - val_loss: 0.0667 - val_accuracy: 0.9764\n",
      "Epoch 936/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9822 - val_loss: 0.0621 - val_accuracy: 0.9784\n",
      "Epoch 937/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9825 - val_loss: 0.0619 - val_accuracy: 0.9776\n",
      "Epoch 938/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9820 - val_loss: 0.0592 - val_accuracy: 0.9775\n",
      "Epoch 939/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 0.0620 - val_accuracy: 0.9775\n",
      "Epoch 940/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9817 - val_loss: 0.0559 - val_accuracy: 0.9787\n",
      "Epoch 941/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9823 - val_loss: 0.0598 - val_accuracy: 0.9784\n",
      "Epoch 942/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9819 - val_loss: 0.0578 - val_accuracy: 0.9778\n",
      "Epoch 943/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9824 - val_loss: 0.0711 - val_accuracy: 0.9763\n",
      "Epoch 944/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9814 - val_loss: 0.0600 - val_accuracy: 0.9775\n",
      "Epoch 945/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9815 - val_loss: 0.0623 - val_accuracy: 0.9777\n",
      "Epoch 946/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 0.0648 - val_accuracy: 0.9766\n",
      "Epoch 947/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9824 - val_loss: 0.0583 - val_accuracy: 0.9774\n",
      "Epoch 948/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9823 - val_loss: 0.0648 - val_accuracy: 0.9767\n",
      "Epoch 949/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 0.0662 - val_accuracy: 0.9760\n",
      "Epoch 950/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9821 - val_loss: 0.0679 - val_accuracy: 0.9767\n",
      "Epoch 951/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9827 - val_loss: 0.0621 - val_accuracy: 0.9763\n",
      "Epoch 952/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9818 - val_loss: 0.0562 - val_accuracy: 0.9781\n",
      "Epoch 953/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9826 - val_loss: 0.0596 - val_accuracy: 0.9770\n",
      "Epoch 954/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9823 - val_loss: 0.0583 - val_accuracy: 0.9777\n",
      "Epoch 955/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9829 - val_loss: 0.0761 - val_accuracy: 0.9749\n",
      "Epoch 956/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9814 - val_loss: 0.0624 - val_accuracy: 0.9777\n",
      "Epoch 957/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0468 - accuracy: 0.9829 - val_loss: 0.0680 - val_accuracy: 0.9760\n",
      "Epoch 958/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9821 - val_loss: 0.0583 - val_accuracy: 0.9769\n",
      "Epoch 959/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.0598 - val_accuracy: 0.9780\n",
      "Epoch 960/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9836 - val_loss: 0.0570 - val_accuracy: 0.9778\n",
      "Epoch 961/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9824 - val_loss: 0.0564 - val_accuracy: 0.9782\n",
      "Epoch 962/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 0.0608 - val_accuracy: 0.9767\n",
      "Epoch 963/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9834 - val_loss: 0.0545 - val_accuracy: 0.9788\n",
      "Epoch 964/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9823 - val_loss: 0.0586 - val_accuracy: 0.9767\n",
      "Epoch 965/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9821 - val_loss: 0.0607 - val_accuracy: 0.9774\n",
      "Epoch 966/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9829 - val_loss: 0.0607 - val_accuracy: 0.9776\n",
      "Epoch 967/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9828 - val_loss: 0.0640 - val_accuracy: 0.9763\n",
      "Epoch 968/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9827 - val_loss: 0.0559 - val_accuracy: 0.9785\n",
      "Epoch 969/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9826 - val_loss: 0.0584 - val_accuracy: 0.9769\n",
      "Epoch 970/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9827 - val_loss: 0.0628 - val_accuracy: 0.9771\n",
      "Epoch 971/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9821 - val_loss: 0.0560 - val_accuracy: 0.9775\n",
      "Epoch 972/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9818 - val_loss: 0.0626 - val_accuracy: 0.9771\n",
      "Epoch 973/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9820 - val_loss: 0.0560 - val_accuracy: 0.9774\n",
      "Epoch 974/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9836 - val_loss: 0.0621 - val_accuracy: 0.9767\n",
      "Epoch 975/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 0.0651 - val_accuracy: 0.9766\n",
      "Epoch 976/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9820 - val_loss: 0.0607 - val_accuracy: 0.9768\n",
      "Epoch 977/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9833 - val_loss: 0.0677 - val_accuracy: 0.9769\n",
      "Epoch 978/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9830 - val_loss: 0.0636 - val_accuracy: 0.9766\n",
      "Epoch 979/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9818 - val_loss: 0.0655 - val_accuracy: 0.9765\n",
      "Epoch 980/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9824 - val_loss: 0.0651 - val_accuracy: 0.9770\n",
      "Epoch 981/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9829 - val_loss: 0.0622 - val_accuracy: 0.9781\n",
      "Epoch 982/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9832 - val_loss: 0.0630 - val_accuracy: 0.9782\n",
      "Epoch 983/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9823 - val_loss: 0.0629 - val_accuracy: 0.9777\n",
      "Epoch 984/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9832 - val_loss: 0.0736 - val_accuracy: 0.9755\n",
      "Epoch 985/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9819 - val_loss: 0.0614 - val_accuracy: 0.9771\n",
      "Epoch 986/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9826 - val_loss: 0.0634 - val_accuracy: 0.9777\n",
      "Epoch 987/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9767\n",
      "Epoch 988/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9832 - val_loss: 0.0624 - val_accuracy: 0.9775\n",
      "Epoch 989/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9826 - val_loss: 0.0552 - val_accuracy: 0.9782\n",
      "Epoch 990/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9824 - val_loss: 0.0547 - val_accuracy: 0.9781\n",
      "Epoch 991/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9815 - val_loss: 0.0633 - val_accuracy: 0.9773\n",
      "Epoch 992/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9830 - val_loss: 0.0597 - val_accuracy: 0.9771\n",
      "Epoch 993/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9829 - val_loss: 0.0648 - val_accuracy: 0.9766\n",
      "Epoch 994/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9825 - val_loss: 0.0567 - val_accuracy: 0.9777\n",
      "Epoch 995/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9830 - val_loss: 0.0620 - val_accuracy: 0.9774\n",
      "Epoch 996/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9830 - val_loss: 0.0682 - val_accuracy: 0.9768\n",
      "Epoch 997/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 0.0581 - val_accuracy: 0.9776\n",
      "Epoch 998/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9827 - val_loss: 0.0594 - val_accuracy: 0.9778\n",
      "Epoch 999/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9827 - val_loss: 0.0711 - val_accuracy: 0.9765\n",
      "Epoch 1000/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9829 - val_loss: 0.0620 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 996us/step\n",
      "xtrain: (85868, 59), ytrain: (85868,)\n",
      "xvalid: (9011, 59), yvalid: (9011,)\n",
      "xtest: (9012, 59), ytest: (9012,)\n",
      "\n",
      "classification_report_Fold=2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Normal 0       1.00      0.98      0.99      8725\n",
      " Anomalous 1       0.58      0.88      0.70       287\n",
      "\n",
      "    accuracy                           0.98      9012\n",
      "   macro avg       0.79      0.93      0.84      9012\n",
      "weighted avg       0.98      0.98      0.98      9012\n",
      "\n",
      "confusion_matrix_Fold=2:\n",
      "\n",
      "True Negatives:  8540\n",
      "False Positives:  185\n",
      "False Negatives:  35\n",
      "True Positives:  252\n",
      "accuracy_score_Fold=2:\n",
      " 8792 \n",
      "\n",
      "End running time Fold=2: 210214_095011 ,-------------------------- \n",
      "\n",
      "Start running time Data Augmentation_Fold=3: 210214_095011 ,-------------------------- \n",
      "\n",
      "Data Augmentation MSE Label1, iter2==> mean: 1.0324411145373457e-05, min: 2.940464134534943e-06, max: 0.00013972056179266794\n",
      "End running time Data Augmentation_Fold=3: 210214_100939 ,-------------------------- \n",
      "\n",
      "\n",
      " Start running time Fold=3: 210214_100939 ,-------------------------- \n",
      "\n",
      "\n",
      " Number of Final yXtrain_Fold=3 labeled 0: 69796\n",
      "Number of Final yXtrain_Fold=3 labeled 1: 16072\n",
      "Number of Final yXtrain_Fold=3 labeled 2: 0 \n",
      "\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.4825 - accuracy: 0.8081 - val_loss: 0.2389 - val_accuracy: 0.9613\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8230 - val_loss: 0.2337 - val_accuracy: 0.9564\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8231 - val_loss: 0.2426 - val_accuracy: 0.9514\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8238 - val_loss: 0.2085 - val_accuracy: 0.9542\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8269 - val_loss: 0.2245 - val_accuracy: 0.9519\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8256 - val_loss: 0.2208 - val_accuracy: 0.9517\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8271 - val_loss: 0.2079 - val_accuracy: 0.9526\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8316 - val_loss: 0.2107 - val_accuracy: 0.9497\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8309 - val_loss: 0.2292 - val_accuracy: 0.9442\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8308 - val_loss: 0.2382 - val_accuracy: 0.9438\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8335 - val_loss: 0.2075 - val_accuracy: 0.9471\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8331 - val_loss: 0.2169 - val_accuracy: 0.9427\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8347 - val_loss: 0.2113 - val_accuracy: 0.9447\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8359 - val_loss: 0.2200 - val_accuracy: 0.9412\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8373 - val_loss: 0.2060 - val_accuracy: 0.9414\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8377 - val_loss: 0.2132 - val_accuracy: 0.9410\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8399 - val_loss: 0.1964 - val_accuracy: 0.9453\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8407 - val_loss: 0.2028 - val_accuracy: 0.9420\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8396 - val_loss: 0.1786 - val_accuracy: 0.9507\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8427 - val_loss: 0.2167 - val_accuracy: 0.9382\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8471 - val_loss: 0.1759 - val_accuracy: 0.9486\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8474 - val_loss: 0.1763 - val_accuracy: 0.9500\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8490 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8512 - val_loss: 0.1902 - val_accuracy: 0.9403\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8512 - val_loss: 0.1927 - val_accuracy: 0.9410\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8529 - val_loss: 0.1983 - val_accuracy: 0.9390\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8544 - val_loss: 0.2121 - val_accuracy: 0.9341\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.8563 - val_loss: 0.1943 - val_accuracy: 0.9411\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8560 - val_loss: 0.1652 - val_accuracy: 0.9511\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8588 - val_loss: 0.1984 - val_accuracy: 0.9362\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8593 - val_loss: 0.1900 - val_accuracy: 0.9400\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8605 - val_loss: 0.1947 - val_accuracy: 0.9364\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8640 - val_loss: 0.1954 - val_accuracy: 0.9366\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2943 - accuracy: 0.8644 - val_loss: 0.1972 - val_accuracy: 0.9325\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.8644 - val_loss: 0.1638 - val_accuracy: 0.9494\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.8657 - val_loss: 0.1728 - val_accuracy: 0.9435\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.8691 - val_loss: 0.1624 - val_accuracy: 0.9492\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.8694 - val_loss: 0.1924 - val_accuracy: 0.9357\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.8716 - val_loss: 0.1731 - val_accuracy: 0.9418\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8715 - val_loss: 0.1690 - val_accuracy: 0.9437\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.8749 - val_loss: 0.1511 - val_accuracy: 0.9488\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8762 - val_loss: 0.1838 - val_accuracy: 0.9371\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.8779 - val_loss: 0.1600 - val_accuracy: 0.9454\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8788 - val_loss: 0.1798 - val_accuracy: 0.9377\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.8804 - val_loss: 0.1614 - val_accuracy: 0.9426\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.8806 - val_loss: 0.1657 - val_accuracy: 0.9401\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2526 - accuracy: 0.8821 - val_loss: 0.1648 - val_accuracy: 0.9410\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2469 - accuracy: 0.8840 - val_loss: 0.1683 - val_accuracy: 0.9390\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.8871 - val_loss: 0.1405 - val_accuracy: 0.9503\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.8890 - val_loss: 0.1392 - val_accuracy: 0.9522\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.8887 - val_loss: 0.1653 - val_accuracy: 0.9395\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2372 - accuracy: 0.8884 - val_loss: 0.1588 - val_accuracy: 0.9409\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.8933 - val_loss: 0.1563 - val_accuracy: 0.9418\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.8949 - val_loss: 0.1542 - val_accuracy: 0.9433\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.8986 - val_loss: 0.1624 - val_accuracy: 0.9379\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.8976 - val_loss: 0.1480 - val_accuracy: 0.9437\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.8997 - val_loss: 0.1309 - val_accuracy: 0.9534\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9030 - val_loss: 0.1328 - val_accuracy: 0.9516\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9030 - val_loss: 0.1376 - val_accuracy: 0.9513\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9062 - val_loss: 0.1379 - val_accuracy: 0.9493\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9083 - val_loss: 0.1509 - val_accuracy: 0.9424\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9109 - val_loss: 0.1509 - val_accuracy: 0.9416\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9090 - val_loss: 0.1424 - val_accuracy: 0.9470\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2023 - accuracy: 0.9142 - val_loss: 0.1400 - val_accuracy: 0.9464\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9149 - val_loss: 0.1275 - val_accuracy: 0.9525\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9152 - val_loss: 0.1246 - val_accuracy: 0.9528\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9169 - val_loss: 0.1474 - val_accuracy: 0.9415\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.9155 - val_loss: 0.1403 - val_accuracy: 0.9453\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9193 - val_loss: 0.1496 - val_accuracy: 0.9374\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9192 - val_loss: 0.1373 - val_accuracy: 0.9458\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.9216 - val_loss: 0.1208 - val_accuracy: 0.9536\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.9228 - val_loss: 0.1385 - val_accuracy: 0.9447\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9242 - val_loss: 0.1203 - val_accuracy: 0.9522\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.9222 - val_loss: 0.1189 - val_accuracy: 0.9525\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9243 - val_loss: 0.1080 - val_accuracy: 0.9578\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1776 - accuracy: 0.9278 - val_loss: 0.1073 - val_accuracy: 0.9583\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1766 - accuracy: 0.9282 - val_loss: 0.1225 - val_accuracy: 0.9513\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9282 - val_loss: 0.1072 - val_accuracy: 0.9571\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9291 - val_loss: 0.0965 - val_accuracy: 0.9605\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9291 - val_loss: 0.1169 - val_accuracy: 0.9536\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9319 - val_loss: 0.1003 - val_accuracy: 0.9599\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1685 - accuracy: 0.9314 - val_loss: 0.1154 - val_accuracy: 0.9538\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9334 - val_loss: 0.1097 - val_accuracy: 0.9554\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9332 - val_loss: 0.1051 - val_accuracy: 0.9568\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9328 - val_loss: 0.1180 - val_accuracy: 0.9501\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9353 - val_loss: 0.1041 - val_accuracy: 0.9566\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9349 - val_loss: 0.1052 - val_accuracy: 0.9556\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9385 - val_loss: 0.1029 - val_accuracy: 0.9573\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9374 - val_loss: 0.1102 - val_accuracy: 0.9534\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9386 - val_loss: 0.0984 - val_accuracy: 0.9591\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9383 - val_loss: 0.1083 - val_accuracy: 0.9548\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9404 - val_loss: 0.1120 - val_accuracy: 0.9524\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1507 - accuracy: 0.9421 - val_loss: 0.1154 - val_accuracy: 0.9514\n",
      "Epoch 94/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1531 - accuracy: 0.9391 - val_loss: 0.0979 - val_accuracy: 0.9578\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9414 - val_loss: 0.1148 - val_accuracy: 0.9506\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9421 - val_loss: 0.1148 - val_accuracy: 0.9486\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9421 - val_loss: 0.1085 - val_accuracy: 0.9534\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9427 - val_loss: 0.1003 - val_accuracy: 0.9569\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9425 - val_loss: 0.1136 - val_accuracy: 0.9504\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9445 - val_loss: 0.1094 - val_accuracy: 0.9531\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9444 - val_loss: 0.1185 - val_accuracy: 0.9495\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1414 - accuracy: 0.9456 - val_loss: 0.1000 - val_accuracy: 0.9556\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9445 - val_loss: 0.1058 - val_accuracy: 0.9552\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9436 - val_loss: 0.0995 - val_accuracy: 0.9571\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9462 - val_loss: 0.1131 - val_accuracy: 0.9509\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9445 - val_loss: 0.0935 - val_accuracy: 0.9596\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9478 - val_loss: 0.1026 - val_accuracy: 0.9551\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9474 - val_loss: 0.0987 - val_accuracy: 0.9581\n",
      "Epoch 109/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9471 - val_loss: 0.0894 - val_accuracy: 0.9619\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9483 - val_loss: 0.1053 - val_accuracy: 0.9546\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9482 - val_loss: 0.0865 - val_accuracy: 0.9629\n",
      "Epoch 112/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9495 - val_loss: 0.0943 - val_accuracy: 0.9581\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9484 - val_loss: 0.1050 - val_accuracy: 0.9542\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9487 - val_loss: 0.0972 - val_accuracy: 0.9573\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9492 - val_loss: 0.0883 - val_accuracy: 0.9608\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9505 - val_loss: 0.1229 - val_accuracy: 0.9464\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9499 - val_loss: 0.0840 - val_accuracy: 0.9626\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9505 - val_loss: 0.0877 - val_accuracy: 0.9616\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9506 - val_loss: 0.0785 - val_accuracy: 0.9639\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9487 - val_loss: 0.1026 - val_accuracy: 0.9561\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9526 - val_loss: 0.1135 - val_accuracy: 0.9506\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9526 - val_loss: 0.0937 - val_accuracy: 0.9591\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9505 - val_loss: 0.0901 - val_accuracy: 0.9599\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9526 - val_loss: 0.1067 - val_accuracy: 0.9528\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9523 - val_loss: 0.0887 - val_accuracy: 0.9610\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9533 - val_loss: 0.0904 - val_accuracy: 0.9591\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9536 - val_loss: 0.0896 - val_accuracy: 0.9612\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9519 - val_loss: 0.0866 - val_accuracy: 0.9606\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9521 - val_loss: 0.0841 - val_accuracy: 0.9614\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9537 - val_loss: 0.0844 - val_accuracy: 0.9630\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9544 - val_loss: 0.0782 - val_accuracy: 0.9648\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9544 - val_loss: 0.0770 - val_accuracy: 0.9663\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9551 - val_loss: 0.1066 - val_accuracy: 0.9532\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9557 - val_loss: 0.0966 - val_accuracy: 0.9566\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1171 - accuracy: 0.9549 - val_loss: 0.0824 - val_accuracy: 0.9623\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9555 - val_loss: 0.0866 - val_accuracy: 0.9632\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9547 - val_loss: 0.0968 - val_accuracy: 0.9564\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9544 - val_loss: 0.0831 - val_accuracy: 0.9618\n",
      "Epoch 139/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9563 - val_loss: 0.0908 - val_accuracy: 0.9597\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9564 - val_loss: 0.0889 - val_accuracy: 0.9608\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9571 - val_loss: 0.0902 - val_accuracy: 0.9585\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9570 - val_loss: 0.0822 - val_accuracy: 0.9638\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1171 - accuracy: 0.9556 - val_loss: 0.0908 - val_accuracy: 0.9592\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9579 - val_loss: 0.0748 - val_accuracy: 0.9667\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9578 - val_loss: 0.1078 - val_accuracy: 0.9529\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9570 - val_loss: 0.0945 - val_accuracy: 0.9577\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9589 - val_loss: 0.0836 - val_accuracy: 0.9622\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9575 - val_loss: 0.0875 - val_accuracy: 0.9618\n",
      "Epoch 149/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1094 - accuracy: 0.9593 - val_loss: 0.0735 - val_accuracy: 0.9668\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9588 - val_loss: 0.0685 - val_accuracy: 0.9700\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9576 - val_loss: 0.0849 - val_accuracy: 0.9620\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.9602 - val_loss: 0.0984 - val_accuracy: 0.9564\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9601 - val_loss: 0.0798 - val_accuracy: 0.9644\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9589 - val_loss: 0.1003 - val_accuracy: 0.9551\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9589 - val_loss: 0.0921 - val_accuracy: 0.9587\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9592 - val_loss: 0.0895 - val_accuracy: 0.9603\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9603 - val_loss: 0.0795 - val_accuracy: 0.9653\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9600 - val_loss: 0.0791 - val_accuracy: 0.9648\n",
      "Epoch 159/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9598 - val_loss: 0.0899 - val_accuracy: 0.9596\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9612 - val_loss: 0.0779 - val_accuracy: 0.9649\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9606 - val_loss: 0.0785 - val_accuracy: 0.9647\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9601 - val_loss: 0.0850 - val_accuracy: 0.9626\n",
      "Epoch 163/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9605 - val_loss: 0.0723 - val_accuracy: 0.9675\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9617 - val_loss: 0.0796 - val_accuracy: 0.9637\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9606 - val_loss: 0.0854 - val_accuracy: 0.9622\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9617 - val_loss: 0.0714 - val_accuracy: 0.9668\n",
      "Epoch 167/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9626 - val_loss: 0.0801 - val_accuracy: 0.9635\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9611 - val_loss: 0.0911 - val_accuracy: 0.9598\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9619 - val_loss: 0.0911 - val_accuracy: 0.9600\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9619 - val_loss: 0.0867 - val_accuracy: 0.9620\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9628 - val_loss: 0.0702 - val_accuracy: 0.9682\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9618 - val_loss: 0.0774 - val_accuracy: 0.9660\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9637 - val_loss: 0.0775 - val_accuracy: 0.9652\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9626 - val_loss: 0.0834 - val_accuracy: 0.9627\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9627 - val_loss: 0.0856 - val_accuracy: 0.9624\n",
      "Epoch 176/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9618 - val_loss: 0.0811 - val_accuracy: 0.9633\n",
      "Epoch 177/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9640 - val_loss: 0.0782 - val_accuracy: 0.9640\n",
      "Epoch 178/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9628 - val_loss: 0.0704 - val_accuracy: 0.9686\n",
      "Epoch 179/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0978 - accuracy: 0.9645 - val_loss: 0.0744 - val_accuracy: 0.9672\n",
      "Epoch 180/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9628 - val_loss: 0.0735 - val_accuracy: 0.9675\n",
      "Epoch 181/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9633 - val_loss: 0.0738 - val_accuracy: 0.9667\n",
      "Epoch 182/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9634 - val_loss: 0.0837 - val_accuracy: 0.9627\n",
      "Epoch 183/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0984 - accuracy: 0.9635 - val_loss: 0.0839 - val_accuracy: 0.9617\n",
      "Epoch 184/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 0.9640 - val_loss: 0.0898 - val_accuracy: 0.9606\n",
      "Epoch 185/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9626 - val_loss: 0.0803 - val_accuracy: 0.9636\n",
      "Epoch 186/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9632 - val_loss: 0.0779 - val_accuracy: 0.9652\n",
      "Epoch 187/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9644 - val_loss: 0.0758 - val_accuracy: 0.9656\n",
      "Epoch 188/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0945 - accuracy: 0.9657 - val_loss: 0.0800 - val_accuracy: 0.9628\n",
      "Epoch 189/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9644 - val_loss: 0.0750 - val_accuracy: 0.9647\n",
      "Epoch 190/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9654 - val_loss: 0.0864 - val_accuracy: 0.9614\n",
      "Epoch 191/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9660 - val_loss: 0.0773 - val_accuracy: 0.9663\n",
      "Epoch 192/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0939 - accuracy: 0.9662 - val_loss: 0.0728 - val_accuracy: 0.9667\n",
      "Epoch 193/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9655 - val_loss: 0.0894 - val_accuracy: 0.9598\n",
      "Epoch 194/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9651 - val_loss: 0.0833 - val_accuracy: 0.9622\n",
      "Epoch 195/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9646 - val_loss: 0.0689 - val_accuracy: 0.9673\n",
      "Epoch 196/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9654 - val_loss: 0.0852 - val_accuracy: 0.9607\n",
      "Epoch 197/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9655 - val_loss: 0.0778 - val_accuracy: 0.9642\n",
      "Epoch 198/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9659 - val_loss: 0.0818 - val_accuracy: 0.9640\n",
      "Epoch 199/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.9674 - val_loss: 0.0757 - val_accuracy: 0.9659\n",
      "Epoch 200/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9658 - val_loss: 0.0752 - val_accuracy: 0.9665\n",
      "Epoch 201/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9650 - val_loss: 0.0681 - val_accuracy: 0.9684\n",
      "Epoch 202/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9670 - val_loss: 0.0726 - val_accuracy: 0.9662\n",
      "Epoch 203/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9661 - val_loss: 0.0657 - val_accuracy: 0.9701\n",
      "Epoch 204/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9662 - val_loss: 0.0740 - val_accuracy: 0.9667\n",
      "Epoch 205/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9683 - val_loss: 0.0750 - val_accuracy: 0.9668\n",
      "Epoch 206/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0904 - accuracy: 0.9669 - val_loss: 0.0862 - val_accuracy: 0.9614\n",
      "Epoch 207/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9680 - val_loss: 0.0814 - val_accuracy: 0.9629\n",
      "Epoch 208/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9664 - val_loss: 0.0715 - val_accuracy: 0.9675\n",
      "Epoch 209/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9658 - val_loss: 0.0634 - val_accuracy: 0.9716\n",
      "Epoch 210/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9672 - val_loss: 0.0820 - val_accuracy: 0.9636\n",
      "Epoch 211/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9678 - val_loss: 0.0661 - val_accuracy: 0.9694\n",
      "Epoch 212/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9670 - val_loss: 0.0678 - val_accuracy: 0.9709\n",
      "Epoch 213/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9683 - val_loss: 0.0751 - val_accuracy: 0.9656\n",
      "Epoch 214/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9687 - val_loss: 0.0713 - val_accuracy: 0.9689\n",
      "Epoch 215/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9690 - val_loss: 0.0853 - val_accuracy: 0.9618\n",
      "Epoch 216/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9685 - val_loss: 0.0723 - val_accuracy: 0.9676\n",
      "Epoch 217/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0886 - accuracy: 0.9677 - val_loss: 0.0786 - val_accuracy: 0.9654\n",
      "Epoch 218/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0897 - accuracy: 0.9674 - val_loss: 0.0818 - val_accuracy: 0.9646\n",
      "Epoch 219/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9688 - val_loss: 0.0729 - val_accuracy: 0.9673\n",
      "Epoch 220/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9693 - val_loss: 0.0756 - val_accuracy: 0.9670\n",
      "Epoch 221/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9695 - val_loss: 0.0821 - val_accuracy: 0.9634\n",
      "Epoch 222/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9690 - val_loss: 0.0822 - val_accuracy: 0.9625\n",
      "Epoch 223/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9687 - val_loss: 0.0597 - val_accuracy: 0.9738\n",
      "Epoch 224/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9690 - val_loss: 0.0753 - val_accuracy: 0.9647\n",
      "Epoch 225/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9704 - val_loss: 0.0799 - val_accuracy: 0.9642\n",
      "Epoch 226/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9695 - val_loss: 0.0647 - val_accuracy: 0.9714\n",
      "Epoch 227/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9696 - val_loss: 0.0828 - val_accuracy: 0.9636\n",
      "Epoch 228/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9685 - val_loss: 0.0729 - val_accuracy: 0.9684\n",
      "Epoch 229/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9706 - val_loss: 0.0696 - val_accuracy: 0.9679\n",
      "Epoch 230/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 0.0706 - val_accuracy: 0.9689\n",
      "Epoch 231/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9698 - val_loss: 0.0893 - val_accuracy: 0.9613\n",
      "Epoch 232/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9708 - val_loss: 0.0673 - val_accuracy: 0.9701\n",
      "Epoch 233/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9694 - val_loss: 0.0592 - val_accuracy: 0.9739\n",
      "Epoch 234/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9710 - val_loss: 0.0737 - val_accuracy: 0.9659\n",
      "Epoch 235/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9699 - val_loss: 0.0672 - val_accuracy: 0.9706\n",
      "Epoch 236/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9709 - val_loss: 0.0678 - val_accuracy: 0.9696\n",
      "Epoch 237/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9694 - val_loss: 0.0726 - val_accuracy: 0.9682\n",
      "Epoch 238/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9704 - val_loss: 0.0766 - val_accuracy: 0.9668\n",
      "Epoch 239/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9706 - val_loss: 0.0694 - val_accuracy: 0.9696\n",
      "Epoch 240/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9699 - val_loss: 0.0777 - val_accuracy: 0.9656\n",
      "Epoch 241/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9698 - val_loss: 0.0639 - val_accuracy: 0.9728\n",
      "Epoch 242/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9709 - val_loss: 0.0672 - val_accuracy: 0.9687\n",
      "Epoch 243/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9715 - val_loss: 0.0683 - val_accuracy: 0.9705\n",
      "Epoch 244/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9715 - val_loss: 0.0780 - val_accuracy: 0.9656\n",
      "Epoch 245/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9706 - val_loss: 0.0731 - val_accuracy: 0.9680\n",
      "Epoch 246/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9721 - val_loss: 0.0686 - val_accuracy: 0.9703\n",
      "Epoch 247/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9702 - val_loss: 0.0715 - val_accuracy: 0.9685\n",
      "Epoch 248/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9713 - val_loss: 0.0543 - val_accuracy: 0.9765\n",
      "Epoch 249/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9692 - val_loss: 0.0614 - val_accuracy: 0.9731\n",
      "Epoch 250/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0798 - accuracy: 0.9727 - val_loss: 0.0739 - val_accuracy: 0.9677\n",
      "Epoch 251/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9724 - val_loss: 0.0713 - val_accuracy: 0.9679\n",
      "Epoch 252/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9719 - val_loss: 0.0666 - val_accuracy: 0.9711\n",
      "Epoch 253/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9715 - val_loss: 0.0708 - val_accuracy: 0.9679\n",
      "Epoch 254/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9707 - val_loss: 0.0734 - val_accuracy: 0.9684\n",
      "Epoch 255/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9717 - val_loss: 0.0947 - val_accuracy: 0.9599\n",
      "Epoch 256/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9722 - val_loss: 0.0704 - val_accuracy: 0.9706\n",
      "Epoch 257/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9711 - val_loss: 0.0823 - val_accuracy: 0.9644\n",
      "Epoch 258/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9711 - val_loss: 0.0652 - val_accuracy: 0.9708\n",
      "Epoch 259/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9727 - val_loss: 0.0943 - val_accuracy: 0.9587\n",
      "Epoch 260/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9706 - val_loss: 0.0652 - val_accuracy: 0.9725\n",
      "Epoch 261/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9719 - val_loss: 0.0679 - val_accuracy: 0.9697\n",
      "Epoch 262/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9728 - val_loss: 0.0678 - val_accuracy: 0.9700\n",
      "Epoch 263/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9734 - val_loss: 0.0696 - val_accuracy: 0.9699\n",
      "Epoch 264/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.9720 - val_loss: 0.0750 - val_accuracy: 0.9674\n",
      "Epoch 265/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9733 - val_loss: 0.0775 - val_accuracy: 0.9670\n",
      "Epoch 266/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9711 - val_loss: 0.0647 - val_accuracy: 0.9717\n",
      "Epoch 267/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9729 - val_loss: 0.0629 - val_accuracy: 0.9743\n",
      "Epoch 268/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9727 - val_loss: 0.0619 - val_accuracy: 0.9747\n",
      "Epoch 269/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9728 - val_loss: 0.0601 - val_accuracy: 0.9750\n",
      "Epoch 270/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9727 - val_loss: 0.0645 - val_accuracy: 0.9723\n",
      "Epoch 271/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9731 - val_loss: 0.0676 - val_accuracy: 0.9701\n",
      "Epoch 272/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9727 - val_loss: 0.0691 - val_accuracy: 0.9710\n",
      "Epoch 273/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9731 - val_loss: 0.0692 - val_accuracy: 0.9709\n",
      "Epoch 274/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9730 - val_loss: 0.0745 - val_accuracy: 0.9680\n",
      "Epoch 275/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9732 - val_loss: 0.0618 - val_accuracy: 0.9727\n",
      "Epoch 276/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9735 - val_loss: 0.0703 - val_accuracy: 0.9697\n",
      "Epoch 277/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9724 - val_loss: 0.0650 - val_accuracy: 0.9726\n",
      "Epoch 278/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9724 - val_loss: 0.0634 - val_accuracy: 0.9739\n",
      "Epoch 279/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9727 - val_loss: 0.0687 - val_accuracy: 0.9714\n",
      "Epoch 280/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9724 - val_loss: 0.0736 - val_accuracy: 0.9688\n",
      "Epoch 281/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9730 - val_loss: 0.0680 - val_accuracy: 0.9720\n",
      "Epoch 282/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9737 - val_loss: 0.0711 - val_accuracy: 0.9703\n",
      "Epoch 283/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9740 - val_loss: 0.0826 - val_accuracy: 0.9653\n",
      "Epoch 284/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9726 - val_loss: 0.0918 - val_accuracy: 0.9600\n",
      "Epoch 285/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9730 - val_loss: 0.0780 - val_accuracy: 0.9672\n",
      "Epoch 286/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9727 - val_loss: 0.0759 - val_accuracy: 0.9685\n",
      "Epoch 287/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9739 - val_loss: 0.0602 - val_accuracy: 0.9745\n",
      "Epoch 288/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9735 - val_loss: 0.0626 - val_accuracy: 0.9740\n",
      "Epoch 289/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9733 - val_loss: 0.0624 - val_accuracy: 0.9731\n",
      "Epoch 290/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9738 - val_loss: 0.0594 - val_accuracy: 0.9734\n",
      "Epoch 291/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9727 - val_loss: 0.0672 - val_accuracy: 0.9716\n",
      "Epoch 292/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 0.9730 - val_loss: 0.0625 - val_accuracy: 0.9734\n",
      "Epoch 293/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9735 - val_loss: 0.0678 - val_accuracy: 0.9723\n",
      "Epoch 294/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9736 - val_loss: 0.0746 - val_accuracy: 0.9687\n",
      "Epoch 295/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9725 - val_loss: 0.0572 - val_accuracy: 0.9763\n",
      "Epoch 296/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9729 - val_loss: 0.0684 - val_accuracy: 0.9711\n",
      "Epoch 297/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9736 - val_loss: 0.0812 - val_accuracy: 0.9657\n",
      "Epoch 298/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9739 - val_loss: 0.0705 - val_accuracy: 0.9710\n",
      "Epoch 299/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9746 - val_loss: 0.0752 - val_accuracy: 0.9678\n",
      "Epoch 300/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9743 - val_loss: 0.0753 - val_accuracy: 0.9676\n",
      "Epoch 301/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9734 - val_loss: 0.0747 - val_accuracy: 0.9685\n",
      "Epoch 302/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9730 - val_loss: 0.0668 - val_accuracy: 0.9720\n",
      "Epoch 303/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9747 - val_loss: 0.0580 - val_accuracy: 0.9760\n",
      "Epoch 304/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9728 - val_loss: 0.0568 - val_accuracy: 0.9761\n",
      "Epoch 305/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9742 - val_loss: 0.0629 - val_accuracy: 0.9736\n",
      "Epoch 306/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9730 - val_loss: 0.0648 - val_accuracy: 0.9715\n",
      "Epoch 307/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9745 - val_loss: 0.0499 - val_accuracy: 0.9785\n",
      "Epoch 308/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9749 - val_loss: 0.0604 - val_accuracy: 0.9744\n",
      "Epoch 309/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9751 - val_loss: 0.0714 - val_accuracy: 0.9697\n",
      "Epoch 310/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9755 - val_loss: 0.0651 - val_accuracy: 0.9719\n",
      "Epoch 311/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9757 - val_loss: 0.0752 - val_accuracy: 0.9684\n",
      "Epoch 312/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9755 - val_loss: 0.0680 - val_accuracy: 0.9726\n",
      "Epoch 313/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9752 - val_loss: 0.0657 - val_accuracy: 0.9731\n",
      "Epoch 314/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9737 - val_loss: 0.0656 - val_accuracy: 0.9736\n",
      "Epoch 315/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9753 - val_loss: 0.0780 - val_accuracy: 0.9676\n",
      "Epoch 316/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9748 - val_loss: 0.0579 - val_accuracy: 0.9759\n",
      "Epoch 317/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9749 - val_loss: 0.0680 - val_accuracy: 0.9715\n",
      "Epoch 318/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9748 - val_loss: 0.0633 - val_accuracy: 0.9745\n",
      "Epoch 319/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9757 - val_loss: 0.0665 - val_accuracy: 0.9723\n",
      "Epoch 320/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9751 - val_loss: 0.0633 - val_accuracy: 0.9730\n",
      "Epoch 321/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9743 - val_loss: 0.0540 - val_accuracy: 0.9777\n",
      "Epoch 322/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9746 - val_loss: 0.0683 - val_accuracy: 0.9721\n",
      "Epoch 323/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9742 - val_loss: 0.0613 - val_accuracy: 0.9737\n",
      "Epoch 324/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9742 - val_loss: 0.0622 - val_accuracy: 0.9739\n",
      "Epoch 325/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9749 - val_loss: 0.0619 - val_accuracy: 0.9741\n",
      "Epoch 326/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9746 - val_loss: 0.0618 - val_accuracy: 0.9755\n",
      "Epoch 327/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9766 - val_loss: 0.0725 - val_accuracy: 0.9696\n",
      "Epoch 328/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9749 - val_loss: 0.0669 - val_accuracy: 0.9724\n",
      "Epoch 329/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9745 - val_loss: 0.0657 - val_accuracy: 0.9723\n",
      "Epoch 330/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9753 - val_loss: 0.0834 - val_accuracy: 0.9659\n",
      "Epoch 331/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9756 - val_loss: 0.0643 - val_accuracy: 0.9733\n",
      "Epoch 332/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9753 - val_loss: 0.0690 - val_accuracy: 0.9723\n",
      "Epoch 333/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9756 - val_loss: 0.0565 - val_accuracy: 0.9763\n",
      "Epoch 334/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9766 - val_loss: 0.0700 - val_accuracy: 0.9710\n",
      "Epoch 335/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.9768 - val_loss: 0.0580 - val_accuracy: 0.9754\n",
      "Epoch 336/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9750 - val_loss: 0.0674 - val_accuracy: 0.9723\n",
      "Epoch 337/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9745 - val_loss: 0.0584 - val_accuracy: 0.9764\n",
      "Epoch 338/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9761 - val_loss: 0.0699 - val_accuracy: 0.9724\n",
      "Epoch 339/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9751 - val_loss: 0.0598 - val_accuracy: 0.9743\n",
      "Epoch 340/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9756 - val_loss: 0.0777 - val_accuracy: 0.9679\n",
      "Epoch 341/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9748 - val_loss: 0.0685 - val_accuracy: 0.9716\n",
      "Epoch 342/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9760 - val_loss: 0.0678 - val_accuracy: 0.9729\n",
      "Epoch 343/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9750 - val_loss: 0.0698 - val_accuracy: 0.9718\n",
      "Epoch 344/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9752 - val_loss: 0.0635 - val_accuracy: 0.9736\n",
      "Epoch 345/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9745 - val_loss: 0.0576 - val_accuracy: 0.9759\n",
      "Epoch 346/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.0725 - val_accuracy: 0.9694\n",
      "Epoch 347/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9760 - val_loss: 0.0726 - val_accuracy: 0.9709\n",
      "Epoch 348/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9755 - val_loss: 0.0669 - val_accuracy: 0.9730\n",
      "Epoch 349/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9748 - val_loss: 0.0628 - val_accuracy: 0.9729\n",
      "Epoch 350/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9757 - val_loss: 0.0647 - val_accuracy: 0.9735\n",
      "Epoch 351/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9767 - val_loss: 0.0636 - val_accuracy: 0.9744\n",
      "Epoch 352/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9761 - val_loss: 0.0610 - val_accuracy: 0.9765\n",
      "Epoch 353/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9755 - val_loss: 0.0649 - val_accuracy: 0.9730\n",
      "Epoch 354/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9766 - val_loss: 0.0528 - val_accuracy: 0.9763\n",
      "Epoch 355/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9753 - val_loss: 0.0682 - val_accuracy: 0.9725\n",
      "Epoch 356/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9759 - val_loss: 0.0682 - val_accuracy: 0.9723\n",
      "Epoch 357/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9752 - val_loss: 0.0758 - val_accuracy: 0.9691\n",
      "Epoch 358/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9762 - val_loss: 0.0670 - val_accuracy: 0.9735\n",
      "Epoch 359/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9749 - val_loss: 0.0676 - val_accuracy: 0.9724\n",
      "Epoch 360/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9754 - val_loss: 0.0733 - val_accuracy: 0.9689\n",
      "Epoch 361/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9757 - val_loss: 0.0675 - val_accuracy: 0.9725\n",
      "Epoch 362/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9763 - val_loss: 0.0624 - val_accuracy: 0.9721\n",
      "Epoch 363/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.0727 - val_accuracy: 0.9704\n",
      "Epoch 364/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9753 - val_loss: 0.0615 - val_accuracy: 0.9748\n",
      "Epoch 365/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9761 - val_loss: 0.0642 - val_accuracy: 0.9728\n",
      "Epoch 366/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9767 - val_loss: 0.0706 - val_accuracy: 0.9723\n",
      "Epoch 367/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9760 - val_loss: 0.0589 - val_accuracy: 0.9765\n",
      "Epoch 368/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9773 - val_loss: 0.0780 - val_accuracy: 0.9682\n",
      "Epoch 369/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9771 - val_loss: 0.0692 - val_accuracy: 0.9718\n",
      "Epoch 370/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9746 - val_loss: 0.0701 - val_accuracy: 0.9713\n",
      "Epoch 371/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9762 - val_loss: 0.0734 - val_accuracy: 0.9709\n",
      "Epoch 372/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9770 - val_loss: 0.0704 - val_accuracy: 0.9711\n",
      "Epoch 373/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9762 - val_loss: 0.0883 - val_accuracy: 0.9660\n",
      "Epoch 374/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9759 - val_loss: 0.0629 - val_accuracy: 0.9731\n",
      "Epoch 375/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.0624 - val_accuracy: 0.9741\n",
      "Epoch 376/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9777 - val_loss: 0.0645 - val_accuracy: 0.9730\n",
      "Epoch 377/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9774 - val_loss: 0.0615 - val_accuracy: 0.9753\n",
      "Epoch 378/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9771 - val_loss: 0.0566 - val_accuracy: 0.9758\n",
      "Epoch 379/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9766 - val_loss: 0.0632 - val_accuracy: 0.9737\n",
      "Epoch 380/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9773 - val_loss: 0.0533 - val_accuracy: 0.9778\n",
      "Epoch 381/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9776 - val_loss: 0.0660 - val_accuracy: 0.9723\n",
      "Epoch 382/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9769 - val_loss: 0.0596 - val_accuracy: 0.9751\n",
      "Epoch 383/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9782 - val_loss: 0.0587 - val_accuracy: 0.9757\n",
      "Epoch 384/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9779 - val_loss: 0.0665 - val_accuracy: 0.9725\n",
      "Epoch 385/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9770 - val_loss: 0.0739 - val_accuracy: 0.9714\n",
      "Epoch 386/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9775 - val_loss: 0.0684 - val_accuracy: 0.9728\n",
      "Epoch 387/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9757 - val_loss: 0.0639 - val_accuracy: 0.9743\n",
      "Epoch 388/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9775 - val_loss: 0.0580 - val_accuracy: 0.9758\n",
      "Epoch 389/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9772 - val_loss: 0.0610 - val_accuracy: 0.9734\n",
      "Epoch 390/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9768 - val_loss: 0.0701 - val_accuracy: 0.9721\n",
      "Epoch 391/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9764 - val_loss: 0.0587 - val_accuracy: 0.9758\n",
      "Epoch 392/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9772 - val_loss: 0.0532 - val_accuracy: 0.9773\n",
      "Epoch 393/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9764 - val_loss: 0.0627 - val_accuracy: 0.9747\n",
      "Epoch 394/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9768 - val_loss: 0.0775 - val_accuracy: 0.9703\n",
      "Epoch 395/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9766 - val_loss: 0.0733 - val_accuracy: 0.9694\n",
      "Epoch 396/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9768 - val_loss: 0.0696 - val_accuracy: 0.9715\n",
      "Epoch 397/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9769 - val_loss: 0.0624 - val_accuracy: 0.9737\n",
      "Epoch 398/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9770 - val_loss: 0.0612 - val_accuracy: 0.9747\n",
      "Epoch 399/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9779 - val_loss: 0.0620 - val_accuracy: 0.9738\n",
      "Epoch 400/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9777 - val_loss: 0.0561 - val_accuracy: 0.9760\n",
      "Epoch 401/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9774 - val_loss: 0.0662 - val_accuracy: 0.9726\n",
      "Epoch 402/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9764 - val_loss: 0.0630 - val_accuracy: 0.9731\n",
      "Epoch 403/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9776 - val_loss: 0.0714 - val_accuracy: 0.9708\n",
      "Epoch 404/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9778 - val_loss: 0.0670 - val_accuracy: 0.9736\n",
      "Epoch 405/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9784 - val_loss: 0.0663 - val_accuracy: 0.9725\n",
      "Epoch 406/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9769 - val_loss: 0.0636 - val_accuracy: 0.9741\n",
      "Epoch 407/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9774 - val_loss: 0.0779 - val_accuracy: 0.9687\n",
      "Epoch 408/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9776 - val_loss: 0.0516 - val_accuracy: 0.9785\n",
      "Epoch 409/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9776 - val_loss: 0.0646 - val_accuracy: 0.9737\n",
      "Epoch 410/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9774 - val_loss: 0.0532 - val_accuracy: 0.9773\n",
      "Epoch 411/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9776 - val_loss: 0.0554 - val_accuracy: 0.9760\n",
      "Epoch 412/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9778 - val_loss: 0.0680 - val_accuracy: 0.9724\n",
      "Epoch 413/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9776 - val_loss: 0.0564 - val_accuracy: 0.9760\n",
      "Epoch 414/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9777 - val_loss: 0.0549 - val_accuracy: 0.9763\n",
      "Epoch 415/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9784 - val_loss: 0.0686 - val_accuracy: 0.9728\n",
      "Epoch 416/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9778 - val_loss: 0.0682 - val_accuracy: 0.9728\n",
      "Epoch 417/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9787 - val_loss: 0.0508 - val_accuracy: 0.9782\n",
      "Epoch 418/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9785 - val_loss: 0.0616 - val_accuracy: 0.9753\n",
      "Epoch 419/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9780 - val_loss: 0.0561 - val_accuracy: 0.9760\n",
      "Epoch 420/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9773 - val_loss: 0.0560 - val_accuracy: 0.9760\n",
      "Epoch 421/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9778 - val_loss: 0.0598 - val_accuracy: 0.9753\n",
      "Epoch 422/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9770 - val_loss: 0.0612 - val_accuracy: 0.9754\n",
      "Epoch 423/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9786 - val_loss: 0.0660 - val_accuracy: 0.9736\n",
      "Epoch 424/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9785 - val_loss: 0.0644 - val_accuracy: 0.9733\n",
      "Epoch 425/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9777 - val_loss: 0.0559 - val_accuracy: 0.9766\n",
      "Epoch 426/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9773 - val_loss: 0.0641 - val_accuracy: 0.9735\n",
      "Epoch 427/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9781 - val_loss: 0.0702 - val_accuracy: 0.9719\n",
      "Epoch 428/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9779 - val_loss: 0.0718 - val_accuracy: 0.9711\n",
      "Epoch 429/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9781 - val_loss: 0.0853 - val_accuracy: 0.9665\n",
      "Epoch 430/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9783 - val_loss: 0.0604 - val_accuracy: 0.9754\n",
      "Epoch 431/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9773 - val_loss: 0.0588 - val_accuracy: 0.9759\n",
      "Epoch 432/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9770 - val_loss: 0.0690 - val_accuracy: 0.9729\n",
      "Epoch 433/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9777 - val_loss: 0.0588 - val_accuracy: 0.9755\n",
      "Epoch 434/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9780 - val_loss: 0.0537 - val_accuracy: 0.9769\n",
      "Epoch 435/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9766 - val_loss: 0.0654 - val_accuracy: 0.9730\n",
      "Epoch 436/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9779 - val_loss: 0.0580 - val_accuracy: 0.9755\n",
      "Epoch 437/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9774 - val_loss: 0.0628 - val_accuracy: 0.9754\n",
      "Epoch 438/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9791 - val_loss: 0.0562 - val_accuracy: 0.9760\n",
      "Epoch 439/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9767 - val_loss: 0.0539 - val_accuracy: 0.9778\n",
      "Epoch 440/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9780 - val_loss: 0.0628 - val_accuracy: 0.9747\n",
      "Epoch 441/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9770 - val_loss: 0.0574 - val_accuracy: 0.9756\n",
      "Epoch 442/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9779 - val_loss: 0.0635 - val_accuracy: 0.9754\n",
      "Epoch 443/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9790 - val_loss: 0.0708 - val_accuracy: 0.9721\n",
      "Epoch 444/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9783 - val_loss: 0.0670 - val_accuracy: 0.9721\n",
      "Epoch 445/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9765 - val_loss: 0.0585 - val_accuracy: 0.9759\n",
      "Epoch 446/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9771 - val_loss: 0.0611 - val_accuracy: 0.9753\n",
      "Epoch 447/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9794 - val_loss: 0.0642 - val_accuracy: 0.9747\n",
      "Epoch 448/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9780 - val_loss: 0.0607 - val_accuracy: 0.9751\n",
      "Epoch 449/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9783 - val_loss: 0.0786 - val_accuracy: 0.9701\n",
      "Epoch 450/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9772 - val_loss: 0.0603 - val_accuracy: 0.9753\n",
      "Epoch 451/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9788 - val_loss: 0.0558 - val_accuracy: 0.9775\n",
      "Epoch 452/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9786 - val_loss: 0.0507 - val_accuracy: 0.9794\n",
      "Epoch 453/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9791 - val_loss: 0.0529 - val_accuracy: 0.9777\n",
      "Epoch 454/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9770 - val_loss: 0.0668 - val_accuracy: 0.9739\n",
      "Epoch 455/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9779 - val_loss: 0.0584 - val_accuracy: 0.9761\n",
      "Epoch 456/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9784 - val_loss: 0.0557 - val_accuracy: 0.9770\n",
      "Epoch 457/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9782 - val_loss: 0.0553 - val_accuracy: 0.9776\n",
      "Epoch 458/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 0.0642 - val_accuracy: 0.9756\n",
      "Epoch 459/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9779 - val_loss: 0.0574 - val_accuracy: 0.9770\n",
      "Epoch 460/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9786 - val_loss: 0.0512 - val_accuracy: 0.9790\n",
      "Epoch 461/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9774 - val_loss: 0.0556 - val_accuracy: 0.9773\n",
      "Epoch 462/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9780 - val_loss: 0.0686 - val_accuracy: 0.9730\n",
      "Epoch 463/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9783 - val_loss: 0.0837 - val_accuracy: 0.9691\n",
      "Epoch 464/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9780 - val_loss: 0.0616 - val_accuracy: 0.9755\n",
      "Epoch 465/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9787 - val_loss: 0.0659 - val_accuracy: 0.9747\n",
      "Epoch 466/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9782 - val_loss: 0.0673 - val_accuracy: 0.9736\n",
      "Epoch 467/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9772 - val_loss: 0.0575 - val_accuracy: 0.9764\n",
      "Epoch 468/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9785 - val_loss: 0.0590 - val_accuracy: 0.9764\n",
      "Epoch 469/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9785 - val_loss: 0.0558 - val_accuracy: 0.9766\n",
      "Epoch 470/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9777 - val_loss: 0.0616 - val_accuracy: 0.9744\n",
      "Epoch 471/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9792 - val_loss: 0.0617 - val_accuracy: 0.9748\n",
      "Epoch 472/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9786 - val_loss: 0.0688 - val_accuracy: 0.9736\n",
      "Epoch 473/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9785 - val_loss: 0.0608 - val_accuracy: 0.9756\n",
      "Epoch 474/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9778 - val_loss: 0.0623 - val_accuracy: 0.9756\n",
      "Epoch 475/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9776 - val_loss: 0.0643 - val_accuracy: 0.9743\n",
      "Epoch 476/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9787 - val_loss: 0.0580 - val_accuracy: 0.9758\n",
      "Epoch 477/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9786 - val_loss: 0.0625 - val_accuracy: 0.9741\n",
      "Epoch 478/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9782 - val_loss: 0.0620 - val_accuracy: 0.9746\n",
      "Epoch 479/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.0585 - val_accuracy: 0.9765\n",
      "Epoch 480/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9780 - val_loss: 0.0610 - val_accuracy: 0.9747\n",
      "Epoch 481/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9783 - val_loss: 0.0538 - val_accuracy: 0.9777\n",
      "Epoch 482/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9790 - val_loss: 0.0605 - val_accuracy: 0.9760\n",
      "Epoch 483/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9794 - val_loss: 0.0604 - val_accuracy: 0.9757\n",
      "Epoch 484/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9781 - val_loss: 0.0589 - val_accuracy: 0.9761\n",
      "Epoch 485/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9788 - val_loss: 0.0642 - val_accuracy: 0.9747\n",
      "Epoch 486/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9779 - val_loss: 0.0616 - val_accuracy: 0.9756\n",
      "Epoch 487/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.0551 - val_accuracy: 0.9773\n",
      "Epoch 488/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9783 - val_loss: 0.0628 - val_accuracy: 0.9750\n",
      "Epoch 489/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9786 - val_loss: 0.0594 - val_accuracy: 0.9751\n",
      "Epoch 490/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9794 - val_loss: 0.0666 - val_accuracy: 0.9735\n",
      "Epoch 491/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9793 - val_loss: 0.0544 - val_accuracy: 0.9775\n",
      "Epoch 492/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 0.0667 - val_accuracy: 0.9734\n",
      "Epoch 493/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9793 - val_loss: 0.0585 - val_accuracy: 0.9760\n",
      "Epoch 494/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9789 - val_loss: 0.0521 - val_accuracy: 0.9777\n",
      "Epoch 495/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9778 - val_loss: 0.0630 - val_accuracy: 0.9753\n",
      "Epoch 496/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9790 - val_loss: 0.0612 - val_accuracy: 0.9758\n",
      "Epoch 497/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0603 - accuracy: 0.9789 - val_loss: 0.0578 - val_accuracy: 0.9760\n",
      "Epoch 498/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9795 - val_loss: 0.0658 - val_accuracy: 0.9737\n",
      "Epoch 499/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.0579 - val_accuracy: 0.9764\n",
      "Epoch 500/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9792 - val_loss: 0.0686 - val_accuracy: 0.9735\n",
      "Epoch 501/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9788 - val_loss: 0.0593 - val_accuracy: 0.9754\n",
      "Epoch 502/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9801 - val_loss: 0.0575 - val_accuracy: 0.9773\n",
      "Epoch 503/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9786 - val_loss: 0.0625 - val_accuracy: 0.9756\n",
      "Epoch 504/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9794 - val_loss: 0.0678 - val_accuracy: 0.9733\n",
      "Epoch 505/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9790 - val_loss: 0.0641 - val_accuracy: 0.9745\n",
      "Epoch 506/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9789 - val_loss: 0.0634 - val_accuracy: 0.9739\n",
      "Epoch 507/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9789 - val_loss: 0.0616 - val_accuracy: 0.9754\n",
      "Epoch 508/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9786 - val_loss: 0.0547 - val_accuracy: 0.9773\n",
      "Epoch 509/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9789 - val_loss: 0.0634 - val_accuracy: 0.9745\n",
      "Epoch 510/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9797 - val_loss: 0.0673 - val_accuracy: 0.9743\n",
      "Epoch 511/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9791 - val_loss: 0.0704 - val_accuracy: 0.9723\n",
      "Epoch 512/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9784 - val_loss: 0.0583 - val_accuracy: 0.9766\n",
      "Epoch 513/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9790 - val_loss: 0.0586 - val_accuracy: 0.9763\n",
      "Epoch 514/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9795 - val_loss: 0.0614 - val_accuracy: 0.9759\n",
      "Epoch 515/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9787 - val_loss: 0.0684 - val_accuracy: 0.9731\n",
      "Epoch 516/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9787 - val_loss: 0.0598 - val_accuracy: 0.9763\n",
      "Epoch 517/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9800 - val_loss: 0.0569 - val_accuracy: 0.9766\n",
      "Epoch 518/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.0734 - val_accuracy: 0.9725\n",
      "Epoch 519/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9788 - val_loss: 0.0632 - val_accuracy: 0.9749\n",
      "Epoch 520/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9798 - val_loss: 0.0608 - val_accuracy: 0.9761\n",
      "Epoch 521/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9793 - val_loss: 0.0569 - val_accuracy: 0.9760\n",
      "Epoch 522/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9786 - val_loss: 0.0594 - val_accuracy: 0.9748\n",
      "Epoch 523/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9789 - val_loss: 0.0659 - val_accuracy: 0.9738\n",
      "Epoch 524/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9793 - val_loss: 0.0561 - val_accuracy: 0.9767\n",
      "Epoch 525/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9788 - val_loss: 0.0579 - val_accuracy: 0.9765\n",
      "Epoch 526/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9785 - val_loss: 0.0532 - val_accuracy: 0.9764\n",
      "Epoch 527/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9797 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
      "Epoch 528/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9781 - val_loss: 0.0659 - val_accuracy: 0.9751\n",
      "Epoch 529/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9791 - val_loss: 0.0653 - val_accuracy: 0.9744\n",
      "Epoch 530/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9796 - val_loss: 0.0580 - val_accuracy: 0.9763\n",
      "Epoch 531/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.0553 - val_accuracy: 0.9782\n",
      "Epoch 532/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9801 - val_loss: 0.0565 - val_accuracy: 0.9765\n",
      "Epoch 533/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9796 - val_loss: 0.0724 - val_accuracy: 0.9728\n",
      "Epoch 534/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9801 - val_loss: 0.0529 - val_accuracy: 0.9781\n",
      "Epoch 535/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9791 - val_loss: 0.0601 - val_accuracy: 0.9751\n",
      "Epoch 536/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9787 - val_loss: 0.0598 - val_accuracy: 0.9765\n",
      "Epoch 537/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9799 - val_loss: 0.0561 - val_accuracy: 0.9763\n",
      "Epoch 538/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9794 - val_loss: 0.0617 - val_accuracy: 0.9758\n",
      "Epoch 539/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9790 - val_loss: 0.0564 - val_accuracy: 0.9775\n",
      "Epoch 540/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9801 - val_loss: 0.0607 - val_accuracy: 0.9757\n",
      "Epoch 541/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9791 - val_loss: 0.0638 - val_accuracy: 0.9746\n",
      "Epoch 542/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9791 - val_loss: 0.0597 - val_accuracy: 0.9764\n",
      "Epoch 543/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9795 - val_loss: 0.0512 - val_accuracy: 0.9778\n",
      "Epoch 544/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9798 - val_loss: 0.0590 - val_accuracy: 0.9758\n",
      "Epoch 545/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9795 - val_loss: 0.0685 - val_accuracy: 0.9739\n",
      "Epoch 546/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9796 - val_loss: 0.0553 - val_accuracy: 0.9771\n",
      "Epoch 547/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9797 - val_loss: 0.0588 - val_accuracy: 0.9763\n",
      "Epoch 548/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9793 - val_loss: 0.0621 - val_accuracy: 0.9750\n",
      "Epoch 549/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9796 - val_loss: 0.0656 - val_accuracy: 0.9756\n",
      "Epoch 550/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 0.0574 - val_accuracy: 0.9760\n",
      "Epoch 551/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.0530 - val_accuracy: 0.9775\n",
      "Epoch 552/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9788 - val_loss: 0.0600 - val_accuracy: 0.9757\n",
      "Epoch 553/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.0585 - accuracy: 0.9794 - val_loss: 0.0608 - val_accuracy: 0.9751\n",
      "Epoch 554/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0572 - accuracy: 0.9800 - val_loss: 0.0612 - val_accuracy: 0.9754\n",
      "Epoch 555/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9802 - val_loss: 0.0688 - val_accuracy: 0.9737\n",
      "Epoch 556/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9798 - val_loss: 0.0539 - val_accuracy: 0.9780\n",
      "Epoch 557/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.9805 - val_loss: 0.0650 - val_accuracy: 0.9748\n",
      "Epoch 558/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9797 - val_loss: 0.0511 - val_accuracy: 0.9778\n",
      "Epoch 559/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9796 - val_loss: 0.0579 - val_accuracy: 0.9760\n",
      "Epoch 560/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0569 - accuracy: 0.9797 - val_loss: 0.0662 - val_accuracy: 0.9743\n",
      "Epoch 561/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9806 - val_loss: 0.0717 - val_accuracy: 0.9727\n",
      "Epoch 562/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0568 - accuracy: 0.9803 - val_loss: 0.0522 - val_accuracy: 0.9777\n",
      "Epoch 563/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0576 - accuracy: 0.9797 - val_loss: 0.0543 - val_accuracy: 0.9778\n",
      "Epoch 564/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9799 - val_loss: 0.0533 - val_accuracy: 0.9779\n",
      "Epoch 565/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9799 - val_loss: 0.0651 - val_accuracy: 0.9744\n",
      "Epoch 566/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9805 - val_loss: 0.0516 - val_accuracy: 0.9779\n",
      "Epoch 567/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9796 - val_loss: 0.0539 - val_accuracy: 0.9779\n",
      "Epoch 568/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9797 - val_loss: 0.0641 - val_accuracy: 0.9757\n",
      "Epoch 569/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9801 - val_loss: 0.0525 - val_accuracy: 0.9778\n",
      "Epoch 570/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9806 - val_loss: 0.0658 - val_accuracy: 0.9737\n",
      "Epoch 571/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9792 - val_loss: 0.0630 - val_accuracy: 0.9754\n",
      "Epoch 572/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9801 - val_loss: 0.0616 - val_accuracy: 0.9759\n",
      "Epoch 573/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9797 - val_loss: 0.0553 - val_accuracy: 0.9770\n",
      "Epoch 574/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9792 - val_loss: 0.0649 - val_accuracy: 0.9737\n",
      "Epoch 575/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9797 - val_loss: 0.0521 - val_accuracy: 0.9781\n",
      "Epoch 576/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9799 - val_loss: 0.0686 - val_accuracy: 0.9734\n",
      "Epoch 577/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9782 - val_loss: 0.0526 - val_accuracy: 0.9779\n",
      "Epoch 578/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.0512 - val_accuracy: 0.9776\n",
      "Epoch 579/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9794 - val_loss: 0.0621 - val_accuracy: 0.9759\n",
      "Epoch 580/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9801 - val_loss: 0.0627 - val_accuracy: 0.9755\n",
      "Epoch 581/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9809 - val_loss: 0.0720 - val_accuracy: 0.9726\n",
      "Epoch 582/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 0.0689 - val_accuracy: 0.9738\n",
      "Epoch 583/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9794 - val_loss: 0.0556 - val_accuracy: 0.9768\n",
      "Epoch 584/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9809 - val_loss: 0.0699 - val_accuracy: 0.9724\n",
      "Epoch 585/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9799 - val_loss: 0.0563 - val_accuracy: 0.9769\n",
      "Epoch 586/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9797 - val_loss: 0.0546 - val_accuracy: 0.9775\n",
      "Epoch 587/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9799 - val_loss: 0.0552 - val_accuracy: 0.9774\n",
      "Epoch 588/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9809 - val_loss: 0.0613 - val_accuracy: 0.9747\n",
      "Epoch 589/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9796 - val_loss: 0.0513 - val_accuracy: 0.9791\n",
      "Epoch 590/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9795 - val_loss: 0.0634 - val_accuracy: 0.9755\n",
      "Epoch 591/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9801 - val_loss: 0.0534 - val_accuracy: 0.9768\n",
      "Epoch 592/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9798 - val_loss: 0.0535 - val_accuracy: 0.9778\n",
      "Epoch 593/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9801 - val_loss: 0.0527 - val_accuracy: 0.9781\n",
      "Epoch 594/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9808 - val_loss: 0.0523 - val_accuracy: 0.9780\n",
      "Epoch 595/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9806 - val_loss: 0.0666 - val_accuracy: 0.9746\n",
      "Epoch 596/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9794 - val_loss: 0.0669 - val_accuracy: 0.9736\n",
      "Epoch 597/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9807 - val_loss: 0.0567 - val_accuracy: 0.9766\n",
      "Epoch 598/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0569 - accuracy: 0.9802 - val_loss: 0.0562 - val_accuracy: 0.9771\n",
      "Epoch 599/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9802 - val_loss: 0.0559 - val_accuracy: 0.9773\n",
      "Epoch 600/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9813 - val_loss: 0.0589 - val_accuracy: 0.9763\n",
      "Epoch 601/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9804 - val_loss: 0.0583 - val_accuracy: 0.9764\n",
      "Epoch 602/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9806 - val_loss: 0.0596 - val_accuracy: 0.9757\n",
      "Epoch 603/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9807 - val_loss: 0.0577 - val_accuracy: 0.9765\n",
      "Epoch 604/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0618 - val_accuracy: 0.9755\n",
      "Epoch 605/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9803 - val_loss: 0.0499 - val_accuracy: 0.9788\n",
      "Epoch 606/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9794 - val_loss: 0.0625 - val_accuracy: 0.9753\n",
      "Epoch 607/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9806 - val_loss: 0.0593 - val_accuracy: 0.9756\n",
      "Epoch 608/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9794 - val_loss: 0.0677 - val_accuracy: 0.9739\n",
      "Epoch 609/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0579 - val_accuracy: 0.9760\n",
      "Epoch 610/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9805 - val_loss: 0.0614 - val_accuracy: 0.9754\n",
      "Epoch 611/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9802 - val_loss: 0.0561 - val_accuracy: 0.9769\n",
      "Epoch 612/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9807 - val_loss: 0.0577 - val_accuracy: 0.9760\n",
      "Epoch 613/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9798 - val_loss: 0.0665 - val_accuracy: 0.9748\n",
      "Epoch 614/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9805 - val_loss: 0.0562 - val_accuracy: 0.9771\n",
      "Epoch 615/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9807 - val_loss: 0.0640 - val_accuracy: 0.9751\n",
      "Epoch 616/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0579 - val_accuracy: 0.9767\n",
      "Epoch 617/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9798 - val_loss: 0.0595 - val_accuracy: 0.9758\n",
      "Epoch 618/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.0563 - val_accuracy: 0.9761\n",
      "Epoch 619/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9811 - val_loss: 0.0766 - val_accuracy: 0.9733\n",
      "Epoch 620/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9796 - val_loss: 0.0579 - val_accuracy: 0.9767\n",
      "Epoch 621/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9808 - val_loss: 0.0569 - val_accuracy: 0.9766\n",
      "Epoch 622/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9795 - val_loss: 0.0545 - val_accuracy: 0.9777\n",
      "Epoch 623/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9797 - val_loss: 0.0600 - val_accuracy: 0.9757\n",
      "Epoch 624/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9806 - val_loss: 0.0627 - val_accuracy: 0.9755\n",
      "Epoch 625/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9798 - val_loss: 0.0645 - val_accuracy: 0.9750\n",
      "Epoch 626/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 0.0568 - val_accuracy: 0.9770\n",
      "Epoch 627/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9814 - val_loss: 0.0531 - val_accuracy: 0.9784\n",
      "Epoch 628/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9802 - val_loss: 0.0554 - val_accuracy: 0.9764\n",
      "Epoch 629/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9804 - val_loss: 0.0715 - val_accuracy: 0.9729\n",
      "Epoch 630/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9789 - val_loss: 0.0564 - val_accuracy: 0.9766\n",
      "Epoch 631/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9804 - val_loss: 0.0640 - val_accuracy: 0.9748\n",
      "Epoch 632/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0645 - val_accuracy: 0.9747\n",
      "Epoch 633/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9791 - val_loss: 0.0572 - val_accuracy: 0.9771\n",
      "Epoch 634/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9802 - val_loss: 0.0675 - val_accuracy: 0.9734\n",
      "Epoch 635/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9807 - val_loss: 0.0513 - val_accuracy: 0.9784\n",
      "Epoch 636/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9808 - val_loss: 0.0569 - val_accuracy: 0.9769\n",
      "Epoch 637/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9815 - val_loss: 0.0531 - val_accuracy: 0.9790\n",
      "Epoch 638/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9807 - val_loss: 0.0541 - val_accuracy: 0.9781\n",
      "Epoch 639/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9806 - val_loss: 0.0614 - val_accuracy: 0.9749\n",
      "Epoch 640/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9799 - val_loss: 0.0645 - val_accuracy: 0.9749\n",
      "Epoch 641/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 0.0565 - val_accuracy: 0.9755\n",
      "Epoch 642/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9799 - val_loss: 0.0635 - val_accuracy: 0.9753\n",
      "Epoch 643/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9806 - val_loss: 0.0659 - val_accuracy: 0.9750\n",
      "Epoch 644/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9802 - val_loss: 0.0603 - val_accuracy: 0.9753\n",
      "Epoch 645/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9799 - val_loss: 0.0723 - val_accuracy: 0.9735\n",
      "Epoch 646/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9797 - val_loss: 0.0662 - val_accuracy: 0.9748\n",
      "Epoch 647/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 0.0671 - val_accuracy: 0.9750\n",
      "Epoch 648/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9806 - val_loss: 0.0595 - val_accuracy: 0.9758\n",
      "Epoch 649/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9805 - val_loss: 0.0570 - val_accuracy: 0.9770\n",
      "Epoch 650/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9807 - val_loss: 0.0774 - val_accuracy: 0.9733\n",
      "Epoch 651/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9809 - val_loss: 0.0576 - val_accuracy: 0.9773\n",
      "Epoch 652/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9814 - val_loss: 0.0577 - val_accuracy: 0.9760\n",
      "Epoch 653/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0527 - val_accuracy: 0.9770\n",
      "Epoch 654/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.9795 - val_loss: 0.0675 - val_accuracy: 0.9740\n",
      "Epoch 655/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9809 - val_loss: 0.0587 - val_accuracy: 0.9765\n",
      "Epoch 656/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.0525 - val_accuracy: 0.9787\n",
      "Epoch 657/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 0.0605 - val_accuracy: 0.9754\n",
      "Epoch 658/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9802 - val_loss: 0.0592 - val_accuracy: 0.9761\n",
      "Epoch 659/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0547 - val_accuracy: 0.9764\n",
      "Epoch 660/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9804 - val_loss: 0.0593 - val_accuracy: 0.9760\n",
      "Epoch 661/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9807 - val_loss: 0.0587 - val_accuracy: 0.9760\n",
      "Epoch 662/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9812 - val_loss: 0.0642 - val_accuracy: 0.9753\n",
      "Epoch 663/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9805 - val_loss: 0.0648 - val_accuracy: 0.9747\n",
      "Epoch 664/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9804 - val_loss: 0.0614 - val_accuracy: 0.9756\n",
      "Epoch 665/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9818 - val_loss: 0.0565 - val_accuracy: 0.9768\n",
      "Epoch 666/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0560 - val_accuracy: 0.9777\n",
      "Epoch 667/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9802 - val_loss: 0.0597 - val_accuracy: 0.9761\n",
      "Epoch 668/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9799 - val_loss: 0.0558 - val_accuracy: 0.9774\n",
      "Epoch 669/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9803 - val_loss: 0.0657 - val_accuracy: 0.9755\n",
      "Epoch 670/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 0.0558 - val_accuracy: 0.9770\n",
      "Epoch 671/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9809 - val_loss: 0.0567 - val_accuracy: 0.9764\n",
      "Epoch 672/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.0626 - val_accuracy: 0.9756\n",
      "Epoch 673/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9803 - val_loss: 0.0627 - val_accuracy: 0.9753\n",
      "Epoch 674/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9807 - val_loss: 0.0570 - val_accuracy: 0.9776\n",
      "Epoch 675/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9807 - val_loss: 0.0572 - val_accuracy: 0.9766\n",
      "Epoch 676/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9817 - val_loss: 0.0571 - val_accuracy: 0.9774\n",
      "Epoch 677/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9795 - val_loss: 0.0683 - val_accuracy: 0.9743\n",
      "Epoch 678/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9816 - val_loss: 0.0522 - val_accuracy: 0.9780\n",
      "Epoch 679/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9808 - val_loss: 0.0568 - val_accuracy: 0.9761\n",
      "Epoch 680/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9805 - val_loss: 0.0661 - val_accuracy: 0.9746\n",
      "Epoch 681/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9809 - val_loss: 0.0673 - val_accuracy: 0.9739\n",
      "Epoch 682/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9801 - val_loss: 0.0590 - val_accuracy: 0.9768\n",
      "Epoch 683/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0583 - val_accuracy: 0.9771\n",
      "Epoch 684/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9798 - val_loss: 0.0694 - val_accuracy: 0.9741\n",
      "Epoch 685/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9811 - val_loss: 0.0522 - val_accuracy: 0.9788\n",
      "Epoch 686/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9803 - val_loss: 0.0534 - val_accuracy: 0.9771\n",
      "Epoch 687/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9804 - val_loss: 0.0578 - val_accuracy: 0.9763\n",
      "Epoch 688/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9809 - val_loss: 0.0497 - val_accuracy: 0.9790\n",
      "Epoch 689/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 0.0648 - val_accuracy: 0.9747\n",
      "Epoch 690/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 0.0565 - val_accuracy: 0.9765\n",
      "Epoch 691/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9813 - val_loss: 0.0577 - val_accuracy: 0.9760\n",
      "Epoch 692/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9822 - val_loss: 0.0583 - val_accuracy: 0.9767\n",
      "Epoch 693/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9806 - val_loss: 0.0580 - val_accuracy: 0.9776\n",
      "Epoch 694/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9806 - val_loss: 0.0606 - val_accuracy: 0.9761\n",
      "Epoch 695/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0549 - val_accuracy: 0.9770\n",
      "Epoch 696/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9797 - val_loss: 0.0559 - val_accuracy: 0.9771\n",
      "Epoch 697/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.0543 - val_accuracy: 0.9773\n",
      "Epoch 698/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9805 - val_loss: 0.0577 - val_accuracy: 0.9766\n",
      "Epoch 699/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0629 - val_accuracy: 0.9753\n",
      "Epoch 700/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9808 - val_loss: 0.0579 - val_accuracy: 0.9765\n",
      "Epoch 701/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9803 - val_loss: 0.0588 - val_accuracy: 0.9773\n",
      "Epoch 702/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9816 - val_loss: 0.0569 - val_accuracy: 0.9770\n",
      "Epoch 703/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9798 - val_loss: 0.0591 - val_accuracy: 0.9761\n",
      "Epoch 704/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0551 - accuracy: 0.9806 - val_loss: 0.0516 - val_accuracy: 0.9787\n",
      "Epoch 705/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0556 - accuracy: 0.9805 - val_loss: 0.0561 - val_accuracy: 0.9768\n",
      "Epoch 706/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9812 - val_loss: 0.0515 - val_accuracy: 0.9789\n",
      "Epoch 707/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.0577 - val_accuracy: 0.9763\n",
      "Epoch 708/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9809 - val_loss: 0.0579 - val_accuracy: 0.9764\n",
      "Epoch 709/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9799 - val_loss: 0.0567 - val_accuracy: 0.9765\n",
      "Epoch 710/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9802 - val_loss: 0.0495 - val_accuracy: 0.9787\n",
      "Epoch 711/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.0582 - val_accuracy: 0.9767\n",
      "Epoch 712/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9811 - val_loss: 0.0562 - val_accuracy: 0.9774\n",
      "Epoch 713/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9804 - val_loss: 0.0507 - val_accuracy: 0.9781\n",
      "Epoch 714/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9816 - val_loss: 0.0580 - val_accuracy: 0.9765\n",
      "Epoch 715/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9797 - val_loss: 0.0554 - val_accuracy: 0.9769\n",
      "Epoch 716/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 0.0546 - val_accuracy: 0.9773\n",
      "Epoch 717/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9799 - val_loss: 0.0662 - val_accuracy: 0.9747\n",
      "Epoch 718/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9805 - val_loss: 0.0514 - val_accuracy: 0.9782\n",
      "Epoch 719/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9814 - val_loss: 0.0553 - val_accuracy: 0.9773\n",
      "Epoch 720/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9809 - val_loss: 0.0550 - val_accuracy: 0.9776\n",
      "Epoch 721/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9817 - val_loss: 0.0576 - val_accuracy: 0.9764\n",
      "Epoch 722/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9814 - val_loss: 0.0540 - val_accuracy: 0.9776\n",
      "Epoch 723/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9809 - val_loss: 0.0565 - val_accuracy: 0.9765\n",
      "Epoch 724/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9809 - val_loss: 0.0584 - val_accuracy: 0.9771\n",
      "Epoch 725/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9804 - val_loss: 0.0559 - val_accuracy: 0.9771\n",
      "Epoch 726/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9811 - val_loss: 0.0595 - val_accuracy: 0.9763\n",
      "Epoch 727/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9815 - val_loss: 0.0621 - val_accuracy: 0.9764\n",
      "Epoch 728/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0571 - val_accuracy: 0.9767\n",
      "Epoch 729/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9801 - val_loss: 0.0584 - val_accuracy: 0.9760\n",
      "Epoch 730/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9800 - val_loss: 0.0626 - val_accuracy: 0.9757\n",
      "Epoch 731/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9802 - val_loss: 0.0617 - val_accuracy: 0.9753\n",
      "Epoch 732/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9802 - val_loss: 0.0581 - val_accuracy: 0.9761\n",
      "Epoch 733/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9808 - val_loss: 0.0613 - val_accuracy: 0.9765\n",
      "Epoch 734/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9807 - val_loss: 0.0565 - val_accuracy: 0.9770\n",
      "Epoch 735/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9817 - val_loss: 0.0534 - val_accuracy: 0.9778\n",
      "Epoch 736/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 0.0563 - val_accuracy: 0.9777\n",
      "Epoch 737/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.0573 - val_accuracy: 0.9771\n",
      "Epoch 738/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9817 - val_loss: 0.0556 - val_accuracy: 0.9766\n",
      "Epoch 739/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9814 - val_loss: 0.0585 - val_accuracy: 0.9769\n",
      "Epoch 740/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 0.0576 - val_accuracy: 0.9765\n",
      "Epoch 741/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9819 - val_loss: 0.0560 - val_accuracy: 0.9774\n",
      "Epoch 742/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9818 - val_loss: 0.0543 - val_accuracy: 0.9773\n",
      "Epoch 743/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9805 - val_loss: 0.0568 - val_accuracy: 0.9770\n",
      "Epoch 744/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9815 - val_loss: 0.0636 - val_accuracy: 0.9756\n",
      "Epoch 745/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9820 - val_loss: 0.0596 - val_accuracy: 0.9764\n",
      "Epoch 746/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9817 - val_loss: 0.0512 - val_accuracy: 0.9782\n",
      "Epoch 747/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9812 - val_loss: 0.0550 - val_accuracy: 0.9770\n",
      "Epoch 748/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9817 - val_loss: 0.0590 - val_accuracy: 0.9759\n",
      "Epoch 749/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9816 - val_loss: 0.0599 - val_accuracy: 0.9761\n",
      "Epoch 750/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9815 - val_loss: 0.0609 - val_accuracy: 0.9764\n",
      "Epoch 751/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9815 - val_loss: 0.0572 - val_accuracy: 0.9774\n",
      "Epoch 752/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9811 - val_loss: 0.0529 - val_accuracy: 0.9780\n",
      "Epoch 753/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9818 - val_loss: 0.0669 - val_accuracy: 0.9750\n",
      "Epoch 754/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 0.0588 - val_accuracy: 0.9766\n",
      "Epoch 755/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.0574 - val_accuracy: 0.9767\n",
      "Epoch 756/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9816 - val_loss: 0.0560 - val_accuracy: 0.9761\n",
      "Epoch 757/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9807 - val_loss: 0.0574 - val_accuracy: 0.9770\n",
      "Epoch 758/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9814 - val_loss: 0.0592 - val_accuracy: 0.9765\n",
      "Epoch 759/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9809 - val_loss: 0.0604 - val_accuracy: 0.9760\n",
      "Epoch 760/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9819 - val_loss: 0.0580 - val_accuracy: 0.9760\n",
      "Epoch 761/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9812 - val_loss: 0.0637 - val_accuracy: 0.9749\n",
      "Epoch 762/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9809 - val_loss: 0.0480 - val_accuracy: 0.9794\n",
      "Epoch 763/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9806 - val_loss: 0.0573 - val_accuracy: 0.9758\n",
      "Epoch 764/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9814 - val_loss: 0.0526 - val_accuracy: 0.9781\n",
      "Epoch 765/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9813 - val_loss: 0.0542 - val_accuracy: 0.9769\n",
      "Epoch 766/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9811 - val_loss: 0.0519 - val_accuracy: 0.9773\n",
      "Epoch 767/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9811 - val_loss: 0.0598 - val_accuracy: 0.9764\n",
      "Epoch 768/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9812 - val_loss: 0.0507 - val_accuracy: 0.9786\n",
      "Epoch 769/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.0581 - val_accuracy: 0.9760\n",
      "Epoch 770/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 0.0574 - val_accuracy: 0.9766\n",
      "Epoch 771/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9811 - val_loss: 0.0561 - val_accuracy: 0.9766\n",
      "Epoch 772/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9816 - val_loss: 0.0522 - val_accuracy: 0.9781\n",
      "Epoch 773/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9817 - val_loss: 0.0588 - val_accuracy: 0.9770\n",
      "Epoch 774/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.0515 - val_accuracy: 0.9784\n",
      "Epoch 775/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9814 - val_loss: 0.0745 - val_accuracy: 0.9737\n",
      "Epoch 776/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9808 - val_loss: 0.0602 - val_accuracy: 0.9758\n",
      "Epoch 777/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 0.0539 - val_accuracy: 0.9771\n",
      "Epoch 778/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9814 - val_loss: 0.0634 - val_accuracy: 0.9754\n",
      "Epoch 779/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9818 - val_loss: 0.0571 - val_accuracy: 0.9776\n",
      "Epoch 780/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.0520 - val_accuracy: 0.9786\n",
      "Epoch 781/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.0709 - val_accuracy: 0.9743\n",
      "Epoch 782/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9817 - val_loss: 0.0579 - val_accuracy: 0.9763\n",
      "Epoch 783/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9803 - val_loss: 0.0568 - val_accuracy: 0.9761\n",
      "Epoch 784/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.0488 - val_accuracy: 0.9791\n",
      "Epoch 785/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9814 - val_loss: 0.0588 - val_accuracy: 0.9764\n",
      "Epoch 786/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9812 - val_loss: 0.0521 - val_accuracy: 0.9781\n",
      "Epoch 787/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9812 - val_loss: 0.0573 - val_accuracy: 0.9766\n",
      "Epoch 788/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.0572 - val_accuracy: 0.9766\n",
      "Epoch 789/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9822 - val_loss: 0.0637 - val_accuracy: 0.9751\n",
      "Epoch 790/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0602 - val_accuracy: 0.9764\n",
      "Epoch 791/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.0580 - val_accuracy: 0.9769\n",
      "Epoch 792/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9829 - val_loss: 0.0532 - val_accuracy: 0.9777\n",
      "Epoch 793/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9804 - val_loss: 0.0586 - val_accuracy: 0.9756\n",
      "Epoch 794/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 0.0575 - val_accuracy: 0.9763\n",
      "Epoch 795/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9813 - val_loss: 0.0562 - val_accuracy: 0.9767\n",
      "Epoch 796/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9804 - val_loss: 0.0597 - val_accuracy: 0.9769\n",
      "Epoch 797/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9824 - val_loss: 0.0646 - val_accuracy: 0.9757\n",
      "Epoch 798/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0571 - val_accuracy: 0.9763\n",
      "Epoch 799/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 0.0516 - val_accuracy: 0.9776\n",
      "Epoch 800/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9817 - val_loss: 0.0569 - val_accuracy: 0.9767\n",
      "Epoch 801/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9828 - val_loss: 0.0560 - val_accuracy: 0.9775\n",
      "Epoch 802/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9797 - val_loss: 0.0560 - val_accuracy: 0.9760\n",
      "Epoch 803/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9811 - val_loss: 0.0585 - val_accuracy: 0.9767\n",
      "Epoch 804/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9818 - val_loss: 0.0605 - val_accuracy: 0.9759\n",
      "Epoch 805/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9818 - val_loss: 0.0551 - val_accuracy: 0.9771\n",
      "Epoch 806/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9821 - val_loss: 0.0641 - val_accuracy: 0.9755\n",
      "Epoch 807/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9813 - val_loss: 0.0539 - val_accuracy: 0.9774\n",
      "Epoch 808/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9827 - val_loss: 0.0561 - val_accuracy: 0.9768\n",
      "Epoch 809/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9813 - val_loss: 0.0515 - val_accuracy: 0.9786\n",
      "Epoch 810/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.0614 - val_accuracy: 0.9765\n",
      "Epoch 811/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9812 - val_loss: 0.0627 - val_accuracy: 0.9758\n",
      "Epoch 812/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9806 - val_loss: 0.0657 - val_accuracy: 0.9749\n",
      "Epoch 813/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 0.0679 - val_accuracy: 0.9748\n",
      "Epoch 814/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9816 - val_loss: 0.0575 - val_accuracy: 0.9760\n",
      "Epoch 815/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.0634 - val_accuracy: 0.9748\n",
      "Epoch 816/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9814 - val_loss: 0.0537 - val_accuracy: 0.9776\n",
      "Epoch 817/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9814 - val_loss: 0.0520 - val_accuracy: 0.9781\n",
      "Epoch 818/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9804 - val_loss: 0.0540 - val_accuracy: 0.9778\n",
      "Epoch 819/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9817 - val_loss: 0.0610 - val_accuracy: 0.9759\n",
      "Epoch 820/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9822 - val_loss: 0.0708 - val_accuracy: 0.9744\n",
      "Epoch 821/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9806 - val_loss: 0.0586 - val_accuracy: 0.9759\n",
      "Epoch 822/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9808 - val_loss: 0.0625 - val_accuracy: 0.9758\n",
      "Epoch 823/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0616 - val_accuracy: 0.9756\n",
      "Epoch 824/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9808 - val_loss: 0.0577 - val_accuracy: 0.9769\n",
      "Epoch 825/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9824 - val_loss: 0.0522 - val_accuracy: 0.9782\n",
      "Epoch 826/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9820 - val_loss: 0.0593 - val_accuracy: 0.9765\n",
      "Epoch 827/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9811 - val_loss: 0.0569 - val_accuracy: 0.9767\n",
      "Epoch 828/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9817 - val_loss: 0.0596 - val_accuracy: 0.9758\n",
      "Epoch 829/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9822 - val_loss: 0.0637 - val_accuracy: 0.9751\n",
      "Epoch 830/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9817 - val_loss: 0.0560 - val_accuracy: 0.9779\n",
      "Epoch 831/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9812 - val_loss: 0.0582 - val_accuracy: 0.9775\n",
      "Epoch 832/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9815 - val_loss: 0.0597 - val_accuracy: 0.9767\n",
      "Epoch 833/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9807 - val_loss: 0.0621 - val_accuracy: 0.9763\n",
      "Epoch 834/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9817 - val_loss: 0.0557 - val_accuracy: 0.9766\n",
      "Epoch 835/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9821 - val_loss: 0.0661 - val_accuracy: 0.9759\n",
      "Epoch 836/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9811 - val_loss: 0.0596 - val_accuracy: 0.9763\n",
      "Epoch 837/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9795 - val_loss: 0.0577 - val_accuracy: 0.9767\n",
      "Epoch 838/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9811 - val_loss: 0.0595 - val_accuracy: 0.9765\n",
      "Epoch 839/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 0.0606 - val_accuracy: 0.9758\n",
      "Epoch 840/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.0659 - val_accuracy: 0.9754\n",
      "Epoch 841/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9820 - val_loss: 0.0606 - val_accuracy: 0.9765\n",
      "Epoch 842/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9818 - val_loss: 0.0540 - val_accuracy: 0.9764\n",
      "Epoch 843/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9820 - val_loss: 0.0563 - val_accuracy: 0.9771\n",
      "Epoch 844/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9816 - val_loss: 0.0594 - val_accuracy: 0.9769\n",
      "Epoch 845/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9822 - val_loss: 0.0589 - val_accuracy: 0.9769\n",
      "Epoch 846/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9809 - val_loss: 0.0535 - val_accuracy: 0.9778\n",
      "Epoch 847/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 0.0532 - val_accuracy: 0.9778\n",
      "Epoch 848/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.0543 - val_accuracy: 0.9778\n",
      "Epoch 849/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 0.0528 - val_accuracy: 0.9777\n",
      "Epoch 850/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9823 - val_loss: 0.0572 - val_accuracy: 0.9768\n",
      "Epoch 851/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9824 - val_loss: 0.0589 - val_accuracy: 0.9764\n",
      "Epoch 852/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9824 - val_loss: 0.0658 - val_accuracy: 0.9754\n",
      "Epoch 853/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9818 - val_loss: 0.0566 - val_accuracy: 0.9769\n",
      "Epoch 854/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9814 - val_loss: 0.0622 - val_accuracy: 0.9767\n",
      "Epoch 855/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9815 - val_loss: 0.0630 - val_accuracy: 0.9757\n",
      "Epoch 856/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 0.0563 - val_accuracy: 0.9773\n",
      "Epoch 857/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9814 - val_loss: 0.0535 - val_accuracy: 0.9775\n",
      "Epoch 858/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9824 - val_loss: 0.0585 - val_accuracy: 0.9776\n",
      "Epoch 859/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 0.0517 - val_accuracy: 0.9785\n",
      "Epoch 860/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 0.0489 - val_accuracy: 0.9792\n",
      "Epoch 861/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9808 - val_loss: 0.0604 - val_accuracy: 0.9759\n",
      "Epoch 862/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9817 - val_loss: 0.0629 - val_accuracy: 0.9758\n",
      "Epoch 863/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9814 - val_loss: 0.0541 - val_accuracy: 0.9776\n",
      "Epoch 864/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9825 - val_loss: 0.0532 - val_accuracy: 0.9771\n",
      "Epoch 865/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.0644 - val_accuracy: 0.9746\n",
      "Epoch 866/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.0547 - val_accuracy: 0.9779\n",
      "Epoch 867/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.0613 - val_accuracy: 0.9763\n",
      "Epoch 868/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9816 - val_loss: 0.0550 - val_accuracy: 0.9781\n",
      "Epoch 869/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9816 - val_loss: 0.0582 - val_accuracy: 0.9765\n",
      "Epoch 870/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9814 - val_loss: 0.0592 - val_accuracy: 0.9759\n",
      "Epoch 871/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9814 - val_loss: 0.0616 - val_accuracy: 0.9758\n",
      "Epoch 872/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9807 - val_loss: 0.0724 - val_accuracy: 0.9744\n",
      "Epoch 873/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9821 - val_loss: 0.0545 - val_accuracy: 0.9771\n",
      "Epoch 874/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9818 - val_loss: 0.0639 - val_accuracy: 0.9755\n",
      "Epoch 875/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9816 - val_loss: 0.0652 - val_accuracy: 0.9758\n",
      "Epoch 876/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9820 - val_loss: 0.0545 - val_accuracy: 0.9767\n",
      "Epoch 877/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9822 - val_loss: 0.0654 - val_accuracy: 0.9755\n",
      "Epoch 878/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9807 - val_loss: 0.0668 - val_accuracy: 0.9751\n",
      "Epoch 879/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9815 - val_loss: 0.0667 - val_accuracy: 0.9745\n",
      "Epoch 880/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9821 - val_loss: 0.0606 - val_accuracy: 0.9765\n",
      "Epoch 881/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.0593 - val_accuracy: 0.9767\n",
      "Epoch 882/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9824 - val_loss: 0.0586 - val_accuracy: 0.9763\n",
      "Epoch 883/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9813 - val_loss: 0.0559 - val_accuracy: 0.9773\n",
      "Epoch 884/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9816 - val_loss: 0.0511 - val_accuracy: 0.9776\n",
      "Epoch 885/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9819 - val_loss: 0.0643 - val_accuracy: 0.9753\n",
      "Epoch 886/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9809 - val_loss: 0.0614 - val_accuracy: 0.9758\n",
      "Epoch 887/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9815 - val_loss: 0.0732 - val_accuracy: 0.9737\n",
      "Epoch 888/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 0.0527 - val_accuracy: 0.9786\n",
      "Epoch 889/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9825 - val_loss: 0.0561 - val_accuracy: 0.9767\n",
      "Epoch 890/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9824 - val_loss: 0.0523 - val_accuracy: 0.9786\n",
      "Epoch 891/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9810 - val_loss: 0.0601 - val_accuracy: 0.9758\n",
      "Epoch 892/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9813 - val_loss: 0.0564 - val_accuracy: 0.9768\n",
      "Epoch 893/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9821 - val_loss: 0.0611 - val_accuracy: 0.9766\n",
      "Epoch 894/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9818 - val_loss: 0.0556 - val_accuracy: 0.9774\n",
      "Epoch 895/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9817 - val_loss: 0.0581 - val_accuracy: 0.9763\n",
      "Epoch 896/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9821 - val_loss: 0.0598 - val_accuracy: 0.9771\n",
      "Epoch 897/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9809 - val_loss: 0.0620 - val_accuracy: 0.9755\n",
      "Epoch 898/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9818 - val_loss: 0.0528 - val_accuracy: 0.9784\n",
      "Epoch 899/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9819 - val_loss: 0.0544 - val_accuracy: 0.9784\n",
      "Epoch 900/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.0586 - val_accuracy: 0.9766\n",
      "Epoch 901/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9820 - val_loss: 0.0584 - val_accuracy: 0.9770\n",
      "Epoch 902/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9817 - val_loss: 0.0641 - val_accuracy: 0.9756\n",
      "Epoch 903/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.0604 - val_accuracy: 0.9761\n",
      "Epoch 904/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9813 - val_loss: 0.0646 - val_accuracy: 0.9761\n",
      "Epoch 905/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9822 - val_loss: 0.0577 - val_accuracy: 0.9768\n",
      "Epoch 906/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.0541 - val_accuracy: 0.9777\n",
      "Epoch 907/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9818 - val_loss: 0.0549 - val_accuracy: 0.9773\n",
      "Epoch 908/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 0.0597 - val_accuracy: 0.9761\n",
      "Epoch 909/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 0.0616 - val_accuracy: 0.9761\n",
      "Epoch 910/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9816 - val_loss: 0.0574 - val_accuracy: 0.9779\n",
      "Epoch 911/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9824 - val_loss: 0.0635 - val_accuracy: 0.9753\n",
      "Epoch 912/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9813 - val_loss: 0.0548 - val_accuracy: 0.9781\n",
      "Epoch 913/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9825 - val_loss: 0.0620 - val_accuracy: 0.9763\n",
      "Epoch 914/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.0654 - val_accuracy: 0.9758\n",
      "Epoch 915/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9816 - val_loss: 0.0550 - val_accuracy: 0.9775\n",
      "Epoch 916/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9817 - val_loss: 0.0554 - val_accuracy: 0.9777\n",
      "Epoch 917/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9817 - val_loss: 0.0543 - val_accuracy: 0.9779\n",
      "Epoch 918/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9822 - val_loss: 0.0638 - val_accuracy: 0.9759\n",
      "Epoch 919/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9826 - val_loss: 0.0570 - val_accuracy: 0.9779\n",
      "Epoch 920/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9822 - val_loss: 0.0589 - val_accuracy: 0.9754\n",
      "Epoch 921/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9811 - val_loss: 0.0570 - val_accuracy: 0.9776\n",
      "Epoch 922/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.0569 - val_accuracy: 0.9769\n",
      "Epoch 923/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9825 - val_loss: 0.0499 - val_accuracy: 0.9786\n",
      "Epoch 924/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9824 - val_loss: 0.0618 - val_accuracy: 0.9755\n",
      "Epoch 925/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9826 - val_loss: 0.0529 - val_accuracy: 0.9787\n",
      "Epoch 926/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9825 - val_loss: 0.0575 - val_accuracy: 0.9771\n",
      "Epoch 927/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9819 - val_loss: 0.0562 - val_accuracy: 0.9774\n",
      "Epoch 928/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.0604 - val_accuracy: 0.9764\n",
      "Epoch 929/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 0.0493 - val_accuracy: 0.9788\n",
      "Epoch 930/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9820 - val_loss: 0.0537 - val_accuracy: 0.9787\n",
      "Epoch 931/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9822 - val_loss: 0.0568 - val_accuracy: 0.9760\n",
      "Epoch 932/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9820 - val_loss: 0.0555 - val_accuracy: 0.9780\n",
      "Epoch 933/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9819 - val_loss: 0.0679 - val_accuracy: 0.9747\n",
      "Epoch 934/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9819 - val_loss: 0.0617 - val_accuracy: 0.9757\n",
      "Epoch 935/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9814 - val_loss: 0.0640 - val_accuracy: 0.9766\n",
      "Epoch 936/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 0.0584 - val_accuracy: 0.9767\n",
      "Epoch 937/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9824 - val_loss: 0.0605 - val_accuracy: 0.9765\n",
      "Epoch 938/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9828 - val_loss: 0.0510 - val_accuracy: 0.9780\n",
      "Epoch 939/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9820 - val_loss: 0.0620 - val_accuracy: 0.9753\n",
      "Epoch 940/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9811 - val_loss: 0.0571 - val_accuracy: 0.9770\n",
      "Epoch 941/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9816 - val_loss: 0.0638 - val_accuracy: 0.9757\n",
      "Epoch 942/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9821 - val_loss: 0.0534 - val_accuracy: 0.9777\n",
      "Epoch 943/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9824 - val_loss: 0.0526 - val_accuracy: 0.9784\n",
      "Epoch 944/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9832 - val_loss: 0.0584 - val_accuracy: 0.9768\n",
      "Epoch 945/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9818 - val_loss: 0.0611 - val_accuracy: 0.9763\n",
      "Epoch 946/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9824 - val_loss: 0.0522 - val_accuracy: 0.9782\n",
      "Epoch 947/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 0.0635 - val_accuracy: 0.9758\n",
      "Epoch 948/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9817 - val_loss: 0.0575 - val_accuracy: 0.9770\n",
      "Epoch 949/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9811 - val_loss: 0.0589 - val_accuracy: 0.9773\n",
      "Epoch 950/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9818 - val_loss: 0.0576 - val_accuracy: 0.9763\n",
      "Epoch 951/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9828 - val_loss: 0.0559 - val_accuracy: 0.9779\n",
      "Epoch 952/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9828 - val_loss: 0.0551 - val_accuracy: 0.9781\n",
      "Epoch 953/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9824 - val_loss: 0.0581 - val_accuracy: 0.9776\n",
      "Epoch 954/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 0.0549 - val_accuracy: 0.9769\n",
      "Epoch 955/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9819 - val_loss: 0.0570 - val_accuracy: 0.9765\n",
      "Epoch 956/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9825 - val_loss: 0.0589 - val_accuracy: 0.9763\n",
      "Epoch 957/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0491 - accuracy: 0.9821 - val_loss: 0.0550 - val_accuracy: 0.9768\n",
      "Epoch 958/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9821 - val_loss: 0.0652 - val_accuracy: 0.9756\n",
      "Epoch 959/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9818 - val_loss: 0.0603 - val_accuracy: 0.9761\n",
      "Epoch 960/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9822 - val_loss: 0.0488 - val_accuracy: 0.9788\n",
      "Epoch 961/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9818 - val_loss: 0.0549 - val_accuracy: 0.9786\n",
      "Epoch 962/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9818 - val_loss: 0.0552 - val_accuracy: 0.9777\n",
      "Epoch 963/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9827 - val_loss: 0.0589 - val_accuracy: 0.9776\n",
      "Epoch 964/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9826 - val_loss: 0.0517 - val_accuracy: 0.9781\n",
      "Epoch 965/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9821 - val_loss: 0.0505 - val_accuracy: 0.9790\n",
      "Epoch 966/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9819 - val_loss: 0.0516 - val_accuracy: 0.9794\n",
      "Epoch 967/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9822 - val_loss: 0.0586 - val_accuracy: 0.9775\n",
      "Epoch 968/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9825 - val_loss: 0.0572 - val_accuracy: 0.9768\n",
      "Epoch 969/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9828 - val_loss: 0.0637 - val_accuracy: 0.9755\n",
      "Epoch 970/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9816 - val_loss: 0.0553 - val_accuracy: 0.9768\n",
      "Epoch 971/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9826 - val_loss: 0.0555 - val_accuracy: 0.9773\n",
      "Epoch 972/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9817 - val_loss: 0.0605 - val_accuracy: 0.9759\n",
      "Epoch 973/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9820 - val_loss: 0.0531 - val_accuracy: 0.9785\n",
      "Epoch 974/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9821 - val_loss: 0.0610 - val_accuracy: 0.9759\n",
      "Epoch 975/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9815 - val_loss: 0.0550 - val_accuracy: 0.9780\n",
      "Epoch 976/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9813 - val_loss: 0.0666 - val_accuracy: 0.9761\n",
      "Epoch 977/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9820 - val_loss: 0.0506 - val_accuracy: 0.9782\n",
      "Epoch 978/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9826 - val_loss: 0.0533 - val_accuracy: 0.9775\n",
      "Epoch 979/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9821 - val_loss: 0.0548 - val_accuracy: 0.9777\n",
      "Epoch 980/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.0601 - val_accuracy: 0.9766\n",
      "Epoch 981/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.0557 - val_accuracy: 0.9771\n",
      "Epoch 982/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9819 - val_loss: 0.0535 - val_accuracy: 0.9775\n",
      "Epoch 983/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 0.0603 - val_accuracy: 0.9766\n",
      "Epoch 984/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 0.0652 - val_accuracy: 0.9756\n",
      "Epoch 985/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9826 - val_loss: 0.0535 - val_accuracy: 0.9776\n",
      "Epoch 986/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.0622 - val_accuracy: 0.9760\n",
      "Epoch 987/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9816 - val_loss: 0.0602 - val_accuracy: 0.9760\n",
      "Epoch 988/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9827 - val_loss: 0.0536 - val_accuracy: 0.9777\n",
      "Epoch 989/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9815 - val_loss: 0.0552 - val_accuracy: 0.9775\n",
      "Epoch 990/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9827 - val_loss: 0.0512 - val_accuracy: 0.9788\n",
      "Epoch 991/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9819 - val_loss: 0.0584 - val_accuracy: 0.9756\n",
      "Epoch 992/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9822 - val_loss: 0.0619 - val_accuracy: 0.9759\n",
      "Epoch 993/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.0655 - val_accuracy: 0.9756\n",
      "Epoch 994/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9822 - val_loss: 0.0568 - val_accuracy: 0.9771\n",
      "Epoch 995/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.0548 - val_accuracy: 0.9776\n",
      "Epoch 996/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9830 - val_loss: 0.0582 - val_accuracy: 0.9760\n",
      "Epoch 997/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9822 - val_loss: 0.0568 - val_accuracy: 0.9773\n",
      "Epoch 998/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9819 - val_loss: 0.0559 - val_accuracy: 0.9774\n",
      "Epoch 999/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9814 - val_loss: 0.0622 - val_accuracy: 0.9767\n",
      "Epoch 1000/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9819 - val_loss: 0.0529 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 970us/step\n",
      "xtrain: (85868, 59), ytrain: (85868,)\n",
      "xvalid: (9011, 59), yvalid: (9011,)\n",
      "xtest: (9012, 59), ytest: (9012,)\n",
      "\n",
      "classification_report_Fold=3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Normal 0       0.99      0.98      0.99      8725\n",
      " Anomalous 1       0.63      0.83      0.72       287\n",
      "\n",
      "    accuracy                           0.98      9012\n",
      "   macro avg       0.81      0.91      0.85      9012\n",
      "weighted avg       0.98      0.98      0.98      9012\n",
      "\n",
      "confusion_matrix_Fold=3:\n",
      "\n",
      "True Negatives:  8585\n",
      "False Positives:  140\n",
      "False Negatives:  49\n",
      "True Positives:  238\n",
      "accuracy_score_Fold=3:\n",
      " 8823 \n",
      "\n",
      "End running time Fold=3: 210214_101717 ,-------------------------- \n",
      "\n",
      "Start running time Data Augmentation_Fold=4: 210214_101717 ,-------------------------- \n",
      "\n",
      "Data Augmentation MSE Label1, iter2==> mean: 1.1209774885741043e-05, min: 2.6535811163314677e-06, max: 0.0002376395609542478\n",
      "End running time Data Augmentation_Fold=4: 210214_103651 ,-------------------------- \n",
      "\n",
      "\n",
      " Start running time Fold=4: 210214_103651 ,-------------------------- \n",
      "\n",
      "\n",
      " Number of Final yXtrain_Fold=4 labeled 0: 69796\n",
      "Number of Final yXtrain_Fold=4 labeled 1: 16072\n",
      "Number of Final yXtrain_Fold=4 labeled 2: 0 \n",
      "\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.4644 - accuracy: 0.8132 - val_loss: 0.2386 - val_accuracy: 0.9624\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8245 - val_loss: 0.2362 - val_accuracy: 0.9595\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8253 - val_loss: 0.2444 - val_accuracy: 0.9522\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8273 - val_loss: 0.2141 - val_accuracy: 0.9542\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8296 - val_loss: 0.2057 - val_accuracy: 0.9574\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8279 - val_loss: 0.2154 - val_accuracy: 0.9556\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8275 - val_loss: 0.2031 - val_accuracy: 0.9554\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8330 - val_loss: 0.2032 - val_accuracy: 0.9551\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8335 - val_loss: 0.2329 - val_accuracy: 0.9478\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8324 - val_loss: 0.2393 - val_accuracy: 0.9484\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8347 - val_loss: 0.2059 - val_accuracy: 0.9532\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8340 - val_loss: 0.2124 - val_accuracy: 0.9485\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8366 - val_loss: 0.2054 - val_accuracy: 0.9509\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8383 - val_loss: 0.2167 - val_accuracy: 0.9442\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8377 - val_loss: 0.2034 - val_accuracy: 0.9454\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8389 - val_loss: 0.2088 - val_accuracy: 0.9444\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8402 - val_loss: 0.1899 - val_accuracy: 0.9483\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8423 - val_loss: 0.2020 - val_accuracy: 0.9437\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8416 - val_loss: 0.1773 - val_accuracy: 0.9518\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8446 - val_loss: 0.2154 - val_accuracy: 0.9371\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8453 - val_loss: 0.1786 - val_accuracy: 0.9498\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8451 - val_loss: 0.1753 - val_accuracy: 0.9524\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8475 - val_loss: 0.1916 - val_accuracy: 0.9443\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8476 - val_loss: 0.1907 - val_accuracy: 0.9418\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8497 - val_loss: 0.1957 - val_accuracy: 0.9394\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8521 - val_loss: 0.1869 - val_accuracy: 0.9435\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8533 - val_loss: 0.2082 - val_accuracy: 0.9322\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8554 - val_loss: 0.1870 - val_accuracy: 0.9426\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8566 - val_loss: 0.1716 - val_accuracy: 0.9488\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.8584 - val_loss: 0.1998 - val_accuracy: 0.9343\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8590 - val_loss: 0.1877 - val_accuracy: 0.9397\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8601 - val_loss: 0.1693 - val_accuracy: 0.9464\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8635 - val_loss: 0.2004 - val_accuracy: 0.9331\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2906 - accuracy: 0.8652 - val_loss: 0.2011 - val_accuracy: 0.9262\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.8670 - val_loss: 0.1656 - val_accuracy: 0.9487\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8685 - val_loss: 0.1721 - val_accuracy: 0.9434\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8696 - val_loss: 0.1516 - val_accuracy: 0.9502\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2740 - accuracy: 0.8732 - val_loss: 0.1897 - val_accuracy: 0.9315\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8737 - val_loss: 0.1732 - val_accuracy: 0.9424\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2683 - accuracy: 0.8763 - val_loss: 0.1707 - val_accuracy: 0.9407\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8794 - val_loss: 0.1525 - val_accuracy: 0.9498\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8799 - val_loss: 0.1748 - val_accuracy: 0.9403\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.8832 - val_loss: 0.1640 - val_accuracy: 0.9427\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2540 - accuracy: 0.8832 - val_loss: 0.1740 - val_accuracy: 0.9381\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.8845 - val_loss: 0.1543 - val_accuracy: 0.9453\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.8848 - val_loss: 0.1578 - val_accuracy: 0.9425\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.8881 - val_loss: 0.1574 - val_accuracy: 0.9416\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2396 - accuracy: 0.8906 - val_loss: 0.1744 - val_accuracy: 0.9316\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.8927 - val_loss: 0.1433 - val_accuracy: 0.9498\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.8962 - val_loss: 0.1371 - val_accuracy: 0.9512\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.8952 - val_loss: 0.1550 - val_accuracy: 0.9426\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.8959 - val_loss: 0.1451 - val_accuracy: 0.9447\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.8981 - val_loss: 0.1337 - val_accuracy: 0.9509\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.8991 - val_loss: 0.1453 - val_accuracy: 0.9456\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9023 - val_loss: 0.1563 - val_accuracy: 0.9389\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9029 - val_loss: 0.1398 - val_accuracy: 0.9462\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9045 - val_loss: 0.1376 - val_accuracy: 0.9465\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9071 - val_loss: 0.1182 - val_accuracy: 0.9573\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9040 - val_loss: 0.1362 - val_accuracy: 0.9477\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9101 - val_loss: 0.1325 - val_accuracy: 0.9496\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9103 - val_loss: 0.1504 - val_accuracy: 0.9383\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9128 - val_loss: 0.1615 - val_accuracy: 0.9324\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9099 - val_loss: 0.1311 - val_accuracy: 0.9490\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9125 - val_loss: 0.1486 - val_accuracy: 0.9411\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9147 - val_loss: 0.1298 - val_accuracy: 0.9509\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1947 - accuracy: 0.9165 - val_loss: 0.1276 - val_accuracy: 0.9505\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9176 - val_loss: 0.1330 - val_accuracy: 0.9453\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.9165 - val_loss: 0.1404 - val_accuracy: 0.9418\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1912 - accuracy: 0.9180 - val_loss: 0.1360 - val_accuracy: 0.9456\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9195 - val_loss: 0.1351 - val_accuracy: 0.9458\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9230 - val_loss: 0.1189 - val_accuracy: 0.9544\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9227 - val_loss: 0.1458 - val_accuracy: 0.9385\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9214 - val_loss: 0.1265 - val_accuracy: 0.9485\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1820 - accuracy: 0.9219 - val_loss: 0.1332 - val_accuracy: 0.9463\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9232 - val_loss: 0.1086 - val_accuracy: 0.9558\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9274 - val_loss: 0.1062 - val_accuracy: 0.9594\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1761 - accuracy: 0.9266 - val_loss: 0.1085 - val_accuracy: 0.9585\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9259 - val_loss: 0.1091 - val_accuracy: 0.9563\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9272 - val_loss: 0.1032 - val_accuracy: 0.9573\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1718 - accuracy: 0.9276 - val_loss: 0.1241 - val_accuracy: 0.9482\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9293 - val_loss: 0.1093 - val_accuracy: 0.9558\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9305 - val_loss: 0.1258 - val_accuracy: 0.9488\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9314 - val_loss: 0.1140 - val_accuracy: 0.9501\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9297 - val_loss: 0.1065 - val_accuracy: 0.9561\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9319 - val_loss: 0.1171 - val_accuracy: 0.9517\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9310 - val_loss: 0.1041 - val_accuracy: 0.9565\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9340 - val_loss: 0.1166 - val_accuracy: 0.9495\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9348 - val_loss: 0.1059 - val_accuracy: 0.9563\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9354 - val_loss: 0.1195 - val_accuracy: 0.9500\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9356 - val_loss: 0.0909 - val_accuracy: 0.9628\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9355 - val_loss: 0.1053 - val_accuracy: 0.9577\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9370 - val_loss: 0.1131 - val_accuracy: 0.9522\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1533 - accuracy: 0.9368 - val_loss: 0.1078 - val_accuracy: 0.9556\n",
      "Epoch 94/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9377 - val_loss: 0.1008 - val_accuracy: 0.9585\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9372 - val_loss: 0.1033 - val_accuracy: 0.9556\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9387 - val_loss: 0.1038 - val_accuracy: 0.9572\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9386 - val_loss: 0.1030 - val_accuracy: 0.9568\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9402 - val_loss: 0.1004 - val_accuracy: 0.9578\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9431 - val_loss: 0.1010 - val_accuracy: 0.9581\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9409 - val_loss: 0.0980 - val_accuracy: 0.9588\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9413 - val_loss: 0.1249 - val_accuracy: 0.9475\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9439 - val_loss: 0.0961 - val_accuracy: 0.9599\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9420 - val_loss: 0.0988 - val_accuracy: 0.9576\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9430 - val_loss: 0.1186 - val_accuracy: 0.9498\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9431 - val_loss: 0.1108 - val_accuracy: 0.9536\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9445 - val_loss: 0.0907 - val_accuracy: 0.9633\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9447 - val_loss: 0.0983 - val_accuracy: 0.9584\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1366 - accuracy: 0.9445 - val_loss: 0.1056 - val_accuracy: 0.9558\n",
      "Epoch 109/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9458 - val_loss: 0.0920 - val_accuracy: 0.9618\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9450 - val_loss: 0.0936 - val_accuracy: 0.9599\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9461 - val_loss: 0.0938 - val_accuracy: 0.9628\n",
      "Epoch 112/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9466 - val_loss: 0.1026 - val_accuracy: 0.9555\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.9465 - val_loss: 0.1017 - val_accuracy: 0.9577\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9471 - val_loss: 0.0945 - val_accuracy: 0.9614\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9487 - val_loss: 0.0797 - val_accuracy: 0.9669\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9474 - val_loss: 0.1360 - val_accuracy: 0.9413\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9482 - val_loss: 0.0830 - val_accuracy: 0.9666\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1326 - accuracy: 0.9463 - val_loss: 0.0935 - val_accuracy: 0.9610\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9502 - val_loss: 0.0975 - val_accuracy: 0.9588\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9479 - val_loss: 0.1154 - val_accuracy: 0.9506\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1296 - accuracy: 0.9484 - val_loss: 0.0854 - val_accuracy: 0.9655\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9506 - val_loss: 0.0911 - val_accuracy: 0.9620\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.9497 - val_loss: 0.0818 - val_accuracy: 0.9663\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9499 - val_loss: 0.1088 - val_accuracy: 0.9541\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9515 - val_loss: 0.0931 - val_accuracy: 0.9610\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9508 - val_loss: 0.0730 - val_accuracy: 0.9687\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9519 - val_loss: 0.0863 - val_accuracy: 0.9657\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9524 - val_loss: 0.0825 - val_accuracy: 0.9663\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9529 - val_loss: 0.0961 - val_accuracy: 0.9591\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1210 - accuracy: 0.9529 - val_loss: 0.0831 - val_accuracy: 0.9654\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9532 - val_loss: 0.0875 - val_accuracy: 0.9632\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9540 - val_loss: 0.0784 - val_accuracy: 0.9687\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1184 - accuracy: 0.9536 - val_loss: 0.1123 - val_accuracy: 0.9511\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9546 - val_loss: 0.0852 - val_accuracy: 0.9645\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9553 - val_loss: 0.0971 - val_accuracy: 0.9579\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9541 - val_loss: 0.0924 - val_accuracy: 0.9615\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9542 - val_loss: 0.0833 - val_accuracy: 0.9640\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9549 - val_loss: 0.0804 - val_accuracy: 0.9673\n",
      "Epoch 139/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9557 - val_loss: 0.0859 - val_accuracy: 0.9636\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9551 - val_loss: 0.0845 - val_accuracy: 0.9657\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9545 - val_loss: 0.0799 - val_accuracy: 0.9673\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9575 - val_loss: 0.0823 - val_accuracy: 0.9658\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9560 - val_loss: 0.0911 - val_accuracy: 0.9622\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9579 - val_loss: 0.0892 - val_accuracy: 0.9618\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9566 - val_loss: 0.0840 - val_accuracy: 0.9655\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9575 - val_loss: 0.0943 - val_accuracy: 0.9586\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9573 - val_loss: 0.0943 - val_accuracy: 0.9613\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9574 - val_loss: 0.0811 - val_accuracy: 0.9666\n",
      "Epoch 149/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1095 - accuracy: 0.9581 - val_loss: 0.0740 - val_accuracy: 0.9700\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9564 - val_loss: 0.0738 - val_accuracy: 0.9707\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9584 - val_loss: 0.0924 - val_accuracy: 0.9607\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.9583 - val_loss: 0.0863 - val_accuracy: 0.9643\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9584 - val_loss: 0.0753 - val_accuracy: 0.9698\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9601 - val_loss: 0.0818 - val_accuracy: 0.9652\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.9590 - val_loss: 0.0963 - val_accuracy: 0.9597\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9612 - val_loss: 0.0836 - val_accuracy: 0.9646\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9591 - val_loss: 0.0849 - val_accuracy: 0.9633\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9596 - val_loss: 0.0682 - val_accuracy: 0.9727\n",
      "Epoch 159/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9601 - val_loss: 0.0732 - val_accuracy: 0.9698\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9606 - val_loss: 0.0715 - val_accuracy: 0.9699\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9586 - val_loss: 0.0973 - val_accuracy: 0.9585\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9617 - val_loss: 0.0983 - val_accuracy: 0.9587\n",
      "Epoch 163/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9614 - val_loss: 0.0819 - val_accuracy: 0.9652\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9619 - val_loss: 0.0939 - val_accuracy: 0.9605\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.9599 - val_loss: 0.0809 - val_accuracy: 0.9658\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9628 - val_loss: 0.0784 - val_accuracy: 0.9674\n",
      "Epoch 167/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0999 - accuracy: 0.9630 - val_loss: 0.0855 - val_accuracy: 0.9634\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9622 - val_loss: 0.0719 - val_accuracy: 0.9708\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9632 - val_loss: 0.0921 - val_accuracy: 0.9599\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9635 - val_loss: 0.0857 - val_accuracy: 0.9626\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9614 - val_loss: 0.0733 - val_accuracy: 0.9699\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9635 - val_loss: 0.0832 - val_accuracy: 0.9643\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9636 - val_loss: 0.0656 - val_accuracy: 0.9730\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9634 - val_loss: 0.0857 - val_accuracy: 0.9618\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9641 - val_loss: 0.0740 - val_accuracy: 0.9690\n",
      "Epoch 176/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1007 - accuracy: 0.9631 - val_loss: 0.0764 - val_accuracy: 0.9685\n",
      "Epoch 177/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9642 - val_loss: 0.0856 - val_accuracy: 0.9637\n",
      "Epoch 178/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9628 - val_loss: 0.0867 - val_accuracy: 0.9610\n",
      "Epoch 179/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9637 - val_loss: 0.0858 - val_accuracy: 0.9625\n",
      "Epoch 180/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9654 - val_loss: 0.0686 - val_accuracy: 0.9718\n",
      "Epoch 181/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9646 - val_loss: 0.0779 - val_accuracy: 0.9662\n",
      "Epoch 182/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.9656 - val_loss: 0.0726 - val_accuracy: 0.9705\n",
      "Epoch 183/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9634 - val_loss: 0.0831 - val_accuracy: 0.9643\n",
      "Epoch 184/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9655 - val_loss: 0.0857 - val_accuracy: 0.9617\n",
      "Epoch 185/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9638 - val_loss: 0.0800 - val_accuracy: 0.9664\n",
      "Epoch 186/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9668 - val_loss: 0.0781 - val_accuracy: 0.9672\n",
      "Epoch 187/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0962 - accuracy: 0.9649 - val_loss: 0.0730 - val_accuracy: 0.9687\n",
      "Epoch 188/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9649 - val_loss: 0.0752 - val_accuracy: 0.9682\n",
      "Epoch 189/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9651 - val_loss: 0.0649 - val_accuracy: 0.9733\n",
      "Epoch 190/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 0.9665 - val_loss: 0.0832 - val_accuracy: 0.9636\n",
      "Epoch 191/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9659 - val_loss: 0.0902 - val_accuracy: 0.9632\n",
      "Epoch 192/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9652 - val_loss: 0.0710 - val_accuracy: 0.9701\n",
      "Epoch 193/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9667 - val_loss: 0.0799 - val_accuracy: 0.9658\n",
      "Epoch 194/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9659 - val_loss: 0.0722 - val_accuracy: 0.9687\n",
      "Epoch 195/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9672 - val_loss: 0.0710 - val_accuracy: 0.9701\n",
      "Epoch 196/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.9680 - val_loss: 0.0782 - val_accuracy: 0.9662\n",
      "Epoch 197/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9663 - val_loss: 0.0722 - val_accuracy: 0.9695\n",
      "Epoch 198/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 0.9671 - val_loss: 0.0919 - val_accuracy: 0.9604\n",
      "Epoch 199/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.9678 - val_loss: 0.0690 - val_accuracy: 0.9699\n",
      "Epoch 200/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9667 - val_loss: 0.0751 - val_accuracy: 0.9693\n",
      "Epoch 201/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9667 - val_loss: 0.0752 - val_accuracy: 0.9675\n",
      "Epoch 202/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9676 - val_loss: 0.0818 - val_accuracy: 0.9649\n",
      "Epoch 203/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9677 - val_loss: 0.0741 - val_accuracy: 0.9684\n",
      "Epoch 204/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9674 - val_loss: 0.0794 - val_accuracy: 0.9663\n",
      "Epoch 205/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9681 - val_loss: 0.0777 - val_accuracy: 0.9673\n",
      "Epoch 206/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9689 - val_loss: 0.0754 - val_accuracy: 0.9680\n",
      "Epoch 207/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9681 - val_loss: 0.0657 - val_accuracy: 0.9719\n",
      "Epoch 208/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9669 - val_loss: 0.0715 - val_accuracy: 0.9711\n",
      "Epoch 209/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9680 - val_loss: 0.0705 - val_accuracy: 0.9699\n",
      "Epoch 210/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9686 - val_loss: 0.0757 - val_accuracy: 0.9677\n",
      "Epoch 211/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9694 - val_loss: 0.0722 - val_accuracy: 0.9695\n",
      "Epoch 212/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9683 - val_loss: 0.0595 - val_accuracy: 0.9754\n",
      "Epoch 213/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9683 - val_loss: 0.0884 - val_accuracy: 0.9624\n",
      "Epoch 214/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9670 - val_loss: 0.0708 - val_accuracy: 0.9693\n",
      "Epoch 215/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9689 - val_loss: 0.0693 - val_accuracy: 0.9700\n",
      "Epoch 216/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9701 - val_loss: 0.0758 - val_accuracy: 0.9667\n",
      "Epoch 217/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9686 - val_loss: 0.0762 - val_accuracy: 0.9670\n",
      "Epoch 218/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9685 - val_loss: 0.0766 - val_accuracy: 0.9666\n",
      "Epoch 219/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9688 - val_loss: 0.0839 - val_accuracy: 0.9630\n",
      "Epoch 220/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9701 - val_loss: 0.0684 - val_accuracy: 0.9707\n",
      "Epoch 221/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9691 - val_loss: 0.0743 - val_accuracy: 0.9682\n",
      "Epoch 222/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9688 - val_loss: 0.0639 - val_accuracy: 0.9728\n",
      "Epoch 223/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9701 - val_loss: 0.0746 - val_accuracy: 0.9676\n",
      "Epoch 224/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9692 - val_loss: 0.0684 - val_accuracy: 0.9705\n",
      "Epoch 225/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 0.0723 - val_accuracy: 0.9695\n",
      "Epoch 226/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9706 - val_loss: 0.0565 - val_accuracy: 0.9767\n",
      "Epoch 227/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9686 - val_loss: 0.0773 - val_accuracy: 0.9676\n",
      "Epoch 228/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9677 - val_loss: 0.0698 - val_accuracy: 0.9701\n",
      "Epoch 229/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9697 - val_loss: 0.0703 - val_accuracy: 0.9701\n",
      "Epoch 230/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9702 - val_loss: 0.0732 - val_accuracy: 0.9691\n",
      "Epoch 231/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9702 - val_loss: 0.0716 - val_accuracy: 0.9680\n",
      "Epoch 232/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9700 - val_loss: 0.0708 - val_accuracy: 0.9707\n",
      "Epoch 233/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9699 - val_loss: 0.0752 - val_accuracy: 0.9677\n",
      "Epoch 234/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9700 - val_loss: 0.0709 - val_accuracy: 0.9688\n",
      "Epoch 235/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9708 - val_loss: 0.0801 - val_accuracy: 0.9648\n",
      "Epoch 236/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9700 - val_loss: 0.0648 - val_accuracy: 0.9724\n",
      "Epoch 237/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0835 - accuracy: 0.9706 - val_loss: 0.0763 - val_accuracy: 0.9668\n",
      "Epoch 238/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9711 - val_loss: 0.0707 - val_accuracy: 0.9707\n",
      "Epoch 239/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9710 - val_loss: 0.0666 - val_accuracy: 0.9717\n",
      "Epoch 240/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9699 - val_loss: 0.0662 - val_accuracy: 0.9725\n",
      "Epoch 241/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0827 - accuracy: 0.9710 - val_loss: 0.0686 - val_accuracy: 0.9705\n",
      "Epoch 242/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9707 - val_loss: 0.0631 - val_accuracy: 0.9734\n",
      "Epoch 243/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9708 - val_loss: 0.0749 - val_accuracy: 0.9678\n",
      "Epoch 244/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9708 - val_loss: 0.0818 - val_accuracy: 0.9645\n",
      "Epoch 245/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9719 - val_loss: 0.0803 - val_accuracy: 0.9649\n",
      "Epoch 246/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9712 - val_loss: 0.0686 - val_accuracy: 0.9707\n",
      "Epoch 247/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9724 - val_loss: 0.0817 - val_accuracy: 0.9655\n",
      "Epoch 248/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9708 - val_loss: 0.0661 - val_accuracy: 0.9716\n",
      "Epoch 249/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9727 - val_loss: 0.0778 - val_accuracy: 0.9652\n",
      "Epoch 250/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9723 - val_loss: 0.0778 - val_accuracy: 0.9655\n",
      "Epoch 251/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9713 - val_loss: 0.0731 - val_accuracy: 0.9680\n",
      "Epoch 252/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9712 - val_loss: 0.0711 - val_accuracy: 0.9694\n",
      "Epoch 253/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9741 - val_loss: 0.0703 - val_accuracy: 0.9704\n",
      "Epoch 254/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9732 - val_loss: 0.0743 - val_accuracy: 0.9678\n",
      "Epoch 255/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9715 - val_loss: 0.0952 - val_accuracy: 0.9596\n",
      "Epoch 256/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9710 - val_loss: 0.0553 - val_accuracy: 0.9780\n",
      "Epoch 257/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9718 - val_loss: 0.0688 - val_accuracy: 0.9710\n",
      "Epoch 258/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9729 - val_loss: 0.0760 - val_accuracy: 0.9673\n",
      "Epoch 259/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9720 - val_loss: 0.0693 - val_accuracy: 0.9700\n",
      "Epoch 260/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9719 - val_loss: 0.0725 - val_accuracy: 0.9682\n",
      "Epoch 261/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9731 - val_loss: 0.0672 - val_accuracy: 0.9711\n",
      "Epoch 262/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.0623 - val_accuracy: 0.9736\n",
      "Epoch 263/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9729 - val_loss: 0.0601 - val_accuracy: 0.9738\n",
      "Epoch 264/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9735 - val_loss: 0.0698 - val_accuracy: 0.9705\n",
      "Epoch 265/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9730 - val_loss: 0.0576 - val_accuracy: 0.9755\n",
      "Epoch 266/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9721 - val_loss: 0.0674 - val_accuracy: 0.9707\n",
      "Epoch 267/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9711 - val_loss: 0.0586 - val_accuracy: 0.9756\n",
      "Epoch 268/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9733 - val_loss: 0.0591 - val_accuracy: 0.9741\n",
      "Epoch 269/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 0.0575 - val_accuracy: 0.9755\n",
      "Epoch 270/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9729 - val_loss: 0.0683 - val_accuracy: 0.9703\n",
      "Epoch 271/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9731 - val_loss: 0.0697 - val_accuracy: 0.9706\n",
      "Epoch 272/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9734 - val_loss: 0.0652 - val_accuracy: 0.9726\n",
      "Epoch 273/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9745 - val_loss: 0.0736 - val_accuracy: 0.9684\n",
      "Epoch 274/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9727 - val_loss: 0.0788 - val_accuracy: 0.9663\n",
      "Epoch 275/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9738 - val_loss: 0.0658 - val_accuracy: 0.9719\n",
      "Epoch 276/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9733 - val_loss: 0.0740 - val_accuracy: 0.9698\n",
      "Epoch 277/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9735 - val_loss: 0.0690 - val_accuracy: 0.9715\n",
      "Epoch 278/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9741 - val_loss: 0.0638 - val_accuracy: 0.9726\n",
      "Epoch 279/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9730 - val_loss: 0.0718 - val_accuracy: 0.9696\n",
      "Epoch 280/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9735 - val_loss: 0.0927 - val_accuracy: 0.9616\n",
      "Epoch 281/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9731 - val_loss: 0.0652 - val_accuracy: 0.9717\n",
      "Epoch 282/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9741 - val_loss: 0.0639 - val_accuracy: 0.9726\n",
      "Epoch 283/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9741 - val_loss: 0.0687 - val_accuracy: 0.9725\n",
      "Epoch 284/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9745 - val_loss: 0.0692 - val_accuracy: 0.9700\n",
      "Epoch 285/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9740 - val_loss: 0.0580 - val_accuracy: 0.9758\n",
      "Epoch 286/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9740 - val_loss: 0.0596 - val_accuracy: 0.9746\n",
      "Epoch 287/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9735 - val_loss: 0.0694 - val_accuracy: 0.9711\n",
      "Epoch 288/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9737 - val_loss: 0.0674 - val_accuracy: 0.9710\n",
      "Epoch 289/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9747 - val_loss: 0.0659 - val_accuracy: 0.9718\n",
      "Epoch 290/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9746 - val_loss: 0.0605 - val_accuracy: 0.9743\n",
      "Epoch 291/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9738 - val_loss: 0.0653 - val_accuracy: 0.9728\n",
      "Epoch 292/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9744 - val_loss: 0.0671 - val_accuracy: 0.9716\n",
      "Epoch 293/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9738 - val_loss: 0.0744 - val_accuracy: 0.9697\n",
      "Epoch 294/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9745 - val_loss: 0.0711 - val_accuracy: 0.9707\n",
      "Epoch 295/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0747 - accuracy: 0.9739 - val_loss: 0.0714 - val_accuracy: 0.9703\n",
      "Epoch 296/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9746 - val_loss: 0.0799 - val_accuracy: 0.9665\n",
      "Epoch 297/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9744 - val_loss: 0.0748 - val_accuracy: 0.9687\n",
      "Epoch 298/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9747 - val_loss: 0.0623 - val_accuracy: 0.9739\n",
      "Epoch 299/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9751 - val_loss: 0.0642 - val_accuracy: 0.9729\n",
      "Epoch 300/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9742 - val_loss: 0.0663 - val_accuracy: 0.9727\n",
      "Epoch 301/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9737 - val_loss: 0.0692 - val_accuracy: 0.9728\n",
      "Epoch 302/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9752 - val_loss: 0.0668 - val_accuracy: 0.9718\n",
      "Epoch 303/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9752 - val_loss: 0.0594 - val_accuracy: 0.9747\n",
      "Epoch 304/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9742 - val_loss: 0.0643 - val_accuracy: 0.9730\n",
      "Epoch 305/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9751 - val_loss: 0.0727 - val_accuracy: 0.9698\n",
      "Epoch 306/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9755 - val_loss: 0.0593 - val_accuracy: 0.9757\n",
      "Epoch 307/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9757 - val_loss: 0.0722 - val_accuracy: 0.9711\n",
      "Epoch 308/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9741 - val_loss: 0.0685 - val_accuracy: 0.9723\n",
      "Epoch 309/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9755 - val_loss: 0.0758 - val_accuracy: 0.9695\n",
      "Epoch 310/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9753 - val_loss: 0.0631 - val_accuracy: 0.9741\n",
      "Epoch 311/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9767 - val_loss: 0.0610 - val_accuracy: 0.9749\n",
      "Epoch 312/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9759 - val_loss: 0.0750 - val_accuracy: 0.9690\n",
      "Epoch 313/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9745 - val_loss: 0.0673 - val_accuracy: 0.9739\n",
      "Epoch 314/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9762 - val_loss: 0.0556 - val_accuracy: 0.9758\n",
      "Epoch 315/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.0566 - val_accuracy: 0.9758\n",
      "Epoch 316/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 0.0683 - val_accuracy: 0.9718\n",
      "Epoch 317/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9756 - val_loss: 0.0571 - val_accuracy: 0.9758\n",
      "Epoch 318/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9760 - val_loss: 0.0700 - val_accuracy: 0.9714\n",
      "Epoch 319/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9751 - val_loss: 0.0619 - val_accuracy: 0.9744\n",
      "Epoch 320/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9757 - val_loss: 0.0625 - val_accuracy: 0.9743\n",
      "Epoch 321/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9762 - val_loss: 0.0615 - val_accuracy: 0.9739\n",
      "Epoch 322/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 0.0636 - val_accuracy: 0.9744\n",
      "Epoch 323/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9761 - val_loss: 0.0604 - val_accuracy: 0.9749\n",
      "Epoch 324/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9760 - val_loss: 0.0681 - val_accuracy: 0.9726\n",
      "Epoch 325/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9754 - val_loss: 0.0754 - val_accuracy: 0.9694\n",
      "Epoch 326/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 0.0656 - val_accuracy: 0.9734\n",
      "Epoch 327/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9755 - val_loss: 0.0684 - val_accuracy: 0.9724\n",
      "Epoch 328/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9755 - val_loss: 0.0654 - val_accuracy: 0.9729\n",
      "Epoch 329/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9765 - val_loss: 0.0691 - val_accuracy: 0.9724\n",
      "Epoch 330/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9760 - val_loss: 0.0770 - val_accuracy: 0.9699\n",
      "Epoch 331/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9761 - val_loss: 0.0604 - val_accuracy: 0.9748\n",
      "Epoch 332/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9765 - val_loss: 0.0631 - val_accuracy: 0.9735\n",
      "Epoch 333/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9768 - val_loss: 0.0607 - val_accuracy: 0.9757\n",
      "Epoch 334/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9758 - val_loss: 0.0612 - val_accuracy: 0.9757\n",
      "Epoch 335/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9762 - val_loss: 0.0618 - val_accuracy: 0.9743\n",
      "Epoch 336/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9776 - val_loss: 0.0716 - val_accuracy: 0.9721\n",
      "Epoch 337/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9767 - val_loss: 0.0603 - val_accuracy: 0.9760\n",
      "Epoch 338/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9764 - val_loss: 0.0668 - val_accuracy: 0.9730\n",
      "Epoch 339/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9769 - val_loss: 0.0641 - val_accuracy: 0.9729\n",
      "Epoch 340/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9765 - val_loss: 0.0567 - val_accuracy: 0.9767\n",
      "Epoch 341/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9765 - val_loss: 0.0813 - val_accuracy: 0.9683\n",
      "Epoch 342/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9771 - val_loss: 0.0694 - val_accuracy: 0.9720\n",
      "Epoch 343/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9767 - val_loss: 0.0637 - val_accuracy: 0.9740\n",
      "Epoch 344/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9763 - val_loss: 0.0700 - val_accuracy: 0.9720\n",
      "Epoch 345/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9771 - val_loss: 0.0623 - val_accuracy: 0.9746\n",
      "Epoch 346/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9752 - val_loss: 0.0699 - val_accuracy: 0.9715\n",
      "Epoch 347/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9769 - val_loss: 0.0710 - val_accuracy: 0.9717\n",
      "Epoch 348/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9765 - val_loss: 0.0676 - val_accuracy: 0.9728\n",
      "Epoch 349/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9765 - val_loss: 0.0547 - val_accuracy: 0.9767\n",
      "Epoch 350/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9767 - val_loss: 0.0574 - val_accuracy: 0.9759\n",
      "Epoch 351/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0684 - accuracy: 0.9768 - val_loss: 0.0571 - val_accuracy: 0.9767\n",
      "Epoch 352/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9766 - val_loss: 0.0606 - val_accuracy: 0.9753\n",
      "Epoch 353/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9771 - val_loss: 0.0592 - val_accuracy: 0.9757\n",
      "Epoch 354/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9774 - val_loss: 0.0638 - val_accuracy: 0.9747\n",
      "Epoch 355/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9768 - val_loss: 0.0583 - val_accuracy: 0.9759\n",
      "Epoch 356/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9773 - val_loss: 0.0604 - val_accuracy: 0.9749\n",
      "Epoch 357/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 0.0784 - val_accuracy: 0.9698\n",
      "Epoch 358/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9767 - val_loss: 0.0654 - val_accuracy: 0.9735\n",
      "Epoch 359/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 0.0724 - val_accuracy: 0.9721\n",
      "Epoch 360/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9772 - val_loss: 0.0599 - val_accuracy: 0.9749\n",
      "Epoch 361/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9764 - val_loss: 0.0734 - val_accuracy: 0.9724\n",
      "Epoch 362/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9761 - val_loss: 0.0571 - val_accuracy: 0.9761\n",
      "Epoch 363/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9759 - val_loss: 0.0689 - val_accuracy: 0.9734\n",
      "Epoch 364/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9776 - val_loss: 0.0581 - val_accuracy: 0.9751\n",
      "Epoch 365/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9772 - val_loss: 0.0682 - val_accuracy: 0.9729\n",
      "Epoch 366/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9767 - val_loss: 0.0820 - val_accuracy: 0.9680\n",
      "Epoch 367/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9764 - val_loss: 0.0617 - val_accuracy: 0.9760\n",
      "Epoch 368/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9774 - val_loss: 0.0604 - val_accuracy: 0.9745\n",
      "Epoch 369/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9771 - val_loss: 0.0709 - val_accuracy: 0.9720\n",
      "Epoch 370/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9763 - val_loss: 0.0578 - val_accuracy: 0.9754\n",
      "Epoch 371/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9775 - val_loss: 0.0665 - val_accuracy: 0.9730\n",
      "Epoch 372/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0659 - accuracy: 0.9775 - val_loss: 0.0695 - val_accuracy: 0.9730\n",
      "Epoch 373/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0643 - accuracy: 0.9784 - val_loss: 0.0758 - val_accuracy: 0.9709\n",
      "Epoch 374/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0651 - accuracy: 0.9775 - val_loss: 0.0582 - val_accuracy: 0.9756\n",
      "Epoch 375/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9773 - val_loss: 0.0623 - val_accuracy: 0.9745\n",
      "Epoch 376/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0668 - accuracy: 0.9770 - val_loss: 0.0695 - val_accuracy: 0.9735\n",
      "Epoch 377/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9778 - val_loss: 0.0566 - val_accuracy: 0.9758\n",
      "Epoch 378/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0673 - accuracy: 0.9768 - val_loss: 0.0543 - val_accuracy: 0.9781\n",
      "Epoch 379/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9771 - val_loss: 0.0732 - val_accuracy: 0.9716\n",
      "Epoch 380/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9775 - val_loss: 0.0601 - val_accuracy: 0.9755\n",
      "Epoch 381/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9770 - val_loss: 0.0721 - val_accuracy: 0.9718\n",
      "Epoch 382/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9771 - val_loss: 0.0610 - val_accuracy: 0.9758\n",
      "Epoch 383/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9775 - val_loss: 0.0597 - val_accuracy: 0.9757\n",
      "Epoch 384/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0657 - accuracy: 0.9781 - val_loss: 0.0631 - val_accuracy: 0.9749\n",
      "Epoch 385/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9778 - val_loss: 0.0669 - val_accuracy: 0.9744\n",
      "Epoch 386/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9773 - val_loss: 0.0699 - val_accuracy: 0.9734\n",
      "Epoch 387/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9778 - val_loss: 0.0682 - val_accuracy: 0.9740\n",
      "Epoch 388/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9777 - val_loss: 0.0583 - val_accuracy: 0.9764\n",
      "Epoch 389/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9766 - val_loss: 0.0630 - val_accuracy: 0.9745\n",
      "Epoch 390/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9781 - val_loss: 0.0645 - val_accuracy: 0.9748\n",
      "Epoch 391/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9778 - val_loss: 0.0635 - val_accuracy: 0.9751\n",
      "Epoch 392/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9790 - val_loss: 0.0677 - val_accuracy: 0.9729\n",
      "Epoch 393/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9779 - val_loss: 0.0639 - val_accuracy: 0.9747\n",
      "Epoch 394/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.0712 - val_accuracy: 0.9714\n",
      "Epoch 395/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9778 - val_loss: 0.0652 - val_accuracy: 0.9744\n",
      "Epoch 396/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0641 - accuracy: 0.9779 - val_loss: 0.0679 - val_accuracy: 0.9734\n",
      "Epoch 397/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9772 - val_loss: 0.0639 - val_accuracy: 0.9745\n",
      "Epoch 398/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.0645 - val_accuracy: 0.9754\n",
      "Epoch 399/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9778 - val_loss: 0.0559 - val_accuracy: 0.9768\n",
      "Epoch 400/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9779 - val_loss: 0.0577 - val_accuracy: 0.9768\n",
      "Epoch 401/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9771 - val_loss: 0.0624 - val_accuracy: 0.9750\n",
      "Epoch 402/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.0634 - val_accuracy: 0.9746\n",
      "Epoch 403/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 0.0663 - val_accuracy: 0.9745\n",
      "Epoch 404/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9773 - val_loss: 0.0667 - val_accuracy: 0.9744\n",
      "Epoch 405/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9786 - val_loss: 0.0552 - val_accuracy: 0.9766\n",
      "Epoch 406/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9766 - val_loss: 0.0670 - val_accuracy: 0.9749\n",
      "Epoch 407/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 0.0687 - val_accuracy: 0.9745\n",
      "Epoch 408/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9779 - val_loss: 0.0648 - val_accuracy: 0.9750\n",
      "Epoch 409/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9792 - val_loss: 0.0571 - val_accuracy: 0.9770\n",
      "Epoch 410/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9791 - val_loss: 0.0563 - val_accuracy: 0.9770\n",
      "Epoch 411/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9777 - val_loss: 0.0563 - val_accuracy: 0.9768\n",
      "Epoch 412/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9785 - val_loss: 0.0675 - val_accuracy: 0.9736\n",
      "Epoch 413/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9773 - val_loss: 0.0630 - val_accuracy: 0.9750\n",
      "Epoch 414/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9779 - val_loss: 0.0607 - val_accuracy: 0.9755\n",
      "Epoch 415/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9779 - val_loss: 0.0569 - val_accuracy: 0.9759\n",
      "Epoch 416/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9784 - val_loss: 0.0544 - val_accuracy: 0.9775\n",
      "Epoch 417/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9768 - val_loss: 0.0616 - val_accuracy: 0.9753\n",
      "Epoch 418/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9777 - val_loss: 0.0662 - val_accuracy: 0.9751\n",
      "Epoch 419/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9780 - val_loss: 0.0528 - val_accuracy: 0.9774\n",
      "Epoch 420/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9774 - val_loss: 0.0699 - val_accuracy: 0.9743\n",
      "Epoch 421/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9773 - val_loss: 0.0607 - val_accuracy: 0.9748\n",
      "Epoch 422/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9783 - val_loss: 0.0623 - val_accuracy: 0.9757\n",
      "Epoch 423/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9784 - val_loss: 0.0583 - val_accuracy: 0.9757\n",
      "Epoch 424/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9781 - val_loss: 0.0610 - val_accuracy: 0.9753\n",
      "Epoch 425/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9785 - val_loss: 0.0611 - val_accuracy: 0.9755\n",
      "Epoch 426/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9779 - val_loss: 0.0641 - val_accuracy: 0.9747\n",
      "Epoch 427/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9787 - val_loss: 0.0682 - val_accuracy: 0.9739\n",
      "Epoch 428/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9783 - val_loss: 0.0638 - val_accuracy: 0.9745\n",
      "Epoch 429/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9788 - val_loss: 0.0707 - val_accuracy: 0.9734\n",
      "Epoch 430/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9779 - val_loss: 0.0591 - val_accuracy: 0.9759\n",
      "Epoch 431/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9784 - val_loss: 0.0681 - val_accuracy: 0.9739\n",
      "Epoch 432/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9773 - val_loss: 0.0679 - val_accuracy: 0.9728\n",
      "Epoch 433/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9788 - val_loss: 0.0660 - val_accuracy: 0.9750\n",
      "Epoch 434/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9794 - val_loss: 0.0538 - val_accuracy: 0.9777\n",
      "Epoch 435/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9790 - val_loss: 0.0674 - val_accuracy: 0.9739\n",
      "Epoch 436/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9785 - val_loss: 0.0575 - val_accuracy: 0.9764\n",
      "Epoch 437/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9786 - val_loss: 0.0604 - val_accuracy: 0.9759\n",
      "Epoch 438/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9776 - val_loss: 0.0679 - val_accuracy: 0.9739\n",
      "Epoch 439/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9774 - val_loss: 0.0615 - val_accuracy: 0.9755\n",
      "Epoch 440/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9785 - val_loss: 0.0678 - val_accuracy: 0.9737\n",
      "Epoch 441/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9788 - val_loss: 0.0704 - val_accuracy: 0.9735\n",
      "Epoch 442/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9776 - val_loss: 0.0644 - val_accuracy: 0.9753\n",
      "Epoch 443/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9784 - val_loss: 0.0674 - val_accuracy: 0.9746\n",
      "Epoch 444/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9778 - val_loss: 0.0616 - val_accuracy: 0.9763\n",
      "Epoch 445/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9785 - val_loss: 0.0667 - val_accuracy: 0.9744\n",
      "Epoch 446/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9794 - val_loss: 0.0565 - val_accuracy: 0.9768\n",
      "Epoch 447/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9791 - val_loss: 0.0599 - val_accuracy: 0.9763\n",
      "Epoch 448/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9788 - val_loss: 0.0569 - val_accuracy: 0.9770\n",
      "Epoch 449/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9789 - val_loss: 0.0769 - val_accuracy: 0.9714\n",
      "Epoch 450/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9778 - val_loss: 0.0548 - val_accuracy: 0.9774\n",
      "Epoch 451/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9791 - val_loss: 0.0705 - val_accuracy: 0.9736\n",
      "Epoch 452/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.0629 - val_accuracy: 0.9753\n",
      "Epoch 453/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9788 - val_loss: 0.0623 - val_accuracy: 0.9755\n",
      "Epoch 454/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9791 - val_loss: 0.0651 - val_accuracy: 0.9749\n",
      "Epoch 455/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9792 - val_loss: 0.0531 - val_accuracy: 0.9776\n",
      "Epoch 456/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9786 - val_loss: 0.0586 - val_accuracy: 0.9767\n",
      "Epoch 457/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9794 - val_loss: 0.0582 - val_accuracy: 0.9765\n",
      "Epoch 458/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9788 - val_loss: 0.0593 - val_accuracy: 0.9763\n",
      "Epoch 459/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9783 - val_loss: 0.0664 - val_accuracy: 0.9748\n",
      "Epoch 460/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9791 - val_loss: 0.0621 - val_accuracy: 0.9750\n",
      "Epoch 461/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9787 - val_loss: 0.0571 - val_accuracy: 0.9755\n",
      "Epoch 462/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9794 - val_loss: 0.0587 - val_accuracy: 0.9768\n",
      "Epoch 463/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9782 - val_loss: 0.0631 - val_accuracy: 0.9750\n",
      "Epoch 464/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9792 - val_loss: 0.0574 - val_accuracy: 0.9768\n",
      "Epoch 465/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9780 - val_loss: 0.0633 - val_accuracy: 0.9755\n",
      "Epoch 466/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9784 - val_loss: 0.0665 - val_accuracy: 0.9744\n",
      "Epoch 467/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9788 - val_loss: 0.0650 - val_accuracy: 0.9749\n",
      "Epoch 468/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9786 - val_loss: 0.0596 - val_accuracy: 0.9761\n",
      "Epoch 469/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9790 - val_loss: 0.0544 - val_accuracy: 0.9768\n",
      "Epoch 470/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9790 - val_loss: 0.0726 - val_accuracy: 0.9731\n",
      "Epoch 471/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9782 - val_loss: 0.0603 - val_accuracy: 0.9766\n",
      "Epoch 472/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9793 - val_loss: 0.0701 - val_accuracy: 0.9740\n",
      "Epoch 473/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9777 - val_loss: 0.0545 - val_accuracy: 0.9775\n",
      "Epoch 474/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9790 - val_loss: 0.0631 - val_accuracy: 0.9758\n",
      "Epoch 475/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9794 - val_loss: 0.0669 - val_accuracy: 0.9739\n",
      "Epoch 476/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9783 - val_loss: 0.0535 - val_accuracy: 0.9776\n",
      "Epoch 477/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9782 - val_loss: 0.0549 - val_accuracy: 0.9784\n",
      "Epoch 478/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9788 - val_loss: 0.0633 - val_accuracy: 0.9758\n",
      "Epoch 479/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9797 - val_loss: 0.0605 - val_accuracy: 0.9758\n",
      "Epoch 480/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9793 - val_loss: 0.0643 - val_accuracy: 0.9750\n",
      "Epoch 481/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9795 - val_loss: 0.0558 - val_accuracy: 0.9770\n",
      "Epoch 482/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9782 - val_loss: 0.0628 - val_accuracy: 0.9759\n",
      "Epoch 483/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9794 - val_loss: 0.0597 - val_accuracy: 0.9757\n",
      "Epoch 484/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9787 - val_loss: 0.0689 - val_accuracy: 0.9735\n",
      "Epoch 485/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9785 - val_loss: 0.0630 - val_accuracy: 0.9759\n",
      "Epoch 486/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9802 - val_loss: 0.0680 - val_accuracy: 0.9744\n",
      "Epoch 487/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9789 - val_loss: 0.0564 - val_accuracy: 0.9775\n",
      "Epoch 488/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9789 - val_loss: 0.0724 - val_accuracy: 0.9731\n",
      "Epoch 489/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9797 - val_loss: 0.0649 - val_accuracy: 0.9754\n",
      "Epoch 490/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9789 - val_loss: 0.0597 - val_accuracy: 0.9760\n",
      "Epoch 491/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9806 - val_loss: 0.0660 - val_accuracy: 0.9751\n",
      "Epoch 492/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9789 - val_loss: 0.0696 - val_accuracy: 0.9744\n",
      "Epoch 493/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9796 - val_loss: 0.0597 - val_accuracy: 0.9764\n",
      "Epoch 494/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9798 - val_loss: 0.0598 - val_accuracy: 0.9766\n",
      "Epoch 495/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9799 - val_loss: 0.0616 - val_accuracy: 0.9760\n",
      "Epoch 496/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9800 - val_loss: 0.0591 - val_accuracy: 0.9768\n",
      "Epoch 497/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0593 - accuracy: 0.9788 - val_loss: 0.0541 - val_accuracy: 0.9775\n",
      "Epoch 498/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9789 - val_loss: 0.0721 - val_accuracy: 0.9724\n",
      "Epoch 499/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9789 - val_loss: 0.0566 - val_accuracy: 0.9773\n",
      "Epoch 500/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9801 - val_loss: 0.0570 - val_accuracy: 0.9768\n",
      "Epoch 501/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9796 - val_loss: 0.0695 - val_accuracy: 0.9741\n",
      "Epoch 502/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9798 - val_loss: 0.0650 - val_accuracy: 0.9751\n",
      "Epoch 503/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9789 - val_loss: 0.0638 - val_accuracy: 0.9756\n",
      "Epoch 504/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 0.0710 - val_accuracy: 0.9733\n",
      "Epoch 505/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9798 - val_loss: 0.0603 - val_accuracy: 0.9764\n",
      "Epoch 506/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9787 - val_loss: 0.0595 - val_accuracy: 0.9763\n",
      "Epoch 507/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9794 - val_loss: 0.0625 - val_accuracy: 0.9767\n",
      "Epoch 508/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9795 - val_loss: 0.0657 - val_accuracy: 0.9756\n",
      "Epoch 509/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9789 - val_loss: 0.0624 - val_accuracy: 0.9761\n",
      "Epoch 510/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9797 - val_loss: 0.0677 - val_accuracy: 0.9741\n",
      "Epoch 511/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9794 - val_loss: 0.0747 - val_accuracy: 0.9726\n",
      "Epoch 512/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9790 - val_loss: 0.0601 - val_accuracy: 0.9767\n",
      "Epoch 513/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9799 - val_loss: 0.0599 - val_accuracy: 0.9763\n",
      "Epoch 514/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9795 - val_loss: 0.0624 - val_accuracy: 0.9754\n",
      "Epoch 515/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9793 - val_loss: 0.0622 - val_accuracy: 0.9760\n",
      "Epoch 516/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9798 - val_loss: 0.0590 - val_accuracy: 0.9775\n",
      "Epoch 517/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9799 - val_loss: 0.0702 - val_accuracy: 0.9741\n",
      "Epoch 518/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9798 - val_loss: 0.0604 - val_accuracy: 0.9770\n",
      "Epoch 519/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9799 - val_loss: 0.0566 - val_accuracy: 0.9768\n",
      "Epoch 520/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9798 - val_loss: 0.0614 - val_accuracy: 0.9773\n",
      "Epoch 521/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9798 - val_loss: 0.0578 - val_accuracy: 0.9776\n",
      "Epoch 522/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9790 - val_loss: 0.0552 - val_accuracy: 0.9770\n",
      "Epoch 523/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9799 - val_loss: 0.0562 - val_accuracy: 0.9770\n",
      "Epoch 524/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9792 - val_loss: 0.0672 - val_accuracy: 0.9748\n",
      "Epoch 525/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9803 - val_loss: 0.0669 - val_accuracy: 0.9744\n",
      "Epoch 526/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9796 - val_loss: 0.0535 - val_accuracy: 0.9774\n",
      "Epoch 527/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9796 - val_loss: 0.0640 - val_accuracy: 0.9763\n",
      "Epoch 528/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 0.0560 - val_accuracy: 0.9773\n",
      "Epoch 529/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9797 - val_loss: 0.0659 - val_accuracy: 0.9748\n",
      "Epoch 530/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9809 - val_loss: 0.0558 - val_accuracy: 0.9771\n",
      "Epoch 531/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9807 - val_loss: 0.0590 - val_accuracy: 0.9761\n",
      "Epoch 532/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9793 - val_loss: 0.0690 - val_accuracy: 0.9744\n",
      "Epoch 533/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9795 - val_loss: 0.0601 - val_accuracy: 0.9764\n",
      "Epoch 534/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9805 - val_loss: 0.0646 - val_accuracy: 0.9759\n",
      "Epoch 535/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.0634 - val_accuracy: 0.9749\n",
      "Epoch 536/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9793 - val_loss: 0.0585 - val_accuracy: 0.9767\n",
      "Epoch 537/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9792 - val_loss: 0.0633 - val_accuracy: 0.9763\n",
      "Epoch 538/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9802 - val_loss: 0.0619 - val_accuracy: 0.9769\n",
      "Epoch 539/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9798 - val_loss: 0.0555 - val_accuracy: 0.9781\n",
      "Epoch 540/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9794 - val_loss: 0.0640 - val_accuracy: 0.9750\n",
      "Epoch 541/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9799 - val_loss: 0.0667 - val_accuracy: 0.9750\n",
      "Epoch 542/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9800 - val_loss: 0.0630 - val_accuracy: 0.9763\n",
      "Epoch 543/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9790 - val_loss: 0.0583 - val_accuracy: 0.9771\n",
      "Epoch 544/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9799 - val_loss: 0.0633 - val_accuracy: 0.9755\n",
      "Epoch 545/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9790 - val_loss: 0.0672 - val_accuracy: 0.9745\n",
      "Epoch 546/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9802 - val_loss: 0.0613 - val_accuracy: 0.9777\n",
      "Epoch 547/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9798 - val_loss: 0.0761 - val_accuracy: 0.9735\n",
      "Epoch 548/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9803 - val_loss: 0.0619 - val_accuracy: 0.9759\n",
      "Epoch 549/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9800 - val_loss: 0.0588 - val_accuracy: 0.9773\n",
      "Epoch 550/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9789 - val_loss: 0.0811 - val_accuracy: 0.9718\n",
      "Epoch 551/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9798 - val_loss: 0.0615 - val_accuracy: 0.9768\n",
      "Epoch 552/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9793 - val_loss: 0.0618 - val_accuracy: 0.9764\n",
      "Epoch 553/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.0571 - val_accuracy: 0.9774\n",
      "Epoch 554/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 0.0663 - val_accuracy: 0.9754\n",
      "Epoch 555/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9802 - val_loss: 0.0678 - val_accuracy: 0.9754\n",
      "Epoch 556/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9798 - val_loss: 0.0623 - val_accuracy: 0.9756\n",
      "Epoch 557/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9793 - val_loss: 0.0598 - val_accuracy: 0.9769\n",
      "Epoch 558/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9809 - val_loss: 0.0573 - val_accuracy: 0.9775\n",
      "Epoch 559/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9808 - val_loss: 0.0687 - val_accuracy: 0.9750\n",
      "Epoch 560/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9808 - val_loss: 0.0571 - val_accuracy: 0.9769\n",
      "Epoch 561/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9807 - val_loss: 0.0664 - val_accuracy: 0.9754\n",
      "Epoch 562/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9800 - val_loss: 0.0526 - val_accuracy: 0.9778\n",
      "Epoch 563/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9809 - val_loss: 0.0831 - val_accuracy: 0.9719\n",
      "Epoch 564/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9803 - val_loss: 0.0612 - val_accuracy: 0.9764\n",
      "Epoch 565/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.0589 - val_accuracy: 0.9771\n",
      "Epoch 566/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9805 - val_loss: 0.0682 - val_accuracy: 0.9759\n",
      "Epoch 567/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9801 - val_loss: 0.0569 - val_accuracy: 0.9765\n",
      "Epoch 568/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9800 - val_loss: 0.0638 - val_accuracy: 0.9753\n",
      "Epoch 569/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9802 - val_loss: 0.0674 - val_accuracy: 0.9753\n",
      "Epoch 570/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9807 - val_loss: 0.0661 - val_accuracy: 0.9757\n",
      "Epoch 571/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9800 - val_loss: 0.0699 - val_accuracy: 0.9754\n",
      "Epoch 572/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9808 - val_loss: 0.0628 - val_accuracy: 0.9761\n",
      "Epoch 573/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9808 - val_loss: 0.0563 - val_accuracy: 0.9768\n",
      "Epoch 574/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9800 - val_loss: 0.0599 - val_accuracy: 0.9768\n",
      "Epoch 575/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9803 - val_loss: 0.0666 - val_accuracy: 0.9758\n",
      "Epoch 576/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0631 - val_accuracy: 0.9763\n",
      "Epoch 577/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9801 - val_loss: 0.0632 - val_accuracy: 0.9765\n",
      "Epoch 578/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9804 - val_loss: 0.0634 - val_accuracy: 0.9755\n",
      "Epoch 579/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9804 - val_loss: 0.0753 - val_accuracy: 0.9729\n",
      "Epoch 580/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9801 - val_loss: 0.0716 - val_accuracy: 0.9740\n",
      "Epoch 581/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9811 - val_loss: 0.0657 - val_accuracy: 0.9755\n",
      "Epoch 582/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9807 - val_loss: 0.0739 - val_accuracy: 0.9736\n",
      "Epoch 583/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9805 - val_loss: 0.0613 - val_accuracy: 0.9769\n",
      "Epoch 584/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9805 - val_loss: 0.0646 - val_accuracy: 0.9761\n",
      "Epoch 585/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 0.0804 - val_accuracy: 0.9720\n",
      "Epoch 586/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9800 - val_loss: 0.0605 - val_accuracy: 0.9769\n",
      "Epoch 587/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9809 - val_loss: 0.0634 - val_accuracy: 0.9769\n",
      "Epoch 588/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9806 - val_loss: 0.0682 - val_accuracy: 0.9754\n",
      "Epoch 589/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9804 - val_loss: 0.0619 - val_accuracy: 0.9763\n",
      "Epoch 590/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9797 - val_loss: 0.0551 - val_accuracy: 0.9779\n",
      "Epoch 591/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9815 - val_loss: 0.0594 - val_accuracy: 0.9766\n",
      "Epoch 592/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9799 - val_loss: 0.0600 - val_accuracy: 0.9770\n",
      "Epoch 593/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9797 - val_loss: 0.0685 - val_accuracy: 0.9746\n",
      "Epoch 594/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9794 - val_loss: 0.0695 - val_accuracy: 0.9747\n",
      "Epoch 595/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9812 - val_loss: 0.0611 - val_accuracy: 0.9766\n",
      "Epoch 596/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9820 - val_loss: 0.0602 - val_accuracy: 0.9766\n",
      "Epoch 597/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9803 - val_loss: 0.0684 - val_accuracy: 0.9753\n",
      "Epoch 598/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0537 - accuracy: 0.9805 - val_loss: 0.0644 - val_accuracy: 0.9753\n",
      "Epoch 599/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9813 - val_loss: 0.0588 - val_accuracy: 0.9771\n",
      "Epoch 600/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9815 - val_loss: 0.0626 - val_accuracy: 0.9759\n",
      "Epoch 601/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9807 - val_loss: 0.0604 - val_accuracy: 0.9771\n",
      "Epoch 602/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9808 - val_loss: 0.0592 - val_accuracy: 0.9768\n",
      "Epoch 603/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.0653 - val_accuracy: 0.9755\n",
      "Epoch 604/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9803 - val_loss: 0.0687 - val_accuracy: 0.9760\n",
      "Epoch 605/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.0611 - val_accuracy: 0.9763\n",
      "Epoch 606/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9808 - val_loss: 0.0635 - val_accuracy: 0.9758\n",
      "Epoch 607/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 0.0642 - val_accuracy: 0.9767\n",
      "Epoch 608/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9814 - val_loss: 0.0591 - val_accuracy: 0.9770\n",
      "Epoch 609/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9806 - val_loss: 0.0656 - val_accuracy: 0.9761\n",
      "Epoch 610/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9804 - val_loss: 0.0632 - val_accuracy: 0.9765\n",
      "Epoch 611/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9807 - val_loss: 0.0669 - val_accuracy: 0.9757\n",
      "Epoch 612/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 0.0656 - val_accuracy: 0.9759\n",
      "Epoch 613/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9802 - val_loss: 0.0665 - val_accuracy: 0.9755\n",
      "Epoch 614/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 0.0659 - val_accuracy: 0.9758\n",
      "Epoch 615/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0606 - val_accuracy: 0.9761\n",
      "Epoch 616/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9815 - val_loss: 0.0611 - val_accuracy: 0.9774\n",
      "Epoch 617/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9812 - val_loss: 0.0691 - val_accuracy: 0.9751\n",
      "Epoch 618/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9808 - val_loss: 0.0623 - val_accuracy: 0.9763\n",
      "Epoch 619/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9824 - val_loss: 0.0593 - val_accuracy: 0.9769\n",
      "Epoch 620/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9817 - val_loss: 0.0554 - val_accuracy: 0.9771\n",
      "Epoch 621/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9807 - val_loss: 0.0589 - val_accuracy: 0.9782\n",
      "Epoch 622/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9805 - val_loss: 0.0623 - val_accuracy: 0.9766\n",
      "Epoch 623/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 0.0653 - val_accuracy: 0.9749\n",
      "Epoch 624/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9817 - val_loss: 0.0638 - val_accuracy: 0.9757\n",
      "Epoch 625/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9807 - val_loss: 0.0613 - val_accuracy: 0.9760\n",
      "Epoch 626/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9808 - val_loss: 0.0582 - val_accuracy: 0.9777\n",
      "Epoch 627/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9805 - val_loss: 0.0555 - val_accuracy: 0.9773\n",
      "Epoch 628/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9803 - val_loss: 0.0634 - val_accuracy: 0.9766\n",
      "Epoch 629/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9808 - val_loss: 0.0612 - val_accuracy: 0.9760\n",
      "Epoch 630/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.0561 - val_accuracy: 0.9776\n",
      "Epoch 631/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9818 - val_loss: 0.0719 - val_accuracy: 0.9743\n",
      "Epoch 632/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0578 - val_accuracy: 0.9777\n",
      "Epoch 633/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9789 - val_loss: 0.0657 - val_accuracy: 0.9754\n",
      "Epoch 634/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9814 - val_loss: 0.0560 - val_accuracy: 0.9780\n",
      "Epoch 635/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9805 - val_loss: 0.0592 - val_accuracy: 0.9770\n",
      "Epoch 636/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.0696 - val_accuracy: 0.9749\n",
      "Epoch 637/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9807 - val_loss: 0.0625 - val_accuracy: 0.9763\n",
      "Epoch 638/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9808 - val_loss: 0.0622 - val_accuracy: 0.9765\n",
      "Epoch 639/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9820 - val_loss: 0.0567 - val_accuracy: 0.9767\n",
      "Epoch 640/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9815 - val_loss: 0.0660 - val_accuracy: 0.9759\n",
      "Epoch 641/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9808 - val_loss: 0.0579 - val_accuracy: 0.9776\n",
      "Epoch 642/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 0.0666 - val_accuracy: 0.9764\n",
      "Epoch 643/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9808 - val_loss: 0.0627 - val_accuracy: 0.9760\n",
      "Epoch 644/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0700 - val_accuracy: 0.9755\n",
      "Epoch 645/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0583 - val_accuracy: 0.9769\n",
      "Epoch 646/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9815 - val_loss: 0.0614 - val_accuracy: 0.9766\n",
      "Epoch 647/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.0643 - val_accuracy: 0.9760\n",
      "Epoch 648/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9818 - val_loss: 0.0668 - val_accuracy: 0.9761\n",
      "Epoch 649/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9816 - val_loss: 0.0695 - val_accuracy: 0.9751\n",
      "Epoch 650/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9809 - val_loss: 0.0772 - val_accuracy: 0.9731\n",
      "Epoch 651/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9816 - val_loss: 0.0624 - val_accuracy: 0.9765\n",
      "Epoch 652/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9813 - val_loss: 0.0584 - val_accuracy: 0.9768\n",
      "Epoch 653/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.0593 - val_accuracy: 0.9769\n",
      "Epoch 654/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0534 - accuracy: 0.9811 - val_loss: 0.0753 - val_accuracy: 0.9735\n",
      "Epoch 655/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9799 - val_loss: 0.0746 - val_accuracy: 0.9745\n",
      "Epoch 656/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9802 - val_loss: 0.0581 - val_accuracy: 0.9765\n",
      "Epoch 657/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9822 - val_loss: 0.0697 - val_accuracy: 0.9754\n",
      "Epoch 658/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.0645 - val_accuracy: 0.9765\n",
      "Epoch 659/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9806 - val_loss: 0.0630 - val_accuracy: 0.9767\n",
      "Epoch 660/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9818 - val_loss: 0.0604 - val_accuracy: 0.9756\n",
      "Epoch 661/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9813 - val_loss: 0.0661 - val_accuracy: 0.9757\n",
      "Epoch 662/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 0.0603 - val_accuracy: 0.9767\n",
      "Epoch 663/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9819 - val_loss: 0.0729 - val_accuracy: 0.9735\n",
      "Epoch 664/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9817 - val_loss: 0.0624 - val_accuracy: 0.9753\n",
      "Epoch 665/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9803 - val_loss: 0.0727 - val_accuracy: 0.9750\n",
      "Epoch 666/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9813 - val_loss: 0.0579 - val_accuracy: 0.9765\n",
      "Epoch 667/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9801 - val_loss: 0.0598 - val_accuracy: 0.9769\n",
      "Epoch 668/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9805 - val_loss: 0.0619 - val_accuracy: 0.9761\n",
      "Epoch 669/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9820 - val_loss: 0.0647 - val_accuracy: 0.9758\n",
      "Epoch 670/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9814 - val_loss: 0.0702 - val_accuracy: 0.9757\n",
      "Epoch 671/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 0.0660 - val_accuracy: 0.9765\n",
      "Epoch 672/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 0.0691 - val_accuracy: 0.9746\n",
      "Epoch 673/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9809 - val_loss: 0.0622 - val_accuracy: 0.9759\n",
      "Epoch 674/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 0.0622 - val_accuracy: 0.9769\n",
      "Epoch 675/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0597 - val_accuracy: 0.9759\n",
      "Epoch 676/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9802 - val_loss: 0.0609 - val_accuracy: 0.9765\n",
      "Epoch 677/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9822 - val_loss: 0.0621 - val_accuracy: 0.9766\n",
      "Epoch 678/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 0.0645 - val_accuracy: 0.9765\n",
      "Epoch 679/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9759\n",
      "Epoch 680/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9821 - val_loss: 0.0589 - val_accuracy: 0.9776\n",
      "Epoch 681/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9819 - val_loss: 0.0584 - val_accuracy: 0.9777\n",
      "Epoch 682/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0632 - val_accuracy: 0.9768\n",
      "Epoch 683/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9802 - val_loss: 0.0577 - val_accuracy: 0.9777\n",
      "Epoch 684/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9807 - val_loss: 0.0651 - val_accuracy: 0.9757\n",
      "Epoch 685/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0643 - val_accuracy: 0.9761\n",
      "Epoch 686/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.0733 - val_accuracy: 0.9754\n",
      "Epoch 687/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9803 - val_loss: 0.0707 - val_accuracy: 0.9755\n",
      "Epoch 688/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9823 - val_loss: 0.0573 - val_accuracy: 0.9777\n",
      "Epoch 689/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9807 - val_loss: 0.0609 - val_accuracy: 0.9768\n",
      "Epoch 690/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.0701 - val_accuracy: 0.9754\n",
      "Epoch 691/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9814 - val_loss: 0.0689 - val_accuracy: 0.9756\n",
      "Epoch 692/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9813 - val_loss: 0.0626 - val_accuracy: 0.9771\n",
      "Epoch 693/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9818 - val_loss: 0.0667 - val_accuracy: 0.9757\n",
      "Epoch 694/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9819 - val_loss: 0.0721 - val_accuracy: 0.9744\n",
      "Epoch 695/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9802 - val_loss: 0.0673 - val_accuracy: 0.9758\n",
      "Epoch 696/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9811 - val_loss: 0.0770 - val_accuracy: 0.9741\n",
      "Epoch 697/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9825 - val_loss: 0.0635 - val_accuracy: 0.9763\n",
      "Epoch 698/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9811 - val_loss: 0.0641 - val_accuracy: 0.9757\n",
      "Epoch 699/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0511 - accuracy: 0.9826 - val_loss: 0.0643 - val_accuracy: 0.9758\n",
      "Epoch 700/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 0.0656 - val_accuracy: 0.9761\n",
      "Epoch 701/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 0.0629 - val_accuracy: 0.9766\n",
      "Epoch 702/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9813 - val_loss: 0.0716 - val_accuracy: 0.9758\n",
      "Epoch 703/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9820 - val_loss: 0.0650 - val_accuracy: 0.9768\n",
      "Epoch 704/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9815 - val_loss: 0.0644 - val_accuracy: 0.9764\n",
      "Epoch 705/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9811 - val_loss: 0.0642 - val_accuracy: 0.9769\n",
      "Epoch 706/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9802 - val_loss: 0.0598 - val_accuracy: 0.9771\n",
      "Epoch 707/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9814 - val_loss: 0.0580 - val_accuracy: 0.9774\n",
      "Epoch 708/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9823 - val_loss: 0.0571 - val_accuracy: 0.9778\n",
      "Epoch 709/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9811 - val_loss: 0.0684 - val_accuracy: 0.9761\n",
      "Epoch 710/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9822 - val_loss: 0.0606 - val_accuracy: 0.9776\n",
      "Epoch 711/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.0603 - val_accuracy: 0.9764\n",
      "Epoch 712/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9817 - val_loss: 0.0619 - val_accuracy: 0.9774\n",
      "Epoch 713/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9817 - val_loss: 0.0595 - val_accuracy: 0.9775\n",
      "Epoch 714/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9821 - val_loss: 0.0594 - val_accuracy: 0.9773\n",
      "Epoch 715/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9816 - val_loss: 0.0581 - val_accuracy: 0.9775\n",
      "Epoch 716/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9814 - val_loss: 0.0674 - val_accuracy: 0.9766\n",
      "Epoch 717/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9808 - val_loss: 0.0575 - val_accuracy: 0.9780\n",
      "Epoch 718/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9823 - val_loss: 0.0697 - val_accuracy: 0.9749\n",
      "Epoch 719/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9804 - val_loss: 0.0712 - val_accuracy: 0.9754\n",
      "Epoch 720/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9816 - val_loss: 0.0626 - val_accuracy: 0.9767\n",
      "Epoch 721/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9820 - val_loss: 0.0722 - val_accuracy: 0.9747\n",
      "Epoch 722/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9821 - val_loss: 0.0738 - val_accuracy: 0.9739\n",
      "Epoch 723/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.0741 - val_accuracy: 0.9741\n",
      "Epoch 724/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9808 - val_loss: 0.0617 - val_accuracy: 0.9774\n",
      "Epoch 725/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.0557 - val_accuracy: 0.9782\n",
      "Epoch 726/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9814 - val_loss: 0.0733 - val_accuracy: 0.9749\n",
      "Epoch 727/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9811 - val_loss: 0.0587 - val_accuracy: 0.9774\n",
      "Epoch 728/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9813 - val_loss: 0.0604 - val_accuracy: 0.9777\n",
      "Epoch 729/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 0.0634 - val_accuracy: 0.9764\n",
      "Epoch 730/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9814 - val_loss: 0.0670 - val_accuracy: 0.9758\n",
      "Epoch 731/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.0686 - val_accuracy: 0.9763\n",
      "Epoch 732/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9819 - val_loss: 0.0745 - val_accuracy: 0.9748\n",
      "Epoch 733/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9818 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
      "Epoch 734/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9811 - val_loss: 0.0636 - val_accuracy: 0.9763\n",
      "Epoch 735/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9820 - val_loss: 0.0669 - val_accuracy: 0.9761\n",
      "Epoch 736/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9818 - val_loss: 0.0562 - val_accuracy: 0.9779\n",
      "Epoch 737/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9821 - val_loss: 0.0729 - val_accuracy: 0.9747\n",
      "Epoch 738/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9820 - val_loss: 0.0696 - val_accuracy: 0.9746\n",
      "Epoch 739/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9811 - val_loss: 0.0603 - val_accuracy: 0.9774\n",
      "Epoch 740/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.0599 - val_accuracy: 0.9773\n",
      "Epoch 741/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9819 - val_loss: 0.0658 - val_accuracy: 0.9760\n",
      "Epoch 742/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9814 - val_loss: 0.0731 - val_accuracy: 0.9743\n",
      "Epoch 743/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9818 - val_loss: 0.0634 - val_accuracy: 0.9761\n",
      "Epoch 744/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9819 - val_loss: 0.0795 - val_accuracy: 0.9728\n",
      "Epoch 745/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9816 - val_loss: 0.0649 - val_accuracy: 0.9759\n",
      "Epoch 746/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9821 - val_loss: 0.0707 - val_accuracy: 0.9754\n",
      "Epoch 747/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9812 - val_loss: 0.0649 - val_accuracy: 0.9763\n",
      "Epoch 748/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9817 - val_loss: 0.0733 - val_accuracy: 0.9747\n",
      "Epoch 749/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9818 - val_loss: 0.0634 - val_accuracy: 0.9770\n",
      "Epoch 750/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9829 - val_loss: 0.0646 - val_accuracy: 0.9766\n",
      "Epoch 751/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9823 - val_loss: 0.0667 - val_accuracy: 0.9753\n",
      "Epoch 752/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9818 - val_loss: 0.0610 - val_accuracy: 0.9770\n",
      "Epoch 753/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9817 - val_loss: 0.0595 - val_accuracy: 0.9765\n",
      "Epoch 754/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9821 - val_loss: 0.0646 - val_accuracy: 0.9764\n",
      "Epoch 755/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0506 - accuracy: 0.9824 - val_loss: 0.0605 - val_accuracy: 0.9778\n",
      "Epoch 756/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9813 - val_loss: 0.0637 - val_accuracy: 0.9769\n",
      "Epoch 757/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9820 - val_loss: 0.0633 - val_accuracy: 0.9764\n",
      "Epoch 758/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9817 - val_loss: 0.0612 - val_accuracy: 0.9769\n",
      "Epoch 759/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 0.0646 - val_accuracy: 0.9761\n",
      "Epoch 760/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9807 - val_loss: 0.0773 - val_accuracy: 0.9739\n",
      "Epoch 761/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9822 - val_loss: 0.0589 - val_accuracy: 0.9781\n",
      "Epoch 762/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 0.0597 - val_accuracy: 0.9779\n",
      "Epoch 763/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 0.0664 - val_accuracy: 0.9759\n",
      "Epoch 764/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9815 - val_loss: 0.0604 - val_accuracy: 0.9775\n",
      "Epoch 765/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9824 - val_loss: 0.0651 - val_accuracy: 0.9761\n",
      "Epoch 766/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9820 - val_loss: 0.0589 - val_accuracy: 0.9771\n",
      "Epoch 767/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9824 - val_loss: 0.0677 - val_accuracy: 0.9758\n",
      "Epoch 768/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9808 - val_loss: 0.0655 - val_accuracy: 0.9757\n",
      "Epoch 769/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9818 - val_loss: 0.0578 - val_accuracy: 0.9780\n",
      "Epoch 770/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9815 - val_loss: 0.0825 - val_accuracy: 0.9731\n",
      "Epoch 771/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9817 - val_loss: 0.0667 - val_accuracy: 0.9755\n",
      "Epoch 772/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9811 - val_loss: 0.0634 - val_accuracy: 0.9764\n",
      "Epoch 773/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9823 - val_loss: 0.0678 - val_accuracy: 0.9758\n",
      "Epoch 774/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9818 - val_loss: 0.0616 - val_accuracy: 0.9755\n",
      "Epoch 775/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.0577 - val_accuracy: 0.9776\n",
      "Epoch 776/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9821 - val_loss: 0.0647 - val_accuracy: 0.9773\n",
      "Epoch 777/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9813 - val_loss: 0.0658 - val_accuracy: 0.9764\n",
      "Epoch 778/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9814 - val_loss: 0.0744 - val_accuracy: 0.9753\n",
      "Epoch 779/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9822 - val_loss: 0.0678 - val_accuracy: 0.9756\n",
      "Epoch 780/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9820 - val_loss: 0.0723 - val_accuracy: 0.9755\n",
      "Epoch 781/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9823 - val_loss: 0.0553 - val_accuracy: 0.9775\n",
      "Epoch 782/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9807 - val_loss: 0.0603 - val_accuracy: 0.9768\n",
      "Epoch 783/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9819 - val_loss: 0.0669 - val_accuracy: 0.9768\n",
      "Epoch 784/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9818 - val_loss: 0.0634 - val_accuracy: 0.9763\n",
      "Epoch 785/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9830 - val_loss: 0.0638 - val_accuracy: 0.9765\n",
      "Epoch 786/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9826 - val_loss: 0.0583 - val_accuracy: 0.9781\n",
      "Epoch 787/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9828 - val_loss: 0.0627 - val_accuracy: 0.9769\n",
      "Epoch 788/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9819 - val_loss: 0.0602 - val_accuracy: 0.9777\n",
      "Epoch 789/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9826 - val_loss: 0.0665 - val_accuracy: 0.9761\n",
      "Epoch 790/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 0.0697 - val_accuracy: 0.9756\n",
      "Epoch 791/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9815 - val_loss: 0.0671 - val_accuracy: 0.9759\n",
      "Epoch 792/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9820 - val_loss: 0.0683 - val_accuracy: 0.9759\n",
      "Epoch 793/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9820 - val_loss: 0.0561 - val_accuracy: 0.9775\n",
      "Epoch 794/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9826 - val_loss: 0.0652 - val_accuracy: 0.9769\n",
      "Epoch 795/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.0624 - val_accuracy: 0.9767\n",
      "Epoch 796/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9822 - val_loss: 0.0589 - val_accuracy: 0.9769\n",
      "Epoch 797/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9814 - val_loss: 0.0664 - val_accuracy: 0.9766\n",
      "Epoch 798/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9818 - val_loss: 0.0639 - val_accuracy: 0.9769\n",
      "Epoch 799/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9827 - val_loss: 0.0611 - val_accuracy: 0.9767\n",
      "Epoch 800/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 0.0685 - val_accuracy: 0.9758\n",
      "Epoch 801/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9817 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
      "Epoch 802/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9813 - val_loss: 0.0660 - val_accuracy: 0.9761\n",
      "Epoch 803/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9826 - val_loss: 0.0653 - val_accuracy: 0.9758\n",
      "Epoch 804/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9815 - val_loss: 0.0637 - val_accuracy: 0.9768\n",
      "Epoch 805/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9829 - val_loss: 0.0623 - val_accuracy: 0.9766\n",
      "Epoch 806/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9812 - val_loss: 0.0647 - val_accuracy: 0.9759\n",
      "Epoch 807/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.0643 - val_accuracy: 0.9759\n",
      "Epoch 808/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9824 - val_loss: 0.0560 - val_accuracy: 0.9782\n",
      "Epoch 809/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9799 - val_loss: 0.0654 - val_accuracy: 0.9766\n",
      "Epoch 810/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 0.0647 - val_accuracy: 0.9767\n",
      "Epoch 811/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9812 - val_loss: 0.0577 - val_accuracy: 0.9780\n",
      "Epoch 812/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.0668 - val_accuracy: 0.9754\n",
      "Epoch 813/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9825 - val_loss: 0.0559 - val_accuracy: 0.9781\n",
      "Epoch 814/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9816 - val_loss: 0.0650 - val_accuracy: 0.9768\n",
      "Epoch 815/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9820 - val_loss: 0.0575 - val_accuracy: 0.9776\n",
      "Epoch 816/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9813 - val_loss: 0.0569 - val_accuracy: 0.9777\n",
      "Epoch 817/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9820 - val_loss: 0.0617 - val_accuracy: 0.9769\n",
      "Epoch 818/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9822 - val_loss: 0.0673 - val_accuracy: 0.9759\n",
      "Epoch 819/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9824 - val_loss: 0.0705 - val_accuracy: 0.9757\n",
      "Epoch 820/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9822 - val_loss: 0.0632 - val_accuracy: 0.9766\n",
      "Epoch 821/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9830 - val_loss: 0.0654 - val_accuracy: 0.9768\n",
      "Epoch 822/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9820 - val_loss: 0.0717 - val_accuracy: 0.9756\n",
      "Epoch 823/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 0.0582 - val_accuracy: 0.9769\n",
      "Epoch 824/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9821 - val_loss: 0.0613 - val_accuracy: 0.9765\n",
      "Epoch 825/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9819 - val_loss: 0.0565 - val_accuracy: 0.9784\n",
      "Epoch 826/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9817 - val_loss: 0.0666 - val_accuracy: 0.9759\n",
      "Epoch 827/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9818 - val_loss: 0.0696 - val_accuracy: 0.9761\n",
      "Epoch 828/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9823 - val_loss: 0.0601 - val_accuracy: 0.9769\n",
      "Epoch 829/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9826 - val_loss: 0.0639 - val_accuracy: 0.9768\n",
      "Epoch 830/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9827 - val_loss: 0.0597 - val_accuracy: 0.9767\n",
      "Epoch 831/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9815 - val_loss: 0.0594 - val_accuracy: 0.9770\n",
      "Epoch 832/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9830 - val_loss: 0.0628 - val_accuracy: 0.9768\n",
      "Epoch 833/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9818 - val_loss: 0.0684 - val_accuracy: 0.9764\n",
      "Epoch 834/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 0.0676 - val_accuracy: 0.9755\n",
      "Epoch 835/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9825 - val_loss: 0.0664 - val_accuracy: 0.9757\n",
      "Epoch 836/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9827 - val_loss: 0.0681 - val_accuracy: 0.9753\n",
      "Epoch 837/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9818 - val_loss: 0.0671 - val_accuracy: 0.9755\n",
      "Epoch 838/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9827 - val_loss: 0.0677 - val_accuracy: 0.9765\n",
      "Epoch 839/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9815 - val_loss: 0.0677 - val_accuracy: 0.9756\n",
      "Epoch 840/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9824 - val_loss: 0.0781 - val_accuracy: 0.9747\n",
      "Epoch 841/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 0.0598 - val_accuracy: 0.9775\n",
      "Epoch 842/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9820 - val_loss: 0.0788 - val_accuracy: 0.9749\n",
      "Epoch 843/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9827 - val_loss: 0.0686 - val_accuracy: 0.9760\n",
      "Epoch 844/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9817 - val_loss: 0.0691 - val_accuracy: 0.9750\n",
      "Epoch 845/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9823 - val_loss: 0.0609 - val_accuracy: 0.9765\n",
      "Epoch 846/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9813 - val_loss: 0.0627 - val_accuracy: 0.9765\n",
      "Epoch 847/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9829 - val_loss: 0.0645 - val_accuracy: 0.9765\n",
      "Epoch 848/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.0582 - val_accuracy: 0.9779\n",
      "Epoch 849/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.0667 - val_accuracy: 0.9756\n",
      "Epoch 850/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9822 - val_loss: 0.0606 - val_accuracy: 0.9774\n",
      "Epoch 851/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9828 - val_loss: 0.0575 - val_accuracy: 0.9771\n",
      "Epoch 852/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9821 - val_loss: 0.0630 - val_accuracy: 0.9770\n",
      "Epoch 853/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9823 - val_loss: 0.0590 - val_accuracy: 0.9777\n",
      "Epoch 854/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9824 - val_loss: 0.0732 - val_accuracy: 0.9749\n",
      "Epoch 855/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.0673 - val_accuracy: 0.9757\n",
      "Epoch 856/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 0.0627 - val_accuracy: 0.9770\n",
      "Epoch 857/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9822 - val_loss: 0.0663 - val_accuracy: 0.9761\n",
      "Epoch 858/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9821 - val_loss: 0.0617 - val_accuracy: 0.9775\n",
      "Epoch 859/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9832 - val_loss: 0.0619 - val_accuracy: 0.9776\n",
      "Epoch 860/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9824 - val_loss: 0.0592 - val_accuracy: 0.9770\n",
      "Epoch 861/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9822 - val_loss: 0.0643 - val_accuracy: 0.9765\n",
      "Epoch 862/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.0645 - val_accuracy: 0.9763\n",
      "Epoch 863/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9830 - val_loss: 0.0601 - val_accuracy: 0.9773\n",
      "Epoch 864/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 0.0604 - val_accuracy: 0.9769\n",
      "Epoch 865/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9826 - val_loss: 0.0682 - val_accuracy: 0.9764\n",
      "Epoch 866/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9809 - val_loss: 0.0647 - val_accuracy: 0.9761\n",
      "Epoch 867/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9826 - val_loss: 0.0634 - val_accuracy: 0.9769\n",
      "Epoch 868/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9816 - val_loss: 0.0639 - val_accuracy: 0.9775\n",
      "Epoch 869/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9836 - val_loss: 0.0628 - val_accuracy: 0.9769\n",
      "Epoch 870/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9834 - val_loss: 0.0715 - val_accuracy: 0.9755\n",
      "Epoch 871/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9826 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
      "Epoch 872/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9833 - val_loss: 0.0642 - val_accuracy: 0.9763\n",
      "Epoch 873/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 0.0697 - val_accuracy: 0.9760\n",
      "Epoch 874/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9817 - val_loss: 0.0812 - val_accuracy: 0.9744\n",
      "Epoch 875/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9813 - val_loss: 0.0831 - val_accuracy: 0.9739\n",
      "Epoch 876/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.0659 - val_accuracy: 0.9763\n",
      "Epoch 877/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9828 - val_loss: 0.0654 - val_accuracy: 0.9767\n",
      "Epoch 878/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9827 - val_loss: 0.0657 - val_accuracy: 0.9768\n",
      "Epoch 879/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9812 - val_loss: 0.0714 - val_accuracy: 0.9755\n",
      "Epoch 880/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9828 - val_loss: 0.0628 - val_accuracy: 0.9771\n",
      "Epoch 881/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9767\n",
      "Epoch 882/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9826 - val_loss: 0.0710 - val_accuracy: 0.9757\n",
      "Epoch 883/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9821 - val_loss: 0.0620 - val_accuracy: 0.9768\n",
      "Epoch 884/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9816 - val_loss: 0.0650 - val_accuracy: 0.9764\n",
      "Epoch 885/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9830 - val_loss: 0.0759 - val_accuracy: 0.9743\n",
      "Epoch 886/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9817 - val_loss: 0.0601 - val_accuracy: 0.9777\n",
      "Epoch 887/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.0726 - val_accuracy: 0.9751\n",
      "Epoch 888/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 0.0771 - val_accuracy: 0.9749\n",
      "Epoch 889/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9820 - val_loss: 0.0641 - val_accuracy: 0.9771\n",
      "Epoch 890/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9817 - val_loss: 0.0636 - val_accuracy: 0.9764\n",
      "Epoch 891/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9819 - val_loss: 0.0650 - val_accuracy: 0.9760\n",
      "Epoch 892/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9826 - val_loss: 0.0686 - val_accuracy: 0.9763\n",
      "Epoch 893/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9821 - val_loss: 0.0612 - val_accuracy: 0.9774\n",
      "Epoch 894/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9824 - val_loss: 0.0681 - val_accuracy: 0.9767\n",
      "Epoch 895/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9824 - val_loss: 0.0756 - val_accuracy: 0.9746\n",
      "Epoch 896/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9826 - val_loss: 0.0652 - val_accuracy: 0.9761\n",
      "Epoch 897/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9821 - val_loss: 0.0698 - val_accuracy: 0.9760\n",
      "Epoch 898/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9821 - val_loss: 0.0678 - val_accuracy: 0.9761\n",
      "Epoch 899/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.0635 - val_accuracy: 0.9774\n",
      "Epoch 900/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9816 - val_loss: 0.0717 - val_accuracy: 0.9756\n",
      "Epoch 901/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9826 - val_loss: 0.0660 - val_accuracy: 0.9757\n",
      "Epoch 902/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9816 - val_loss: 0.0635 - val_accuracy: 0.9770\n",
      "Epoch 903/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9819 - val_loss: 0.0684 - val_accuracy: 0.9757\n",
      "Epoch 904/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9828 - val_loss: 0.0647 - val_accuracy: 0.9773\n",
      "Epoch 905/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9824 - val_loss: 0.0610 - val_accuracy: 0.9764\n",
      "Epoch 906/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9838 - val_loss: 0.0651 - val_accuracy: 0.9761\n",
      "Epoch 907/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9822 - val_loss: 0.0626 - val_accuracy: 0.9775\n",
      "Epoch 908/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9832 - val_loss: 0.0750 - val_accuracy: 0.9749\n",
      "Epoch 909/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9821 - val_loss: 0.0661 - val_accuracy: 0.9771\n",
      "Epoch 910/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9820 - val_loss: 0.0611 - val_accuracy: 0.9776\n",
      "Epoch 911/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9833 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
      "Epoch 912/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.0618 - val_accuracy: 0.9774\n",
      "Epoch 913/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9820 - val_loss: 0.0719 - val_accuracy: 0.9759\n",
      "Epoch 914/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.0599 - val_accuracy: 0.9769\n",
      "Epoch 915/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9821 - val_loss: 0.0674 - val_accuracy: 0.9758\n",
      "Epoch 916/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9824 - val_loss: 0.0668 - val_accuracy: 0.9756\n",
      "Epoch 917/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9825 - val_loss: 0.0623 - val_accuracy: 0.9771\n",
      "Epoch 918/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 0.0702 - val_accuracy: 0.9760\n",
      "Epoch 919/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9828 - val_loss: 0.0657 - val_accuracy: 0.9766\n",
      "Epoch 920/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.0640 - val_accuracy: 0.9776\n",
      "Epoch 921/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0650 - val_accuracy: 0.9765\n",
      "Epoch 922/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9829 - val_loss: 0.0656 - val_accuracy: 0.9766\n",
      "Epoch 923/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9825 - val_loss: 0.0593 - val_accuracy: 0.9780\n",
      "Epoch 924/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9825 - val_loss: 0.0713 - val_accuracy: 0.9759\n",
      "Epoch 925/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9825 - val_loss: 0.0591 - val_accuracy: 0.9786\n",
      "Epoch 926/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9825 - val_loss: 0.0639 - val_accuracy: 0.9767\n",
      "Epoch 927/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.0680 - val_accuracy: 0.9760\n",
      "Epoch 928/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 0.0641 - val_accuracy: 0.9766\n",
      "Epoch 929/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.0673 - val_accuracy: 0.9758\n",
      "Epoch 930/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0577 - val_accuracy: 0.9777\n",
      "Epoch 931/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.0729 - val_accuracy: 0.9756\n",
      "Epoch 932/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9822 - val_loss: 0.0630 - val_accuracy: 0.9771\n",
      "Epoch 933/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9831 - val_loss: 0.0726 - val_accuracy: 0.9765\n",
      "Epoch 934/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9830 - val_loss: 0.0592 - val_accuracy: 0.9780\n",
      "Epoch 935/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9822 - val_loss: 0.0695 - val_accuracy: 0.9767\n",
      "Epoch 936/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9824 - val_loss: 0.0653 - val_accuracy: 0.9770\n",
      "Epoch 937/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9828 - val_loss: 0.0667 - val_accuracy: 0.9765\n",
      "Epoch 938/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9823 - val_loss: 0.0704 - val_accuracy: 0.9753\n",
      "Epoch 939/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 0.0802 - val_accuracy: 0.9747\n",
      "Epoch 940/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9828 - val_loss: 0.0760 - val_accuracy: 0.9747\n",
      "Epoch 941/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 0.0688 - val_accuracy: 0.9760\n",
      "Epoch 942/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9829 - val_loss: 0.0657 - val_accuracy: 0.9768\n",
      "Epoch 943/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.0599 - val_accuracy: 0.9777\n",
      "Epoch 944/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9828 - val_loss: 0.0642 - val_accuracy: 0.9773\n",
      "Epoch 945/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0480 - accuracy: 0.9827 - val_loss: 0.0682 - val_accuracy: 0.9770\n",
      "Epoch 946/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 0.0800 - val_accuracy: 0.9740\n",
      "Epoch 947/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.0655 - val_accuracy: 0.9763\n",
      "Epoch 948/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0470 - accuracy: 0.9829 - val_loss: 0.0602 - val_accuracy: 0.9779\n",
      "Epoch 949/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9833 - val_loss: 0.0724 - val_accuracy: 0.9759\n",
      "Epoch 950/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9821 - val_loss: 0.0646 - val_accuracy: 0.9769\n",
      "Epoch 951/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9834 - val_loss: 0.0680 - val_accuracy: 0.9761\n",
      "Epoch 952/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.0683 - val_accuracy: 0.9760\n",
      "Epoch 953/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9827 - val_loss: 0.0626 - val_accuracy: 0.9769\n",
      "Epoch 954/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.0652 - val_accuracy: 0.9761\n",
      "Epoch 955/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9829 - val_loss: 0.0646 - val_accuracy: 0.9769\n",
      "Epoch 956/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 0.0646 - val_accuracy: 0.9771\n",
      "Epoch 957/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.9824 - val_loss: 0.0692 - val_accuracy: 0.9756\n",
      "Epoch 958/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9820 - val_loss: 0.0770 - val_accuracy: 0.9744\n",
      "Epoch 959/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.0646 - val_accuracy: 0.9763\n",
      "Epoch 960/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9832 - val_loss: 0.0692 - val_accuracy: 0.9764\n",
      "Epoch 961/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9827 - val_loss: 0.0687 - val_accuracy: 0.9758\n",
      "Epoch 962/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9826 - val_loss: 0.0642 - val_accuracy: 0.9766\n",
      "Epoch 963/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9832 - val_loss: 0.0631 - val_accuracy: 0.9764\n",
      "Epoch 964/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9834 - val_loss: 0.0705 - val_accuracy: 0.9759\n",
      "Epoch 965/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9824 - val_loss: 0.0669 - val_accuracy: 0.9757\n",
      "Epoch 966/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9829 - val_loss: 0.0663 - val_accuracy: 0.9766\n",
      "Epoch 967/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9830 - val_loss: 0.0695 - val_accuracy: 0.9760\n",
      "Epoch 968/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9823 - val_loss: 0.0612 - val_accuracy: 0.9778\n",
      "Epoch 969/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9825 - val_loss: 0.0645 - val_accuracy: 0.9768\n",
      "Epoch 970/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9826 - val_loss: 0.0651 - val_accuracy: 0.9764\n",
      "Epoch 971/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9831 - val_loss: 0.0683 - val_accuracy: 0.9763\n",
      "Epoch 972/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9828 - val_loss: 0.0619 - val_accuracy: 0.9775\n",
      "Epoch 973/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9831 - val_loss: 0.0674 - val_accuracy: 0.9765\n",
      "Epoch 974/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9833 - val_loss: 0.0628 - val_accuracy: 0.9765\n",
      "Epoch 975/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9827 - val_loss: 0.0655 - val_accuracy: 0.9765\n",
      "Epoch 976/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9820 - val_loss: 0.0709 - val_accuracy: 0.9750\n",
      "Epoch 977/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.0632 - val_accuracy: 0.9774\n",
      "Epoch 978/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9826 - val_loss: 0.0622 - val_accuracy: 0.9773\n",
      "Epoch 979/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9830 - val_loss: 0.0690 - val_accuracy: 0.9763\n",
      "Epoch 980/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9827 - val_loss: 0.0679 - val_accuracy: 0.9756\n",
      "Epoch 981/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9828 - val_loss: 0.0697 - val_accuracy: 0.9763\n",
      "Epoch 982/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9825 - val_loss: 0.0705 - val_accuracy: 0.9758\n",
      "Epoch 983/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 0.0689 - val_accuracy: 0.9764\n",
      "Epoch 984/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9832 - val_loss: 0.0750 - val_accuracy: 0.9751\n",
      "Epoch 985/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9827 - val_loss: 0.0663 - val_accuracy: 0.9764\n",
      "Epoch 986/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9833 - val_loss: 0.0653 - val_accuracy: 0.9763\n",
      "Epoch 987/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9834 - val_loss: 0.0672 - val_accuracy: 0.9763\n",
      "Epoch 988/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9833 - val_loss: 0.0629 - val_accuracy: 0.9773\n",
      "Epoch 989/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9836 - val_loss: 0.0616 - val_accuracy: 0.9777\n",
      "Epoch 990/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9824 - val_loss: 0.0605 - val_accuracy: 0.9777\n",
      "Epoch 991/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9833 - val_loss: 0.0687 - val_accuracy: 0.9765\n",
      "Epoch 992/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9834 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
      "Epoch 993/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9835 - val_loss: 0.0744 - val_accuracy: 0.9749\n",
      "Epoch 994/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9827 - val_loss: 0.0630 - val_accuracy: 0.9766\n",
      "Epoch 995/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9818 - val_loss: 0.0612 - val_accuracy: 0.9771\n",
      "Epoch 996/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9832 - val_loss: 0.0661 - val_accuracy: 0.9765\n",
      "Epoch 997/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9824 - val_loss: 0.0721 - val_accuracy: 0.9754\n",
      "Epoch 998/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.0699 - val_accuracy: 0.9757\n",
      "Epoch 999/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9831 - val_loss: 0.0688 - val_accuracy: 0.9755\n",
      "Epoch 1000/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9835 - val_loss: 0.0602 - val_accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 966us/step\n",
      "xtrain: (85868, 59), ytrain: (85868,)\n",
      "xvalid: (9011, 59), yvalid: (9011,)\n",
      "xtest: (9012, 59), ytest: (9012,)\n",
      "\n",
      "classification_report_Fold=4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Normal 0       0.99      0.98      0.99      8725\n",
      " Anomalous 1       0.59      0.74      0.65       287\n",
      "\n",
      "    accuracy                           0.98      9012\n",
      "   macro avg       0.79      0.86      0.82      9012\n",
      "weighted avg       0.98      0.98      0.98      9012\n",
      "\n",
      "confusion_matrix_Fold=4:\n",
      "\n",
      "True Negatives:  8574\n",
      "False Positives:  151\n",
      "False Negatives:  74\n",
      "True Positives:  213\n",
      "accuracy_score_Fold=4:\n",
      " 8787 \n",
      "\n",
      "End running time Fold=4: 210214_104438 ,-------------------------- \n",
      "\n",
      "Start running time Data Augmentation_Fold=5: 210214_104438 ,-------------------------- \n",
      "\n",
      "Data Augmentation MSE Label1, iter2==> mean: 1.168529122596383e-05, min: 3.0825261039666358e-06, max: 0.00021248865851291224\n",
      "End running time Data Augmentation_Fold=5: 210214_110402 ,-------------------------- \n",
      "\n",
      "\n",
      " Start running time Fold=5: 210214_110402 ,-------------------------- \n",
      "\n",
      "\n",
      " Number of Final yXtrain_Fold=5 labeled 0: 69796\n",
      "Number of Final yXtrain_Fold=5 labeled 1: 16072\n",
      "Number of Final yXtrain_Fold=5 labeled 2: 0 \n",
      "\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.5271 - accuracy: 0.7450 - val_loss: 0.2290 - val_accuracy: 0.9665\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.8175 - val_loss: 0.2374 - val_accuracy: 0.9600\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8224 - val_loss: 0.2449 - val_accuracy: 0.9563\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8259 - val_loss: 0.2175 - val_accuracy: 0.9568\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8278 - val_loss: 0.2327 - val_accuracy: 0.9552\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8244 - val_loss: 0.2265 - val_accuracy: 0.9534\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8258 - val_loss: 0.2107 - val_accuracy: 0.9545\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8295 - val_loss: 0.2189 - val_accuracy: 0.9498\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8311 - val_loss: 0.2305 - val_accuracy: 0.9461\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8308 - val_loss: 0.2422 - val_accuracy: 0.9443\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8331 - val_loss: 0.2131 - val_accuracy: 0.9485\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8306 - val_loss: 0.2186 - val_accuracy: 0.9447\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8333 - val_loss: 0.2144 - val_accuracy: 0.9444\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8340 - val_loss: 0.2276 - val_accuracy: 0.9415\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8360 - val_loss: 0.2063 - val_accuracy: 0.9454\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8369 - val_loss: 0.2091 - val_accuracy: 0.9466\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8365 - val_loss: 0.2007 - val_accuracy: 0.9485\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8390 - val_loss: 0.2034 - val_accuracy: 0.9454\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8367 - val_loss: 0.1743 - val_accuracy: 0.9518\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8409 - val_loss: 0.2288 - val_accuracy: 0.9349\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8430 - val_loss: 0.1836 - val_accuracy: 0.9482\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8445 - val_loss: 0.1802 - val_accuracy: 0.9490\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8449 - val_loss: 0.1952 - val_accuracy: 0.9466\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8466 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8499 - val_loss: 0.1972 - val_accuracy: 0.9431\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8515 - val_loss: 0.1808 - val_accuracy: 0.9480\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8538 - val_loss: 0.2048 - val_accuracy: 0.9401\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8556 - val_loss: 0.1914 - val_accuracy: 0.9424\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8558 - val_loss: 0.1743 - val_accuracy: 0.9505\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8589 - val_loss: 0.2084 - val_accuracy: 0.9321\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8588 - val_loss: 0.1871 - val_accuracy: 0.9428\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8602 - val_loss: 0.1737 - val_accuracy: 0.9455\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8623 - val_loss: 0.1939 - val_accuracy: 0.9392\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8647 - val_loss: 0.2030 - val_accuracy: 0.9296\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8654 - val_loss: 0.1580 - val_accuracy: 0.9533\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.8670 - val_loss: 0.1804 - val_accuracy: 0.9431\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.8667 - val_loss: 0.1629 - val_accuracy: 0.9497\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8703 - val_loss: 0.1861 - val_accuracy: 0.9380\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8682 - val_loss: 0.1669 - val_accuracy: 0.9448\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8715 - val_loss: 0.1754 - val_accuracy: 0.9397\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8733 - val_loss: 0.1657 - val_accuracy: 0.9463\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.8754 - val_loss: 0.1977 - val_accuracy: 0.9309\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2693 - accuracy: 0.8764 - val_loss: 0.1649 - val_accuracy: 0.9428\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.8777 - val_loss: 0.1801 - val_accuracy: 0.9360\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.8806 - val_loss: 0.1592 - val_accuracy: 0.9444\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.8795 - val_loss: 0.1679 - val_accuracy: 0.9394\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8812 - val_loss: 0.1653 - val_accuracy: 0.9417\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2536 - accuracy: 0.8839 - val_loss: 0.1788 - val_accuracy: 0.9347\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.8851 - val_loss: 0.1495 - val_accuracy: 0.9485\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.8877 - val_loss: 0.1417 - val_accuracy: 0.9522\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.8887 - val_loss: 0.1664 - val_accuracy: 0.9392\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.8879 - val_loss: 0.1670 - val_accuracy: 0.9387\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2398 - accuracy: 0.8922 - val_loss: 0.1600 - val_accuracy: 0.9428\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.8940 - val_loss: 0.1711 - val_accuracy: 0.9362\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.8944 - val_loss: 0.1766 - val_accuracy: 0.9318\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.8960 - val_loss: 0.1566 - val_accuracy: 0.9417\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.8956 - val_loss: 0.1384 - val_accuracy: 0.9497\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2256 - accuracy: 0.8984 - val_loss: 0.1306 - val_accuracy: 0.9538\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.8999 - val_loss: 0.1356 - val_accuracy: 0.9534\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9019 - val_loss: 0.1473 - val_accuracy: 0.9460\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2192 - accuracy: 0.9023 - val_loss: 0.1541 - val_accuracy: 0.9426\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9078 - val_loss: 0.1496 - val_accuracy: 0.9442\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2148 - accuracy: 0.9060 - val_loss: 0.1429 - val_accuracy: 0.9447\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9087 - val_loss: 0.1336 - val_accuracy: 0.9517\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9094 - val_loss: 0.1303 - val_accuracy: 0.9507\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9099 - val_loss: 0.1325 - val_accuracy: 0.9501\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9111 - val_loss: 0.1247 - val_accuracy: 0.9529\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2023 - accuracy: 0.9126 - val_loss: 0.1368 - val_accuracy: 0.9475\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2021 - accuracy: 0.9123 - val_loss: 0.1540 - val_accuracy: 0.9400\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9143 - val_loss: 0.1327 - val_accuracy: 0.9503\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9162 - val_loss: 0.1258 - val_accuracy: 0.9519\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1940 - accuracy: 0.9177 - val_loss: 0.1557 - val_accuracy: 0.9381\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 0.9163 - val_loss: 0.1370 - val_accuracy: 0.9478\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.9176 - val_loss: 0.1295 - val_accuracy: 0.9498\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9200 - val_loss: 0.1286 - val_accuracy: 0.9496\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9218 - val_loss: 0.1162 - val_accuracy: 0.9559\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9223 - val_loss: 0.1099 - val_accuracy: 0.9588\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1847 - accuracy: 0.9213 - val_loss: 0.1208 - val_accuracy: 0.9541\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1813 - accuracy: 0.9226 - val_loss: 0.1048 - val_accuracy: 0.9605\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9239 - val_loss: 0.1198 - val_accuracy: 0.9532\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9233 - val_loss: 0.1001 - val_accuracy: 0.9610\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9259 - val_loss: 0.1132 - val_accuracy: 0.9549\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9273 - val_loss: 0.0941 - val_accuracy: 0.9634\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9247 - val_loss: 0.1024 - val_accuracy: 0.9593\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9264 - val_loss: 0.0940 - val_accuracy: 0.9634\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9280 - val_loss: 0.0953 - val_accuracy: 0.9633\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9288 - val_loss: 0.1098 - val_accuracy: 0.9562\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9323 - val_loss: 0.1106 - val_accuracy: 0.9555\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9301 - val_loss: 0.1307 - val_accuracy: 0.9466\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1623 - accuracy: 0.9347 - val_loss: 0.1001 - val_accuracy: 0.9606\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9325 - val_loss: 0.1025 - val_accuracy: 0.9585\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9328 - val_loss: 0.1096 - val_accuracy: 0.9536\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9353 - val_loss: 0.1155 - val_accuracy: 0.9517\n",
      "Epoch 94/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9340 - val_loss: 0.1164 - val_accuracy: 0.9524\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9373 - val_loss: 0.1066 - val_accuracy: 0.9572\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9381 - val_loss: 0.1122 - val_accuracy: 0.9531\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1543 - accuracy: 0.9363 - val_loss: 0.1022 - val_accuracy: 0.9596\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9370 - val_loss: 0.0906 - val_accuracy: 0.9623\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9376 - val_loss: 0.0994 - val_accuracy: 0.9583\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9381 - val_loss: 0.1058 - val_accuracy: 0.9557\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9382 - val_loss: 0.1179 - val_accuracy: 0.9519\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9410 - val_loss: 0.0866 - val_accuracy: 0.9650\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9401 - val_loss: 0.1102 - val_accuracy: 0.9543\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9413 - val_loss: 0.0997 - val_accuracy: 0.9588\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9417 - val_loss: 0.1017 - val_accuracy: 0.9579\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9408 - val_loss: 0.0910 - val_accuracy: 0.9623\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9426 - val_loss: 0.0964 - val_accuracy: 0.9612\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9444 - val_loss: 0.1101 - val_accuracy: 0.9539\n",
      "Epoch 109/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9428 - val_loss: 0.0962 - val_accuracy: 0.9597\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.9440 - val_loss: 0.1128 - val_accuracy: 0.9524\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9450 - val_loss: 0.0846 - val_accuracy: 0.9646\n",
      "Epoch 112/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9441 - val_loss: 0.0974 - val_accuracy: 0.9583\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9459 - val_loss: 0.1011 - val_accuracy: 0.9571\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9443 - val_loss: 0.0979 - val_accuracy: 0.9603\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9467 - val_loss: 0.0856 - val_accuracy: 0.9632\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9472 - val_loss: 0.1149 - val_accuracy: 0.9504\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9457 - val_loss: 0.0960 - val_accuracy: 0.9605\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9461 - val_loss: 0.0800 - val_accuracy: 0.9672\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9482 - val_loss: 0.0906 - val_accuracy: 0.9599\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9466 - val_loss: 0.0980 - val_accuracy: 0.9578\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9486 - val_loss: 0.1031 - val_accuracy: 0.9572\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 0.9492 - val_loss: 0.0864 - val_accuracy: 0.9629\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9473 - val_loss: 0.0790 - val_accuracy: 0.9670\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9476 - val_loss: 0.1013 - val_accuracy: 0.9584\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9482 - val_loss: 0.0845 - val_accuracy: 0.9632\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.9490 - val_loss: 0.0840 - val_accuracy: 0.9646\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9501 - val_loss: 0.0891 - val_accuracy: 0.9629\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9488 - val_loss: 0.0798 - val_accuracy: 0.9659\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9507 - val_loss: 0.0895 - val_accuracy: 0.9622\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1258 - accuracy: 0.9514 - val_loss: 0.0663 - val_accuracy: 0.9713\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9492 - val_loss: 0.0699 - val_accuracy: 0.9700\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9496 - val_loss: 0.0814 - val_accuracy: 0.9664\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9508 - val_loss: 0.0994 - val_accuracy: 0.9582\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9510 - val_loss: 0.1064 - val_accuracy: 0.9537\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9537 - val_loss: 0.0797 - val_accuracy: 0.9668\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9527 - val_loss: 0.0931 - val_accuracy: 0.9610\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9519 - val_loss: 0.1126 - val_accuracy: 0.9525\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9537 - val_loss: 0.0856 - val_accuracy: 0.9626\n",
      "Epoch 139/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9521 - val_loss: 0.0751 - val_accuracy: 0.9684\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9525 - val_loss: 0.0809 - val_accuracy: 0.9652\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9531 - val_loss: 0.0751 - val_accuracy: 0.9688\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9554 - val_loss: 0.0737 - val_accuracy: 0.9686\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9515 - val_loss: 0.0831 - val_accuracy: 0.9652\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9560 - val_loss: 0.0828 - val_accuracy: 0.9634\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9551 - val_loss: 0.0912 - val_accuracy: 0.9610\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9552 - val_loss: 0.0788 - val_accuracy: 0.9677\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9541 - val_loss: 0.0726 - val_accuracy: 0.9693\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9541 - val_loss: 0.0800 - val_accuracy: 0.9656\n",
      "Epoch 149/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1151 - accuracy: 0.9556 - val_loss: 0.0738 - val_accuracy: 0.9696\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9572 - val_loss: 0.0778 - val_accuracy: 0.9663\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.9567 - val_loss: 0.0754 - val_accuracy: 0.9677\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 0.9568 - val_loss: 0.0948 - val_accuracy: 0.9594\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9569 - val_loss: 0.0729 - val_accuracy: 0.9696\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9563 - val_loss: 0.0978 - val_accuracy: 0.9572\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 0.9564 - val_loss: 0.0927 - val_accuracy: 0.9617\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9581 - val_loss: 0.0807 - val_accuracy: 0.9662\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9587 - val_loss: 0.0901 - val_accuracy: 0.9622\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9553 - val_loss: 0.0713 - val_accuracy: 0.9694\n",
      "Epoch 159/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9577 - val_loss: 0.0738 - val_accuracy: 0.9679\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9575 - val_loss: 0.0679 - val_accuracy: 0.9705\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9578 - val_loss: 0.0908 - val_accuracy: 0.9628\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9592 - val_loss: 0.0927 - val_accuracy: 0.9612\n",
      "Epoch 163/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9570 - val_loss: 0.0864 - val_accuracy: 0.9644\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9604 - val_loss: 0.0754 - val_accuracy: 0.9683\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9597 - val_loss: 0.0692 - val_accuracy: 0.9717\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9594 - val_loss: 0.0741 - val_accuracy: 0.9705\n",
      "Epoch 167/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9611 - val_loss: 0.0922 - val_accuracy: 0.9613\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9600 - val_loss: 0.0881 - val_accuracy: 0.9643\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9599 - val_loss: 0.0745 - val_accuracy: 0.9706\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9593 - val_loss: 0.0955 - val_accuracy: 0.9607\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9606 - val_loss: 0.0646 - val_accuracy: 0.9726\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9606 - val_loss: 0.0670 - val_accuracy: 0.9719\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9603 - val_loss: 0.0704 - val_accuracy: 0.9706\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.9609 - val_loss: 0.0786 - val_accuracy: 0.9672\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9625 - val_loss: 0.0938 - val_accuracy: 0.9598\n",
      "Epoch 176/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9602 - val_loss: 0.0676 - val_accuracy: 0.9709\n",
      "Epoch 177/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9605 - val_loss: 0.0727 - val_accuracy: 0.9700\n",
      "Epoch 178/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9619 - val_loss: 0.0819 - val_accuracy: 0.9662\n",
      "Epoch 179/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9624 - val_loss: 0.0759 - val_accuracy: 0.9689\n",
      "Epoch 180/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9617 - val_loss: 0.0715 - val_accuracy: 0.9685\n",
      "Epoch 181/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9615 - val_loss: 0.0640 - val_accuracy: 0.9726\n",
      "Epoch 182/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9606 - val_loss: 0.0649 - val_accuracy: 0.9718\n",
      "Epoch 183/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9609 - val_loss: 0.0874 - val_accuracy: 0.9649\n",
      "Epoch 184/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9620 - val_loss: 0.0790 - val_accuracy: 0.9675\n",
      "Epoch 185/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9622 - val_loss: 0.0896 - val_accuracy: 0.9627\n",
      "Epoch 186/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9614 - val_loss: 0.0752 - val_accuracy: 0.9684\n",
      "Epoch 187/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9628 - val_loss: 0.0778 - val_accuracy: 0.9678\n",
      "Epoch 188/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9633 - val_loss: 0.0738 - val_accuracy: 0.9697\n",
      "Epoch 189/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9630 - val_loss: 0.0773 - val_accuracy: 0.9672\n",
      "Epoch 190/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9635 - val_loss: 0.0776 - val_accuracy: 0.9683\n",
      "Epoch 191/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9627 - val_loss: 0.0669 - val_accuracy: 0.9719\n",
      "Epoch 192/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9648 - val_loss: 0.0731 - val_accuracy: 0.9699\n",
      "Epoch 193/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0978 - accuracy: 0.9629 - val_loss: 0.0753 - val_accuracy: 0.9694\n",
      "Epoch 194/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9620 - val_loss: 0.0645 - val_accuracy: 0.9725\n",
      "Epoch 195/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9629 - val_loss: 0.0710 - val_accuracy: 0.9710\n",
      "Epoch 196/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9652 - val_loss: 0.0651 - val_accuracy: 0.9731\n",
      "Epoch 197/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 0.9626 - val_loss: 0.0789 - val_accuracy: 0.9677\n",
      "Epoch 198/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0971 - accuracy: 0.9638 - val_loss: 0.0775 - val_accuracy: 0.9682\n",
      "Epoch 199/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9635 - val_loss: 0.0699 - val_accuracy: 0.9721\n",
      "Epoch 200/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9647 - val_loss: 0.0694 - val_accuracy: 0.9711\n",
      "Epoch 201/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9649 - val_loss: 0.0700 - val_accuracy: 0.9711\n",
      "Epoch 202/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9644 - val_loss: 0.0641 - val_accuracy: 0.9737\n",
      "Epoch 203/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9643 - val_loss: 0.0740 - val_accuracy: 0.9707\n",
      "Epoch 204/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9655 - val_loss: 0.0649 - val_accuracy: 0.9725\n",
      "Epoch 205/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9656 - val_loss: 0.0646 - val_accuracy: 0.9733\n",
      "Epoch 206/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9653 - val_loss: 0.0822 - val_accuracy: 0.9657\n",
      "Epoch 207/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9661 - val_loss: 0.0662 - val_accuracy: 0.9726\n",
      "Epoch 208/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9659 - val_loss: 0.0692 - val_accuracy: 0.9716\n",
      "Epoch 209/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9652 - val_loss: 0.0651 - val_accuracy: 0.9730\n",
      "Epoch 210/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0929 - accuracy: 0.9658 - val_loss: 0.0718 - val_accuracy: 0.9695\n",
      "Epoch 211/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9665 - val_loss: 0.0549 - val_accuracy: 0.9760\n",
      "Epoch 212/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9643 - val_loss: 0.0662 - val_accuracy: 0.9719\n",
      "Epoch 213/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9653 - val_loss: 0.0742 - val_accuracy: 0.9698\n",
      "Epoch 214/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9659 - val_loss: 0.0724 - val_accuracy: 0.9708\n",
      "Epoch 215/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9664 - val_loss: 0.0777 - val_accuracy: 0.9691\n",
      "Epoch 216/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9642 - val_loss: 0.0663 - val_accuracy: 0.9733\n",
      "Epoch 217/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.9665 - val_loss: 0.0777 - val_accuracy: 0.9680\n",
      "Epoch 218/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9662 - val_loss: 0.0628 - val_accuracy: 0.9735\n",
      "Epoch 219/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0909 - accuracy: 0.9667 - val_loss: 0.0819 - val_accuracy: 0.9678\n",
      "Epoch 220/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9676 - val_loss: 0.0716 - val_accuracy: 0.9704\n",
      "Epoch 221/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9663 - val_loss: 0.0767 - val_accuracy: 0.9693\n",
      "Epoch 222/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9646 - val_loss: 0.0717 - val_accuracy: 0.9707\n",
      "Epoch 223/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9644 - val_loss: 0.0624 - val_accuracy: 0.9737\n",
      "Epoch 224/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9673 - val_loss: 0.0809 - val_accuracy: 0.9678\n",
      "Epoch 225/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9656 - val_loss: 0.0731 - val_accuracy: 0.9693\n",
      "Epoch 226/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0884 - accuracy: 0.9677 - val_loss: 0.0637 - val_accuracy: 0.9730\n",
      "Epoch 227/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9672 - val_loss: 0.0662 - val_accuracy: 0.9726\n",
      "Epoch 228/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0907 - accuracy: 0.9663 - val_loss: 0.0649 - val_accuracy: 0.9730\n",
      "Epoch 229/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9684 - val_loss: 0.0687 - val_accuracy: 0.9711\n",
      "Epoch 230/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9673 - val_loss: 0.0664 - val_accuracy: 0.9733\n",
      "Epoch 231/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9675 - val_loss: 0.0635 - val_accuracy: 0.9739\n",
      "Epoch 232/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9684 - val_loss: 0.0677 - val_accuracy: 0.9717\n",
      "Epoch 233/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9685 - val_loss: 0.0688 - val_accuracy: 0.9714\n",
      "Epoch 234/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9682 - val_loss: 0.0728 - val_accuracy: 0.9706\n",
      "Epoch 235/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9685 - val_loss: 0.0605 - val_accuracy: 0.9740\n",
      "Epoch 236/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9687 - val_loss: 0.0587 - val_accuracy: 0.9746\n",
      "Epoch 237/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9673 - val_loss: 0.0677 - val_accuracy: 0.9713\n",
      "Epoch 238/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9676 - val_loss: 0.0749 - val_accuracy: 0.9689\n",
      "Epoch 239/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9690 - val_loss: 0.0675 - val_accuracy: 0.9725\n",
      "Epoch 240/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9682 - val_loss: 0.0690 - val_accuracy: 0.9715\n",
      "Epoch 241/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9678 - val_loss: 0.0550 - val_accuracy: 0.9764\n",
      "Epoch 242/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9662 - val_loss: 0.0820 - val_accuracy: 0.9670\n",
      "Epoch 243/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9694 - val_loss: 0.0777 - val_accuracy: 0.9687\n",
      "Epoch 244/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9683 - val_loss: 0.0702 - val_accuracy: 0.9709\n",
      "Epoch 245/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9695 - val_loss: 0.0715 - val_accuracy: 0.9706\n",
      "Epoch 246/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9690 - val_loss: 0.0654 - val_accuracy: 0.9729\n",
      "Epoch 247/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9698 - val_loss: 0.0680 - val_accuracy: 0.9725\n",
      "Epoch 248/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9696 - val_loss: 0.0688 - val_accuracy: 0.9715\n",
      "Epoch 249/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9696 - val_loss: 0.0707 - val_accuracy: 0.9705\n",
      "Epoch 250/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9703 - val_loss: 0.0664 - val_accuracy: 0.9730\n",
      "Epoch 251/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9691 - val_loss: 0.0548 - val_accuracy: 0.9764\n",
      "Epoch 252/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9693 - val_loss: 0.0673 - val_accuracy: 0.9727\n",
      "Epoch 253/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9706 - val_loss: 0.0582 - val_accuracy: 0.9766\n",
      "Epoch 254/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9690 - val_loss: 0.0639 - val_accuracy: 0.9730\n",
      "Epoch 255/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9701 - val_loss: 0.0671 - val_accuracy: 0.9725\n",
      "Epoch 256/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9713 - val_loss: 0.0613 - val_accuracy: 0.9747\n",
      "Epoch 257/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9699 - val_loss: 0.0807 - val_accuracy: 0.9680\n",
      "Epoch 258/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9697 - val_loss: 0.0636 - val_accuracy: 0.9739\n",
      "Epoch 259/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9705 - val_loss: 0.0778 - val_accuracy: 0.9688\n",
      "Epoch 260/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9693 - val_loss: 0.0624 - val_accuracy: 0.9745\n",
      "Epoch 261/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9707 - val_loss: 0.0624 - val_accuracy: 0.9735\n",
      "Epoch 262/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9700 - val_loss: 0.0605 - val_accuracy: 0.9753\n",
      "Epoch 263/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9701 - val_loss: 0.0576 - val_accuracy: 0.9749\n",
      "Epoch 264/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9709 - val_loss: 0.0687 - val_accuracy: 0.9726\n",
      "Epoch 265/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9704 - val_loss: 0.0548 - val_accuracy: 0.9768\n",
      "Epoch 266/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.9696 - val_loss: 0.0559 - val_accuracy: 0.9749\n",
      "Epoch 267/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9713 - val_loss: 0.0654 - val_accuracy: 0.9730\n",
      "Epoch 268/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9707 - val_loss: 0.0612 - val_accuracy: 0.9744\n",
      "Epoch 269/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9716 - val_loss: 0.0508 - val_accuracy: 0.9768\n",
      "Epoch 270/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9699 - val_loss: 0.0601 - val_accuracy: 0.9747\n",
      "Epoch 271/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9707 - val_loss: 0.0577 - val_accuracy: 0.9750\n",
      "Epoch 272/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9708 - val_loss: 0.0563 - val_accuracy: 0.9766\n",
      "Epoch 273/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9702 - val_loss: 0.0603 - val_accuracy: 0.9740\n",
      "Epoch 274/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9711 - val_loss: 0.0579 - val_accuracy: 0.9756\n",
      "Epoch 275/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9720 - val_loss: 0.0569 - val_accuracy: 0.9758\n",
      "Epoch 276/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9720 - val_loss: 0.0604 - val_accuracy: 0.9753\n",
      "Epoch 277/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9723 - val_loss: 0.0529 - val_accuracy: 0.9768\n",
      "Epoch 278/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9712 - val_loss: 0.0620 - val_accuracy: 0.9750\n",
      "Epoch 279/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9721 - val_loss: 0.0721 - val_accuracy: 0.9725\n",
      "Epoch 280/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9717 - val_loss: 0.0808 - val_accuracy: 0.9675\n",
      "Epoch 281/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9710 - val_loss: 0.0532 - val_accuracy: 0.9769\n",
      "Epoch 282/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9709 - val_loss: 0.0652 - val_accuracy: 0.9735\n",
      "Epoch 283/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9719 - val_loss: 0.0627 - val_accuracy: 0.9750\n",
      "Epoch 284/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9718 - val_loss: 0.0662 - val_accuracy: 0.9728\n",
      "Epoch 285/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9725 - val_loss: 0.0813 - val_accuracy: 0.9683\n",
      "Epoch 286/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9725 - val_loss: 0.0669 - val_accuracy: 0.9724\n",
      "Epoch 287/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9724 - val_loss: 0.0558 - val_accuracy: 0.9766\n",
      "Epoch 288/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9721 - val_loss: 0.0702 - val_accuracy: 0.9726\n",
      "Epoch 289/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9717 - val_loss: 0.0515 - val_accuracy: 0.9763\n",
      "Epoch 290/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9717 - val_loss: 0.0601 - val_accuracy: 0.9743\n",
      "Epoch 291/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9730 - val_loss: 0.0652 - val_accuracy: 0.9737\n",
      "Epoch 292/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9721 - val_loss: 0.0619 - val_accuracy: 0.9746\n",
      "Epoch 293/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9731 - val_loss: 0.0594 - val_accuracy: 0.9745\n",
      "Epoch 294/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9724 - val_loss: 0.0635 - val_accuracy: 0.9734\n",
      "Epoch 295/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.9724 - val_loss: 0.0643 - val_accuracy: 0.9726\n",
      "Epoch 296/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9727 - val_loss: 0.0567 - val_accuracy: 0.9757\n",
      "Epoch 297/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9737 - val_loss: 0.0670 - val_accuracy: 0.9730\n",
      "Epoch 298/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9725 - val_loss: 0.0594 - val_accuracy: 0.9755\n",
      "Epoch 299/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9736 - val_loss: 0.0651 - val_accuracy: 0.9734\n",
      "Epoch 300/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9730 - val_loss: 0.0626 - val_accuracy: 0.9744\n",
      "Epoch 301/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9728 - val_loss: 0.0680 - val_accuracy: 0.9723\n",
      "Epoch 302/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9726 - val_loss: 0.0780 - val_accuracy: 0.9690\n",
      "Epoch 303/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9728 - val_loss: 0.0565 - val_accuracy: 0.9758\n",
      "Epoch 304/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9725 - val_loss: 0.0544 - val_accuracy: 0.9770\n",
      "Epoch 305/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9728 - val_loss: 0.0576 - val_accuracy: 0.9747\n",
      "Epoch 306/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9730 - val_loss: 0.0568 - val_accuracy: 0.9758\n",
      "Epoch 307/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9731 - val_loss: 0.0618 - val_accuracy: 0.9741\n",
      "Epoch 308/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9744 - val_loss: 0.0577 - val_accuracy: 0.9751\n",
      "Epoch 309/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9723 - val_loss: 0.0554 - val_accuracy: 0.9771\n",
      "Epoch 310/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9743 - val_loss: 0.0640 - val_accuracy: 0.9741\n",
      "Epoch 311/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9745 - val_loss: 0.0762 - val_accuracy: 0.9700\n",
      "Epoch 312/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9740 - val_loss: 0.0578 - val_accuracy: 0.9758\n",
      "Epoch 313/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9748 - val_loss: 0.0642 - val_accuracy: 0.9733\n",
      "Epoch 314/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9739 - val_loss: 0.0577 - val_accuracy: 0.9751\n",
      "Epoch 315/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9734 - val_loss: 0.0623 - val_accuracy: 0.9740\n",
      "Epoch 316/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9736 - val_loss: 0.0492 - val_accuracy: 0.9780\n",
      "Epoch 317/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9739 - val_loss: 0.0602 - val_accuracy: 0.9750\n",
      "Epoch 318/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9750 - val_loss: 0.0625 - val_accuracy: 0.9741\n",
      "Epoch 319/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9740 - val_loss: 0.0596 - val_accuracy: 0.9750\n",
      "Epoch 320/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9745 - val_loss: 0.0551 - val_accuracy: 0.9757\n",
      "Epoch 321/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9727 - val_loss: 0.0636 - val_accuracy: 0.9739\n",
      "Epoch 322/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9728 - val_loss: 0.0588 - val_accuracy: 0.9748\n",
      "Epoch 323/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9750 - val_loss: 0.0591 - val_accuracy: 0.9753\n",
      "Epoch 324/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9747 - val_loss: 0.0637 - val_accuracy: 0.9740\n",
      "Epoch 325/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9734 - val_loss: 0.0533 - val_accuracy: 0.9765\n",
      "Epoch 326/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9749 - val_loss: 0.0552 - val_accuracy: 0.9759\n",
      "Epoch 327/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9744 - val_loss: 0.0601 - val_accuracy: 0.9753\n",
      "Epoch 328/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9748 - val_loss: 0.0579 - val_accuracy: 0.9757\n",
      "Epoch 329/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9766 - val_loss: 0.0581 - val_accuracy: 0.9755\n",
      "Epoch 330/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9739 - val_loss: 0.0707 - val_accuracy: 0.9718\n",
      "Epoch 331/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9742 - val_loss: 0.0660 - val_accuracy: 0.9744\n",
      "Epoch 332/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9748 - val_loss: 0.0553 - val_accuracy: 0.9767\n",
      "Epoch 333/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9746 - val_loss: 0.0539 - val_accuracy: 0.9776\n",
      "Epoch 334/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9751 - val_loss: 0.0592 - val_accuracy: 0.9756\n",
      "Epoch 335/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9757 - val_loss: 0.0575 - val_accuracy: 0.9757\n",
      "Epoch 336/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9746 - val_loss: 0.0517 - val_accuracy: 0.9767\n",
      "Epoch 337/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9748 - val_loss: 0.0554 - val_accuracy: 0.9766\n",
      "Epoch 338/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9742 - val_loss: 0.0571 - val_accuracy: 0.9760\n",
      "Epoch 339/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9749 - val_loss: 0.0627 - val_accuracy: 0.9746\n",
      "Epoch 340/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9745 - val_loss: 0.0590 - val_accuracy: 0.9749\n",
      "Epoch 341/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9750 - val_loss: 0.0645 - val_accuracy: 0.9734\n",
      "Epoch 342/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9737 - val_loss: 0.0616 - val_accuracy: 0.9745\n",
      "Epoch 343/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9753 - val_loss: 0.0580 - val_accuracy: 0.9761\n",
      "Epoch 344/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9756 - val_loss: 0.0615 - val_accuracy: 0.9753\n",
      "Epoch 345/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9755 - val_loss: 0.0653 - val_accuracy: 0.9738\n",
      "Epoch 346/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9751 - val_loss: 0.0575 - val_accuracy: 0.9757\n",
      "Epoch 347/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9757 - val_loss: 0.0696 - val_accuracy: 0.9726\n",
      "Epoch 348/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9761 - val_loss: 0.0531 - val_accuracy: 0.9771\n",
      "Epoch 349/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9748 - val_loss: 0.0774 - val_accuracy: 0.9701\n",
      "Epoch 350/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9756 - val_loss: 0.0589 - val_accuracy: 0.9756\n",
      "Epoch 351/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.9752 - val_loss: 0.0504 - val_accuracy: 0.9778\n",
      "Epoch 352/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9740 - val_loss: 0.0653 - val_accuracy: 0.9740\n",
      "Epoch 353/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9762 - val_loss: 0.0622 - val_accuracy: 0.9746\n",
      "Epoch 354/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9755 - val_loss: 0.0593 - val_accuracy: 0.9748\n",
      "Epoch 355/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9752 - val_loss: 0.0560 - val_accuracy: 0.9758\n",
      "Epoch 356/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9752 - val_loss: 0.0602 - val_accuracy: 0.9758\n",
      "Epoch 357/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9762 - val_loss: 0.0719 - val_accuracy: 0.9717\n",
      "Epoch 358/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9759 - val_loss: 0.0544 - val_accuracy: 0.9771\n",
      "Epoch 359/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9762 - val_loss: 0.0620 - val_accuracy: 0.9749\n",
      "Epoch 360/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9765 - val_loss: 0.0612 - val_accuracy: 0.9748\n",
      "Epoch 361/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9763 - val_loss: 0.0660 - val_accuracy: 0.9741\n",
      "Epoch 362/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9762 - val_loss: 0.0529 - val_accuracy: 0.9775\n",
      "Epoch 363/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9758 - val_loss: 0.0584 - val_accuracy: 0.9750\n",
      "Epoch 364/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9762 - val_loss: 0.0587 - val_accuracy: 0.9747\n",
      "Epoch 365/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9765 - val_loss: 0.0558 - val_accuracy: 0.9757\n",
      "Epoch 366/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9767 - val_loss: 0.0607 - val_accuracy: 0.9756\n",
      "Epoch 367/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9756 - val_loss: 0.0587 - val_accuracy: 0.9751\n",
      "Epoch 368/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9758 - val_loss: 0.0669 - val_accuracy: 0.9745\n",
      "Epoch 369/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9770 - val_loss: 0.0708 - val_accuracy: 0.9718\n",
      "Epoch 370/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9763 - val_loss: 0.0509 - val_accuracy: 0.9782\n",
      "Epoch 371/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9760 - val_loss: 0.0639 - val_accuracy: 0.9745\n",
      "Epoch 372/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9770 - val_loss: 0.0817 - val_accuracy: 0.9686\n",
      "Epoch 373/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9762 - val_loss: 0.0769 - val_accuracy: 0.9700\n",
      "Epoch 374/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9776 - val_loss: 0.0598 - val_accuracy: 0.9753\n",
      "Epoch 375/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9769 - val_loss: 0.0571 - val_accuracy: 0.9767\n",
      "Epoch 376/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9773 - val_loss: 0.0561 - val_accuracy: 0.9768\n",
      "Epoch 377/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9768 - val_loss: 0.0689 - val_accuracy: 0.9736\n",
      "Epoch 378/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9759 - val_loss: 0.0565 - val_accuracy: 0.9761\n",
      "Epoch 379/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9756 - val_loss: 0.0640 - val_accuracy: 0.9745\n",
      "Epoch 380/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9776 - val_loss: 0.0536 - val_accuracy: 0.9781\n",
      "Epoch 381/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9761 - val_loss: 0.0599 - val_accuracy: 0.9755\n",
      "Epoch 382/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.0478 - val_accuracy: 0.9788\n",
      "Epoch 383/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9769 - val_loss: 0.0537 - val_accuracy: 0.9779\n",
      "Epoch 384/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9765 - val_loss: 0.0655 - val_accuracy: 0.9749\n",
      "Epoch 385/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9768 - val_loss: 0.0550 - val_accuracy: 0.9770\n",
      "Epoch 386/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9761 - val_loss: 0.0674 - val_accuracy: 0.9748\n",
      "Epoch 387/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9774 - val_loss: 0.0621 - val_accuracy: 0.9748\n",
      "Epoch 388/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9764 - val_loss: 0.0614 - val_accuracy: 0.9753\n",
      "Epoch 389/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9777 - val_loss: 0.0680 - val_accuracy: 0.9731\n",
      "Epoch 390/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9773 - val_loss: 0.0566 - val_accuracy: 0.9765\n",
      "Epoch 391/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9767 - val_loss: 0.0529 - val_accuracy: 0.9776\n",
      "Epoch 392/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9769 - val_loss: 0.0635 - val_accuracy: 0.9751\n",
      "Epoch 393/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9766 - val_loss: 0.0531 - val_accuracy: 0.9778\n",
      "Epoch 394/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9779 - val_loss: 0.0622 - val_accuracy: 0.9744\n",
      "Epoch 395/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9775 - val_loss: 0.0563 - val_accuracy: 0.9766\n",
      "Epoch 396/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0656 - accuracy: 0.9773 - val_loss: 0.0542 - val_accuracy: 0.9767\n",
      "Epoch 397/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9779 - val_loss: 0.0648 - val_accuracy: 0.9738\n",
      "Epoch 398/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9764 - val_loss: 0.0556 - val_accuracy: 0.9773\n",
      "Epoch 399/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.0480 - val_accuracy: 0.9786\n",
      "Epoch 400/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9758 - val_loss: 0.0555 - val_accuracy: 0.9770\n",
      "Epoch 401/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9777 - val_loss: 0.0635 - val_accuracy: 0.9751\n",
      "Epoch 402/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9778 - val_loss: 0.0552 - val_accuracy: 0.9766\n",
      "Epoch 403/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9785 - val_loss: 0.0553 - val_accuracy: 0.9764\n",
      "Epoch 404/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9790 - val_loss: 0.0621 - val_accuracy: 0.9744\n",
      "Epoch 405/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9783 - val_loss: 0.0580 - val_accuracy: 0.9766\n",
      "Epoch 406/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9777 - val_loss: 0.0599 - val_accuracy: 0.9751\n",
      "Epoch 407/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9769 - val_loss: 0.0594 - val_accuracy: 0.9756\n",
      "Epoch 408/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9780 - val_loss: 0.0604 - val_accuracy: 0.9759\n",
      "Epoch 409/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9778 - val_loss: 0.0611 - val_accuracy: 0.9751\n",
      "Epoch 410/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9773 - val_loss: 0.0552 - val_accuracy: 0.9771\n",
      "Epoch 411/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9775 - val_loss: 0.0620 - val_accuracy: 0.9754\n",
      "Epoch 412/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9767 - val_loss: 0.0647 - val_accuracy: 0.9743\n",
      "Epoch 413/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9779 - val_loss: 0.0530 - val_accuracy: 0.9777\n",
      "Epoch 414/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9783 - val_loss: 0.0508 - val_accuracy: 0.9775\n",
      "Epoch 415/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9788 - val_loss: 0.0496 - val_accuracy: 0.9778\n",
      "Epoch 416/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9778 - val_loss: 0.0584 - val_accuracy: 0.9768\n",
      "Epoch 417/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9785 - val_loss: 0.0603 - val_accuracy: 0.9753\n",
      "Epoch 418/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9781 - val_loss: 0.0685 - val_accuracy: 0.9726\n",
      "Epoch 419/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9780 - val_loss: 0.0710 - val_accuracy: 0.9740\n",
      "Epoch 420/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9783 - val_loss: 0.0641 - val_accuracy: 0.9759\n",
      "Epoch 421/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9776 - val_loss: 0.0535 - val_accuracy: 0.9774\n",
      "Epoch 422/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9786 - val_loss: 0.0590 - val_accuracy: 0.9767\n",
      "Epoch 423/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9790 - val_loss: 0.0500 - val_accuracy: 0.9778\n",
      "Epoch 424/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9787 - val_loss: 0.0526 - val_accuracy: 0.9775\n",
      "Epoch 425/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9782 - val_loss: 0.0609 - val_accuracy: 0.9765\n",
      "Epoch 426/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9777 - val_loss: 0.0569 - val_accuracy: 0.9765\n",
      "Epoch 427/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9786 - val_loss: 0.0590 - val_accuracy: 0.9758\n",
      "Epoch 428/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 0.0485 - val_accuracy: 0.9779\n",
      "Epoch 429/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9782 - val_loss: 0.0731 - val_accuracy: 0.9727\n",
      "Epoch 430/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9777 - val_loss: 0.0524 - val_accuracy: 0.9776\n",
      "Epoch 431/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9783 - val_loss: 0.0619 - val_accuracy: 0.9753\n",
      "Epoch 432/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9779 - val_loss: 0.0672 - val_accuracy: 0.9743\n",
      "Epoch 433/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9773 - val_loss: 0.0554 - val_accuracy: 0.9774\n",
      "Epoch 434/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9788 - val_loss: 0.0552 - val_accuracy: 0.9770\n",
      "Epoch 435/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9790 - val_loss: 0.0566 - val_accuracy: 0.9763\n",
      "Epoch 436/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9775 - val_loss: 0.0664 - val_accuracy: 0.9745\n",
      "Epoch 437/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9778 - val_loss: 0.0650 - val_accuracy: 0.9751\n",
      "Epoch 438/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9784 - val_loss: 0.0524 - val_accuracy: 0.9778\n",
      "Epoch 439/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9782 - val_loss: 0.0499 - val_accuracy: 0.9773\n",
      "Epoch 440/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9777 - val_loss: 0.0542 - val_accuracy: 0.9770\n",
      "Epoch 441/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9794 - val_loss: 0.0555 - val_accuracy: 0.9760\n",
      "Epoch 442/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9782 - val_loss: 0.0620 - val_accuracy: 0.9754\n",
      "Epoch 443/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.0558 - val_accuracy: 0.9771\n",
      "Epoch 444/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9782 - val_loss: 0.0476 - val_accuracy: 0.9787\n",
      "Epoch 445/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9788 - val_loss: 0.0523 - val_accuracy: 0.9779\n",
      "Epoch 446/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9775 - val_loss: 0.0574 - val_accuracy: 0.9773\n",
      "Epoch 447/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9777 - val_loss: 0.0548 - val_accuracy: 0.9770\n",
      "Epoch 448/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9794 - val_loss: 0.0709 - val_accuracy: 0.9730\n",
      "Epoch 449/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9781 - val_loss: 0.0576 - val_accuracy: 0.9765\n",
      "Epoch 450/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9795 - val_loss: 0.0476 - val_accuracy: 0.9789\n",
      "Epoch 451/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9788 - val_loss: 0.0575 - val_accuracy: 0.9777\n",
      "Epoch 452/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9790 - val_loss: 0.0512 - val_accuracy: 0.9776\n",
      "Epoch 453/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9781 - val_loss: 0.0634 - val_accuracy: 0.9750\n",
      "Epoch 454/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9776 - val_loss: 0.0539 - val_accuracy: 0.9779\n",
      "Epoch 455/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9784 - val_loss: 0.0520 - val_accuracy: 0.9774\n",
      "Epoch 456/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.0479 - val_accuracy: 0.9789\n",
      "Epoch 457/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9787 - val_loss: 0.0478 - val_accuracy: 0.9784\n",
      "Epoch 458/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9789 - val_loss: 0.0503 - val_accuracy: 0.9782\n",
      "Epoch 459/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9790 - val_loss: 0.0495 - val_accuracy: 0.9775\n",
      "Epoch 460/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9779 - val_loss: 0.0607 - val_accuracy: 0.9754\n",
      "Epoch 461/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9782 - val_loss: 0.0523 - val_accuracy: 0.9778\n",
      "Epoch 462/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9788 - val_loss: 0.0562 - val_accuracy: 0.9765\n",
      "Epoch 463/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9792 - val_loss: 0.0612 - val_accuracy: 0.9750\n",
      "Epoch 464/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9797 - val_loss: 0.0543 - val_accuracy: 0.9766\n",
      "Epoch 465/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9788 - val_loss: 0.0535 - val_accuracy: 0.9767\n",
      "Epoch 466/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9784 - val_loss: 0.0569 - val_accuracy: 0.9765\n",
      "Epoch 467/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9788 - val_loss: 0.0602 - val_accuracy: 0.9764\n",
      "Epoch 468/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9793 - val_loss: 0.0564 - val_accuracy: 0.9763\n",
      "Epoch 469/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9791 - val_loss: 0.0588 - val_accuracy: 0.9751\n",
      "Epoch 470/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9789 - val_loss: 0.0550 - val_accuracy: 0.9771\n",
      "Epoch 471/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9790 - val_loss: 0.0603 - val_accuracy: 0.9757\n",
      "Epoch 472/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 0.0491 - val_accuracy: 0.9779\n",
      "Epoch 473/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9793 - val_loss: 0.0568 - val_accuracy: 0.9769\n",
      "Epoch 474/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9788 - val_loss: 0.0570 - val_accuracy: 0.9775\n",
      "Epoch 475/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9786 - val_loss: 0.0497 - val_accuracy: 0.9780\n",
      "Epoch 476/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9796 - val_loss: 0.0584 - val_accuracy: 0.9761\n",
      "Epoch 477/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9796 - val_loss: 0.0501 - val_accuracy: 0.9782\n",
      "Epoch 478/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9784 - val_loss: 0.0553 - val_accuracy: 0.9769\n",
      "Epoch 479/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9793 - val_loss: 0.0545 - val_accuracy: 0.9770\n",
      "Epoch 480/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9789 - val_loss: 0.0564 - val_accuracy: 0.9774\n",
      "Epoch 481/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9788 - val_loss: 0.0516 - val_accuracy: 0.9780\n",
      "Epoch 482/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9789 - val_loss: 0.0541 - val_accuracy: 0.9771\n",
      "Epoch 483/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9790 - val_loss: 0.0543 - val_accuracy: 0.9774\n",
      "Epoch 484/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9800 - val_loss: 0.0661 - val_accuracy: 0.9758\n",
      "Epoch 485/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9778 - val_loss: 0.0507 - val_accuracy: 0.9780\n",
      "Epoch 486/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9786 - val_loss: 0.0651 - val_accuracy: 0.9750\n",
      "Epoch 487/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9791 - val_loss: 0.0579 - val_accuracy: 0.9765\n",
      "Epoch 488/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9784 - val_loss: 0.0500 - val_accuracy: 0.9774\n",
      "Epoch 489/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9797 - val_loss: 0.0471 - val_accuracy: 0.9795\n",
      "Epoch 490/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9791 - val_loss: 0.0598 - val_accuracy: 0.9758\n",
      "Epoch 491/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9793 - val_loss: 0.0590 - val_accuracy: 0.9767\n",
      "Epoch 492/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9797 - val_loss: 0.0514 - val_accuracy: 0.9777\n",
      "Epoch 493/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9796 - val_loss: 0.0552 - val_accuracy: 0.9770\n",
      "Epoch 494/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9803 - val_loss: 0.0640 - val_accuracy: 0.9756\n",
      "Epoch 495/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9790 - val_loss: 0.0496 - val_accuracy: 0.9771\n",
      "Epoch 496/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9807 - val_loss: 0.0502 - val_accuracy: 0.9769\n",
      "Epoch 497/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9798 - val_loss: 0.0550 - val_accuracy: 0.9769\n",
      "Epoch 498/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9791 - val_loss: 0.0571 - val_accuracy: 0.9759\n",
      "Epoch 499/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 0.0461 - val_accuracy: 0.9798\n",
      "Epoch 500/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9791 - val_loss: 0.0504 - val_accuracy: 0.9777\n",
      "Epoch 501/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9797 - val_loss: 0.0592 - val_accuracy: 0.9759\n",
      "Epoch 502/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9789 - val_loss: 0.0631 - val_accuracy: 0.9755\n",
      "Epoch 503/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9793 - val_loss: 0.0591 - val_accuracy: 0.9760\n",
      "Epoch 504/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9786 - val_loss: 0.0654 - val_accuracy: 0.9746\n",
      "Epoch 505/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9793 - val_loss: 0.0600 - val_accuracy: 0.9766\n",
      "Epoch 506/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9779 - val_loss: 0.0623 - val_accuracy: 0.9756\n",
      "Epoch 507/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9798 - val_loss: 0.0621 - val_accuracy: 0.9757\n",
      "Epoch 508/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.0510 - val_accuracy: 0.9779\n",
      "Epoch 509/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 0.0551 - val_accuracy: 0.9773\n",
      "Epoch 510/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9805 - val_loss: 0.0546 - val_accuracy: 0.9766\n",
      "Epoch 511/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9800 - val_loss: 0.0581 - val_accuracy: 0.9765\n",
      "Epoch 512/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9802 - val_loss: 0.0571 - val_accuracy: 0.9765\n",
      "Epoch 513/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9795 - val_loss: 0.0563 - val_accuracy: 0.9767\n",
      "Epoch 514/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9804 - val_loss: 0.0678 - val_accuracy: 0.9746\n",
      "Epoch 515/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9785 - val_loss: 0.0540 - val_accuracy: 0.9773\n",
      "Epoch 516/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9797 - val_loss: 0.0591 - val_accuracy: 0.9765\n",
      "Epoch 517/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9798 - val_loss: 0.0552 - val_accuracy: 0.9776\n",
      "Epoch 518/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 0.0606 - val_accuracy: 0.9757\n",
      "Epoch 519/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9795 - val_loss: 0.0572 - val_accuracy: 0.9759\n",
      "Epoch 520/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9800 - val_loss: 0.0602 - val_accuracy: 0.9763\n",
      "Epoch 521/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9792 - val_loss: 0.0527 - val_accuracy: 0.9778\n",
      "Epoch 522/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9792 - val_loss: 0.0584 - val_accuracy: 0.9768\n",
      "Epoch 523/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9787 - val_loss: 0.0563 - val_accuracy: 0.9774\n",
      "Epoch 524/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9797 - val_loss: 0.0545 - val_accuracy: 0.9774\n",
      "Epoch 525/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9795 - val_loss: 0.0493 - val_accuracy: 0.9785\n",
      "Epoch 526/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9795 - val_loss: 0.0580 - val_accuracy: 0.9768\n",
      "Epoch 527/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9792 - val_loss: 0.0551 - val_accuracy: 0.9773\n",
      "Epoch 528/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9798 - val_loss: 0.0502 - val_accuracy: 0.9776\n",
      "Epoch 529/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9789 - val_loss: 0.0620 - val_accuracy: 0.9764\n",
      "Epoch 530/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9796 - val_loss: 0.0570 - val_accuracy: 0.9765\n",
      "Epoch 531/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9797 - val_loss: 0.0520 - val_accuracy: 0.9769\n",
      "Epoch 532/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 0.0515 - val_accuracy: 0.9769\n",
      "Epoch 533/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9795 - val_loss: 0.0597 - val_accuracy: 0.9766\n",
      "Epoch 534/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9796 - val_loss: 0.0482 - val_accuracy: 0.9780\n",
      "Epoch 535/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9798 - val_loss: 0.0595 - val_accuracy: 0.9767\n",
      "Epoch 536/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9797 - val_loss: 0.0527 - val_accuracy: 0.9776\n",
      "Epoch 537/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.0555 - val_accuracy: 0.9773\n",
      "Epoch 538/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9807 - val_loss: 0.0542 - val_accuracy: 0.9777\n",
      "Epoch 539/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9796 - val_loss: 0.0571 - val_accuracy: 0.9775\n",
      "Epoch 540/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.0519 - val_accuracy: 0.9782\n",
      "Epoch 541/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9797 - val_loss: 0.0625 - val_accuracy: 0.9759\n",
      "Epoch 542/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9798 - val_loss: 0.0572 - val_accuracy: 0.9781\n",
      "Epoch 543/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9792 - val_loss: 0.0540 - val_accuracy: 0.9778\n",
      "Epoch 544/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9800 - val_loss: 0.0636 - val_accuracy: 0.9760\n",
      "Epoch 545/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9799 - val_loss: 0.0615 - val_accuracy: 0.9761\n",
      "Epoch 546/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9797 - val_loss: 0.0576 - val_accuracy: 0.9769\n",
      "Epoch 547/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.0524 - val_accuracy: 0.9765\n",
      "Epoch 548/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9812 - val_loss: 0.0541 - val_accuracy: 0.9769\n",
      "Epoch 549/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9797 - val_loss: 0.0559 - val_accuracy: 0.9764\n",
      "Epoch 550/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9793 - val_loss: 0.0620 - val_accuracy: 0.9755\n",
      "Epoch 551/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 0.0531 - val_accuracy: 0.9771\n",
      "Epoch 552/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9805 - val_loss: 0.0490 - val_accuracy: 0.9785\n",
      "Epoch 553/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0559 - accuracy: 0.9804 - val_loss: 0.0596 - val_accuracy: 0.9758\n",
      "Epoch 554/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9798 - val_loss: 0.0640 - val_accuracy: 0.9754\n",
      "Epoch 555/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.0622 - val_accuracy: 0.9754\n",
      "Epoch 556/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9799 - val_loss: 0.0499 - val_accuracy: 0.9794\n",
      "Epoch 557/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9802 - val_loss: 0.0598 - val_accuracy: 0.9759\n",
      "Epoch 558/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9802 - val_loss: 0.0566 - val_accuracy: 0.9776\n",
      "Epoch 559/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9793 - val_loss: 0.0786 - val_accuracy: 0.9719\n",
      "Epoch 560/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 0.0672 - val_accuracy: 0.9754\n",
      "Epoch 561/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9803 - val_loss: 0.0562 - val_accuracy: 0.9770\n",
      "Epoch 562/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9806 - val_loss: 0.0509 - val_accuracy: 0.9791\n",
      "Epoch 563/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.0568 - val_accuracy: 0.9766\n",
      "Epoch 564/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9801 - val_loss: 0.0618 - val_accuracy: 0.9756\n",
      "Epoch 565/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9793 - val_loss: 0.0595 - val_accuracy: 0.9757\n",
      "Epoch 566/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9805 - val_loss: 0.0657 - val_accuracy: 0.9754\n",
      "Epoch 567/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9794 - val_loss: 0.0505 - val_accuracy: 0.9784\n",
      "Epoch 568/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9805 - val_loss: 0.0633 - val_accuracy: 0.9754\n",
      "Epoch 569/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9792 - val_loss: 0.0539 - val_accuracy: 0.9778\n",
      "Epoch 570/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9802 - val_loss: 0.0595 - val_accuracy: 0.9765\n",
      "Epoch 571/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 0.0579 - val_accuracy: 0.9768\n",
      "Epoch 572/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9798 - val_loss: 0.0578 - val_accuracy: 0.9766\n",
      "Epoch 573/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9806 - val_loss: 0.0511 - val_accuracy: 0.9776\n",
      "Epoch 574/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9807 - val_loss: 0.0629 - val_accuracy: 0.9754\n",
      "Epoch 575/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9793 - val_loss: 0.0508 - val_accuracy: 0.9780\n",
      "Epoch 576/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9807 - val_loss: 0.0629 - val_accuracy: 0.9747\n",
      "Epoch 577/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9799 - val_loss: 0.0544 - val_accuracy: 0.9774\n",
      "Epoch 578/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9803 - val_loss: 0.0541 - val_accuracy: 0.9767\n",
      "Epoch 579/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 0.0565 - val_accuracy: 0.9770\n",
      "Epoch 580/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9812 - val_loss: 0.0661 - val_accuracy: 0.9743\n",
      "Epoch 581/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9803 - val_loss: 0.0620 - val_accuracy: 0.9760\n",
      "Epoch 582/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9800 - val_loss: 0.0549 - val_accuracy: 0.9770\n",
      "Epoch 583/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9799 - val_loss: 0.0469 - val_accuracy: 0.9798\n",
      "Epoch 584/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9806 - val_loss: 0.0599 - val_accuracy: 0.9761\n",
      "Epoch 585/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9809 - val_loss: 0.0588 - val_accuracy: 0.9765\n",
      "Epoch 586/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9804 - val_loss: 0.0596 - val_accuracy: 0.9760\n",
      "Epoch 587/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9807 - val_loss: 0.0548 - val_accuracy: 0.9779\n",
      "Epoch 588/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.0519 - val_accuracy: 0.9778\n",
      "Epoch 589/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9804 - val_loss: 0.0511 - val_accuracy: 0.9773\n",
      "Epoch 590/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9807 - val_loss: 0.0687 - val_accuracy: 0.9755\n",
      "Epoch 591/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9813 - val_loss: 0.0512 - val_accuracy: 0.9778\n",
      "Epoch 592/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9799 - val_loss: 0.0576 - val_accuracy: 0.9764\n",
      "Epoch 593/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.0535 - val_accuracy: 0.9770\n",
      "Epoch 594/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9796 - val_loss: 0.0544 - val_accuracy: 0.9773\n",
      "Epoch 595/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9816 - val_loss: 0.0584 - val_accuracy: 0.9769\n",
      "Epoch 596/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 0.0511 - val_accuracy: 0.9785\n",
      "Epoch 597/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9809 - val_loss: 0.0604 - val_accuracy: 0.9766\n",
      "Epoch 598/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9818 - val_loss: 0.0543 - val_accuracy: 0.9773\n",
      "Epoch 599/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9809 - val_loss: 0.0597 - val_accuracy: 0.9760\n",
      "Epoch 600/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9807 - val_loss: 0.0487 - val_accuracy: 0.9781\n",
      "Epoch 601/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9803 - val_loss: 0.0517 - val_accuracy: 0.9774\n",
      "Epoch 602/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9812 - val_loss: 0.0493 - val_accuracy: 0.9792\n",
      "Epoch 603/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9802 - val_loss: 0.0557 - val_accuracy: 0.9769\n",
      "Epoch 604/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9804 - val_loss: 0.0520 - val_accuracy: 0.9785\n",
      "Epoch 605/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9808 - val_loss: 0.0518 - val_accuracy: 0.9767\n",
      "Epoch 606/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9807 - val_loss: 0.0619 - val_accuracy: 0.9764\n",
      "Epoch 607/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9815 - val_loss: 0.0609 - val_accuracy: 0.9768\n",
      "Epoch 608/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9807 - val_loss: 0.0532 - val_accuracy: 0.9776\n",
      "Epoch 609/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9805 - val_loss: 0.0500 - val_accuracy: 0.9795\n",
      "Epoch 610/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9807 - val_loss: 0.0510 - val_accuracy: 0.9790\n",
      "Epoch 611/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9802 - val_loss: 0.0518 - val_accuracy: 0.9778\n",
      "Epoch 612/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9803 - val_loss: 0.0549 - val_accuracy: 0.9774\n",
      "Epoch 613/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9803 - val_loss: 0.0597 - val_accuracy: 0.9761\n",
      "Epoch 614/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9798 - val_loss: 0.0594 - val_accuracy: 0.9765\n",
      "Epoch 615/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9806 - val_loss: 0.0527 - val_accuracy: 0.9779\n",
      "Epoch 616/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9804 - val_loss: 0.0608 - val_accuracy: 0.9763\n",
      "Epoch 617/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0577 - val_accuracy: 0.9766\n",
      "Epoch 618/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9814 - val_loss: 0.0547 - val_accuracy: 0.9775\n",
      "Epoch 619/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0569 - val_accuracy: 0.9767\n",
      "Epoch 620/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9806 - val_loss: 0.0506 - val_accuracy: 0.9778\n",
      "Epoch 621/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9819 - val_loss: 0.0604 - val_accuracy: 0.9760\n",
      "Epoch 622/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9807 - val_loss: 0.0563 - val_accuracy: 0.9767\n",
      "Epoch 623/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9811 - val_loss: 0.0519 - val_accuracy: 0.9787\n",
      "Epoch 624/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9808 - val_loss: 0.0568 - val_accuracy: 0.9774\n",
      "Epoch 625/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9804 - val_loss: 0.0537 - val_accuracy: 0.9775\n",
      "Epoch 626/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0554 - val_accuracy: 0.9778\n",
      "Epoch 627/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.0537 - val_accuracy: 0.9780\n",
      "Epoch 628/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9814 - val_loss: 0.0456 - val_accuracy: 0.9794\n",
      "Epoch 629/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9805 - val_loss: 0.0567 - val_accuracy: 0.9773\n",
      "Epoch 630/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 0.0498 - val_accuracy: 0.9788\n",
      "Epoch 631/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9796 - val_loss: 0.0625 - val_accuracy: 0.9757\n",
      "Epoch 632/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9806 - val_loss: 0.0579 - val_accuracy: 0.9758\n",
      "Epoch 633/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9802 - val_loss: 0.0533 - val_accuracy: 0.9775\n",
      "Epoch 634/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 0.0505 - val_accuracy: 0.9781\n",
      "Epoch 635/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9800 - val_loss: 0.0617 - val_accuracy: 0.9764\n",
      "Epoch 636/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9806 - val_loss: 0.0614 - val_accuracy: 0.9760\n",
      "Epoch 637/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9815 - val_loss: 0.0542 - val_accuracy: 0.9766\n",
      "Epoch 638/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9807 - val_loss: 0.0498 - val_accuracy: 0.9777\n",
      "Epoch 639/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9806 - val_loss: 0.0577 - val_accuracy: 0.9769\n",
      "Epoch 640/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9808 - val_loss: 0.0607 - val_accuracy: 0.9766\n",
      "Epoch 641/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9806 - val_loss: 0.0592 - val_accuracy: 0.9771\n",
      "Epoch 642/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9806 - val_loss: 0.0486 - val_accuracy: 0.9785\n",
      "Epoch 643/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9807 - val_loss: 0.0634 - val_accuracy: 0.9763\n",
      "Epoch 644/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9806 - val_loss: 0.0505 - val_accuracy: 0.9790\n",
      "Epoch 645/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9813 - val_loss: 0.0526 - val_accuracy: 0.9778\n",
      "Epoch 646/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9803 - val_loss: 0.0550 - val_accuracy: 0.9778\n",
      "Epoch 647/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9812 - val_loss: 0.0590 - val_accuracy: 0.9765\n",
      "Epoch 648/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9813 - val_loss: 0.0646 - val_accuracy: 0.9753\n",
      "Epoch 649/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9817 - val_loss: 0.0574 - val_accuracy: 0.9771\n",
      "Epoch 650/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.0533 - val_accuracy: 0.9779\n",
      "Epoch 651/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.0539 - val_accuracy: 0.9781\n",
      "Epoch 652/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9813 - val_loss: 0.0580 - val_accuracy: 0.9769\n",
      "Epoch 653/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9816 - val_loss: 0.0593 - val_accuracy: 0.9765\n",
      "Epoch 654/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9820 - val_loss: 0.0526 - val_accuracy: 0.9785\n",
      "Epoch 655/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9819 - val_loss: 0.0577 - val_accuracy: 0.9768\n",
      "Epoch 656/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9821 - val_loss: 0.0543 - val_accuracy: 0.9782\n",
      "Epoch 657/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9816 - val_loss: 0.0621 - val_accuracy: 0.9766\n",
      "Epoch 658/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9814 - val_loss: 0.0591 - val_accuracy: 0.9765\n",
      "Epoch 659/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9817 - val_loss: 0.0528 - val_accuracy: 0.9788\n",
      "Epoch 660/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9800 - val_loss: 0.0574 - val_accuracy: 0.9767\n",
      "Epoch 661/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9812 - val_loss: 0.0582 - val_accuracy: 0.9765\n",
      "Epoch 662/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9811 - val_loss: 0.0559 - val_accuracy: 0.9769\n",
      "Epoch 663/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9809 - val_loss: 0.0584 - val_accuracy: 0.9770\n",
      "Epoch 664/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9799 - val_loss: 0.0582 - val_accuracy: 0.9773\n",
      "Epoch 665/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9808 - val_loss: 0.0501 - val_accuracy: 0.9792\n",
      "Epoch 666/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 0.0560 - val_accuracy: 0.9773\n",
      "Epoch 667/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9813 - val_loss: 0.0558 - val_accuracy: 0.9777\n",
      "Epoch 668/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9809 - val_loss: 0.0595 - val_accuracy: 0.9771\n",
      "Epoch 669/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9816 - val_loss: 0.0537 - val_accuracy: 0.9792\n",
      "Epoch 670/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0543 - val_accuracy: 0.9780\n",
      "Epoch 671/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9821 - val_loss: 0.0590 - val_accuracy: 0.9764\n",
      "Epoch 672/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9812 - val_loss: 0.0654 - val_accuracy: 0.9756\n",
      "Epoch 673/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9806 - val_loss: 0.0590 - val_accuracy: 0.9769\n",
      "Epoch 674/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0544 - val_accuracy: 0.9773\n",
      "Epoch 675/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9821 - val_loss: 0.0570 - val_accuracy: 0.9765\n",
      "Epoch 676/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9807 - val_loss: 0.0543 - val_accuracy: 0.9787\n",
      "Epoch 677/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9803 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
      "Epoch 678/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.0524 - val_accuracy: 0.9775\n",
      "Epoch 679/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0535 - val_accuracy: 0.9776\n",
      "Epoch 680/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9818 - val_loss: 0.0603 - val_accuracy: 0.9770\n",
      "Epoch 681/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9817 - val_loss: 0.0563 - val_accuracy: 0.9767\n",
      "Epoch 682/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9809 - val_loss: 0.0558 - val_accuracy: 0.9770\n",
      "Epoch 683/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9816 - val_loss: 0.0495 - val_accuracy: 0.9788\n",
      "Epoch 684/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9805 - val_loss: 0.0585 - val_accuracy: 0.9782\n",
      "Epoch 685/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9811 - val_loss: 0.0534 - val_accuracy: 0.9774\n",
      "Epoch 686/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.0558 - val_accuracy: 0.9777\n",
      "Epoch 687/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0525 - val_accuracy: 0.9782\n",
      "Epoch 688/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9812 - val_loss: 0.0508 - val_accuracy: 0.9787\n",
      "Epoch 689/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.0467 - val_accuracy: 0.9800\n",
      "Epoch 690/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9817 - val_loss: 0.0582 - val_accuracy: 0.9771\n",
      "Epoch 691/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9811 - val_loss: 0.0540 - val_accuracy: 0.9778\n",
      "Epoch 692/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0543 - val_accuracy: 0.9774\n",
      "Epoch 693/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9801 - val_loss: 0.0565 - val_accuracy: 0.9768\n",
      "Epoch 694/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9803 - val_loss: 0.0615 - val_accuracy: 0.9757\n",
      "Epoch 695/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9812 - val_loss: 0.0501 - val_accuracy: 0.9790\n",
      "Epoch 696/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9816 - val_loss: 0.0534 - val_accuracy: 0.9774\n",
      "Epoch 697/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9814 - val_loss: 0.0478 - val_accuracy: 0.9786\n",
      "Epoch 698/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9811 - val_loss: 0.0575 - val_accuracy: 0.9773\n",
      "Epoch 699/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9806 - val_loss: 0.0588 - val_accuracy: 0.9776\n",
      "Epoch 700/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9811 - val_loss: 0.0532 - val_accuracy: 0.9781\n",
      "Epoch 701/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9819 - val_loss: 0.0555 - val_accuracy: 0.9774\n",
      "Epoch 702/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0574 - val_accuracy: 0.9770\n",
      "Epoch 703/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.0523 - val_accuracy: 0.9790\n",
      "Epoch 704/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9803 - val_loss: 0.0552 - val_accuracy: 0.9778\n",
      "Epoch 705/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9805 - val_loss: 0.0626 - val_accuracy: 0.9761\n",
      "Epoch 706/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9811 - val_loss: 0.0471 - val_accuracy: 0.9788\n",
      "Epoch 707/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9812 - val_loss: 0.0519 - val_accuracy: 0.9796\n",
      "Epoch 708/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9822 - val_loss: 0.0487 - val_accuracy: 0.9801\n",
      "Epoch 709/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9813 - val_loss: 0.0516 - val_accuracy: 0.9781\n",
      "Epoch 710/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9817 - val_loss: 0.0604 - val_accuracy: 0.9760\n",
      "Epoch 711/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9814 - val_loss: 0.0533 - val_accuracy: 0.9786\n",
      "Epoch 712/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.0515 - val_accuracy: 0.9778\n",
      "Epoch 713/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9812 - val_loss: 0.0488 - val_accuracy: 0.9790\n",
      "Epoch 714/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9814 - val_loss: 0.0505 - val_accuracy: 0.9789\n",
      "Epoch 715/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9809 - val_loss: 0.0538 - val_accuracy: 0.9784\n",
      "Epoch 716/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 0.0527 - val_accuracy: 0.9784\n",
      "Epoch 717/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9805 - val_loss: 0.0486 - val_accuracy: 0.9792\n",
      "Epoch 718/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 0.0506 - val_accuracy: 0.9782\n",
      "Epoch 719/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9814 - val_loss: 0.0524 - val_accuracy: 0.9778\n",
      "Epoch 720/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9821 - val_loss: 0.0547 - val_accuracy: 0.9777\n",
      "Epoch 721/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9811 - val_loss: 0.0574 - val_accuracy: 0.9768\n",
      "Epoch 722/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.0512 - val_accuracy: 0.9784\n",
      "Epoch 723/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 0.0569 - val_accuracy: 0.9771\n",
      "Epoch 724/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9806 - val_loss: 0.0545 - val_accuracy: 0.9779\n",
      "Epoch 725/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9812 - val_loss: 0.0531 - val_accuracy: 0.9776\n",
      "Epoch 726/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9821 - val_loss: 0.0555 - val_accuracy: 0.9781\n",
      "Epoch 727/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9826 - val_loss: 0.0580 - val_accuracy: 0.9769\n",
      "Epoch 728/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9807 - val_loss: 0.0547 - val_accuracy: 0.9779\n",
      "Epoch 729/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9813 - val_loss: 0.0606 - val_accuracy: 0.9766\n",
      "Epoch 730/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9817 - val_loss: 0.0534 - val_accuracy: 0.9786\n",
      "Epoch 731/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9809 - val_loss: 0.0644 - val_accuracy: 0.9761\n",
      "Epoch 732/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9801 - val_loss: 0.0500 - val_accuracy: 0.9787\n",
      "Epoch 733/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9817 - val_loss: 0.0601 - val_accuracy: 0.9767\n",
      "Epoch 734/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0593 - val_accuracy: 0.9766\n",
      "Epoch 735/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.0518 - val_accuracy: 0.9776\n",
      "Epoch 736/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9827 - val_loss: 0.0607 - val_accuracy: 0.9768\n",
      "Epoch 737/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0569 - val_accuracy: 0.9765\n",
      "Epoch 738/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9814 - val_loss: 0.0648 - val_accuracy: 0.9751\n",
      "Epoch 739/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9814 - val_loss: 0.0505 - val_accuracy: 0.9785\n",
      "Epoch 740/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.0585 - val_accuracy: 0.9770\n",
      "Epoch 741/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.0542 - val_accuracy: 0.9780\n",
      "Epoch 742/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9813 - val_loss: 0.0503 - val_accuracy: 0.9791\n",
      "Epoch 743/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9815 - val_loss: 0.0515 - val_accuracy: 0.9795\n",
      "Epoch 744/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.0519 - val_accuracy: 0.9788\n",
      "Epoch 745/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9816 - val_loss: 0.0618 - val_accuracy: 0.9765\n",
      "Epoch 746/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9804 - val_loss: 0.0567 - val_accuracy: 0.9774\n",
      "Epoch 747/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9811 - val_loss: 0.0546 - val_accuracy: 0.9780\n",
      "Epoch 748/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9814 - val_loss: 0.0598 - val_accuracy: 0.9773\n",
      "Epoch 749/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0534 - val_accuracy: 0.9779\n",
      "Epoch 750/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9816 - val_loss: 0.0548 - val_accuracy: 0.9773\n",
      "Epoch 751/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9814 - val_loss: 0.0568 - val_accuracy: 0.9774\n",
      "Epoch 752/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.0529 - val_accuracy: 0.9787\n",
      "Epoch 753/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9823 - val_loss: 0.0593 - val_accuracy: 0.9773\n",
      "Epoch 754/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 0.0473 - val_accuracy: 0.9802\n",
      "Epoch 755/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9811 - val_loss: 0.0527 - val_accuracy: 0.9782\n",
      "Epoch 756/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9815 - val_loss: 0.0543 - val_accuracy: 0.9774\n",
      "Epoch 757/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9809 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
      "Epoch 758/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9821 - val_loss: 0.0611 - val_accuracy: 0.9766\n",
      "Epoch 759/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9816 - val_loss: 0.0575 - val_accuracy: 0.9775\n",
      "Epoch 760/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9816 - val_loss: 0.0544 - val_accuracy: 0.9776\n",
      "Epoch 761/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9806 - val_loss: 0.0557 - val_accuracy: 0.9785\n",
      "Epoch 762/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9821 - val_loss: 0.0486 - val_accuracy: 0.9789\n",
      "Epoch 763/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9812 - val_loss: 0.0585 - val_accuracy: 0.9769\n",
      "Epoch 764/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0506 - val_accuracy: 0.9794\n",
      "Epoch 765/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9817 - val_loss: 0.0538 - val_accuracy: 0.9785\n",
      "Epoch 766/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9818 - val_loss: 0.0588 - val_accuracy: 0.9773\n",
      "Epoch 767/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9819 - val_loss: 0.0634 - val_accuracy: 0.9767\n",
      "Epoch 768/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9813 - val_loss: 0.0552 - val_accuracy: 0.9789\n",
      "Epoch 769/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9813 - val_loss: 0.0611 - val_accuracy: 0.9766\n",
      "Epoch 770/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9819 - val_loss: 0.0565 - val_accuracy: 0.9771\n",
      "Epoch 771/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.0508 - val_accuracy: 0.9788\n",
      "Epoch 772/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0526 - val_accuracy: 0.9789\n",
      "Epoch 773/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9813 - val_loss: 0.0550 - val_accuracy: 0.9774\n",
      "Epoch 774/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 0.0527 - val_accuracy: 0.9778\n",
      "Epoch 775/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9814 - val_loss: 0.0539 - val_accuracy: 0.9786\n",
      "Epoch 776/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9833 - val_loss: 0.0559 - val_accuracy: 0.9780\n",
      "Epoch 777/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9823 - val_loss: 0.0527 - val_accuracy: 0.9789\n",
      "Epoch 778/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.0561 - val_accuracy: 0.9774\n",
      "Epoch 779/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9818 - val_loss: 0.0523 - val_accuracy: 0.9782\n",
      "Epoch 780/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9823 - val_loss: 0.0593 - val_accuracy: 0.9771\n",
      "Epoch 781/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.0640 - val_accuracy: 0.9758\n",
      "Epoch 782/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9820 - val_loss: 0.0525 - val_accuracy: 0.9788\n",
      "Epoch 783/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9817 - val_loss: 0.0569 - val_accuracy: 0.9775\n",
      "Epoch 784/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9814 - val_loss: 0.0556 - val_accuracy: 0.9770\n",
      "Epoch 785/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9821 - val_loss: 0.0588 - val_accuracy: 0.9773\n",
      "Epoch 786/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9818 - val_loss: 0.0563 - val_accuracy: 0.9782\n",
      "Epoch 787/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9824 - val_loss: 0.0579 - val_accuracy: 0.9771\n",
      "Epoch 788/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9816 - val_loss: 0.0602 - val_accuracy: 0.9775\n",
      "Epoch 789/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9822 - val_loss: 0.0591 - val_accuracy: 0.9774\n",
      "Epoch 790/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0531 - val_accuracy: 0.9787\n",
      "Epoch 791/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9808 - val_loss: 0.0548 - val_accuracy: 0.9781\n",
      "Epoch 792/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 0.0531 - val_accuracy: 0.9780\n",
      "Epoch 793/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9819 - val_loss: 0.0567 - val_accuracy: 0.9777\n",
      "Epoch 794/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9811 - val_loss: 0.0623 - val_accuracy: 0.9760\n",
      "Epoch 795/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9822 - val_loss: 0.0563 - val_accuracy: 0.9774\n",
      "Epoch 796/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9825 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
      "Epoch 797/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9818 - val_loss: 0.0637 - val_accuracy: 0.9764\n",
      "Epoch 798/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9833 - val_loss: 0.0605 - val_accuracy: 0.9765\n",
      "Epoch 799/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 0.0499 - val_accuracy: 0.9790\n",
      "Epoch 800/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9816 - val_loss: 0.0603 - val_accuracy: 0.9767\n",
      "Epoch 801/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9816 - val_loss: 0.0566 - val_accuracy: 0.9774\n",
      "Epoch 802/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.0490 - val_accuracy: 0.9791\n",
      "Epoch 803/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9821 - val_loss: 0.0530 - val_accuracy: 0.9781\n",
      "Epoch 804/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9817 - val_loss: 0.0634 - val_accuracy: 0.9768\n",
      "Epoch 805/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9816 - val_loss: 0.0555 - val_accuracy: 0.9776\n",
      "Epoch 806/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9821 - val_loss: 0.0577 - val_accuracy: 0.9775\n",
      "Epoch 807/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.0595 - val_accuracy: 0.9764\n",
      "Epoch 808/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9826 - val_loss: 0.0542 - val_accuracy: 0.9787\n",
      "Epoch 809/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9817 - val_loss: 0.0530 - val_accuracy: 0.9786\n",
      "Epoch 810/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9819 - val_loss: 0.0558 - val_accuracy: 0.9778\n",
      "Epoch 811/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9820 - val_loss: 0.0496 - val_accuracy: 0.9790\n",
      "Epoch 812/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9820 - val_loss: 0.0528 - val_accuracy: 0.9779\n",
      "Epoch 813/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9818 - val_loss: 0.0561 - val_accuracy: 0.9775\n",
      "Epoch 814/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9822 - val_loss: 0.0574 - val_accuracy: 0.9777\n",
      "Epoch 815/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9815 - val_loss: 0.0553 - val_accuracy: 0.9775\n",
      "Epoch 816/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9812 - val_loss: 0.0608 - val_accuracy: 0.9770\n",
      "Epoch 817/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9809 - val_loss: 0.0529 - val_accuracy: 0.9784\n",
      "Epoch 818/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 0.0542 - val_accuracy: 0.9782\n",
      "Epoch 819/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9817 - val_loss: 0.0560 - val_accuracy: 0.9774\n",
      "Epoch 820/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9819 - val_loss: 0.0575 - val_accuracy: 0.9776\n",
      "Epoch 821/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9817 - val_loss: 0.0643 - val_accuracy: 0.9763\n",
      "Epoch 822/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9823 - val_loss: 0.0636 - val_accuracy: 0.9767\n",
      "Epoch 823/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9807 - val_loss: 0.0508 - val_accuracy: 0.9786\n",
      "Epoch 824/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.0523 - val_accuracy: 0.9791\n",
      "Epoch 825/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9825 - val_loss: 0.0497 - val_accuracy: 0.9795\n",
      "Epoch 826/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9817 - val_loss: 0.0534 - val_accuracy: 0.9784\n",
      "Epoch 827/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9807 - val_loss: 0.0546 - val_accuracy: 0.9774\n",
      "Epoch 828/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9829 - val_loss: 0.0631 - val_accuracy: 0.9769\n",
      "Epoch 829/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 0.0551 - val_accuracy: 0.9775\n",
      "Epoch 830/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9829 - val_loss: 0.0522 - val_accuracy: 0.9781\n",
      "Epoch 831/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9821 - val_loss: 0.0595 - val_accuracy: 0.9770\n",
      "Epoch 832/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9819 - val_loss: 0.0499 - val_accuracy: 0.9791\n",
      "Epoch 833/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 0.0540 - val_accuracy: 0.9779\n",
      "Epoch 834/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9829 - val_loss: 0.0481 - val_accuracy: 0.9792\n",
      "Epoch 835/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9820 - val_loss: 0.0590 - val_accuracy: 0.9768\n",
      "Epoch 836/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9824 - val_loss: 0.0501 - val_accuracy: 0.9787\n",
      "Epoch 837/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9821 - val_loss: 0.0523 - val_accuracy: 0.9794\n",
      "Epoch 838/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9828 - val_loss: 0.0684 - val_accuracy: 0.9760\n",
      "Epoch 839/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9827 - val_loss: 0.0514 - val_accuracy: 0.9787\n",
      "Epoch 840/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9825 - val_loss: 0.0546 - val_accuracy: 0.9785\n",
      "Epoch 841/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9830 - val_loss: 0.0481 - val_accuracy: 0.9792\n",
      "Epoch 842/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9822 - val_loss: 0.0502 - val_accuracy: 0.9794\n",
      "Epoch 843/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9820 - val_loss: 0.0544 - val_accuracy: 0.9787\n",
      "Epoch 844/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9825 - val_loss: 0.0620 - val_accuracy: 0.9766\n",
      "Epoch 845/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.0502 - val_accuracy: 0.9785\n",
      "Epoch 846/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9823 - val_loss: 0.0600 - val_accuracy: 0.9775\n",
      "Epoch 847/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9824 - val_loss: 0.0566 - val_accuracy: 0.9776\n",
      "Epoch 848/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9825 - val_loss: 0.0583 - val_accuracy: 0.9776\n",
      "Epoch 849/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9829 - val_loss: 0.0492 - val_accuracy: 0.9787\n",
      "Epoch 850/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9820 - val_loss: 0.0571 - val_accuracy: 0.9780\n",
      "Epoch 851/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9829 - val_loss: 0.0600 - val_accuracy: 0.9773\n",
      "Epoch 852/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.0501 - val_accuracy: 0.9798\n",
      "Epoch 853/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 0.0527 - val_accuracy: 0.9780\n",
      "Epoch 854/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9821 - val_loss: 0.0504 - val_accuracy: 0.9796\n",
      "Epoch 855/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9821 - val_loss: 0.0632 - val_accuracy: 0.9760\n",
      "Epoch 856/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0497 - accuracy: 0.9817 - val_loss: 0.0586 - val_accuracy: 0.9774\n",
      "Epoch 857/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9823 - val_loss: 0.0590 - val_accuracy: 0.9764\n",
      "Epoch 858/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9828 - val_loss: 0.0615 - val_accuracy: 0.9769\n",
      "Epoch 859/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9814 - val_loss: 0.0515 - val_accuracy: 0.9791\n",
      "Epoch 860/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9824 - val_loss: 0.0546 - val_accuracy: 0.9779\n",
      "Epoch 861/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0572 - val_accuracy: 0.9776\n",
      "Epoch 862/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9830 - val_loss: 0.0523 - val_accuracy: 0.9787\n",
      "Epoch 863/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 0.0533 - val_accuracy: 0.9789\n",
      "Epoch 864/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9821 - val_loss: 0.0607 - val_accuracy: 0.9778\n",
      "Epoch 865/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.0524 - val_accuracy: 0.9784\n",
      "Epoch 866/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9826 - val_loss: 0.0516 - val_accuracy: 0.9799\n",
      "Epoch 867/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9823 - val_loss: 0.0573 - val_accuracy: 0.9781\n",
      "Epoch 868/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 0.0521 - val_accuracy: 0.9787\n",
      "Epoch 869/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.0554 - val_accuracy: 0.9775\n",
      "Epoch 870/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9826 - val_loss: 0.0552 - val_accuracy: 0.9785\n",
      "Epoch 871/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9818 - val_loss: 0.0511 - val_accuracy: 0.9798\n",
      "Epoch 872/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9816 - val_loss: 0.0740 - val_accuracy: 0.9750\n",
      "Epoch 873/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0493 - accuracy: 0.9825 - val_loss: 0.0522 - val_accuracy: 0.9780\n",
      "Epoch 874/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9829 - val_loss: 0.0660 - val_accuracy: 0.9760\n",
      "Epoch 875/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9822 - val_loss: 0.0578 - val_accuracy: 0.9781\n",
      "Epoch 876/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.9819 - val_loss: 0.0574 - val_accuracy: 0.9780\n",
      "Epoch 877/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9828 - val_loss: 0.0544 - val_accuracy: 0.9779\n",
      "Epoch 878/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9820 - val_loss: 0.0588 - val_accuracy: 0.9770\n",
      "Epoch 879/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9817 - val_loss: 0.0571 - val_accuracy: 0.9771\n",
      "Epoch 880/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.9823 - val_loss: 0.0548 - val_accuracy: 0.9782\n",
      "Epoch 881/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9822 - val_loss: 0.0508 - val_accuracy: 0.9786\n",
      "Epoch 882/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9825 - val_loss: 0.0611 - val_accuracy: 0.9763\n",
      "Epoch 883/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9822 - val_loss: 0.0529 - val_accuracy: 0.9784\n",
      "Epoch 884/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0516 - accuracy: 0.9812 - val_loss: 0.0519 - val_accuracy: 0.9792\n",
      "Epoch 885/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 0.0596 - val_accuracy: 0.9774\n",
      "Epoch 886/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0462 - accuracy: 0.9834 - val_loss: 0.0517 - val_accuracy: 0.9781\n",
      "Epoch 887/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9828 - val_loss: 0.0583 - val_accuracy: 0.9774\n",
      "Epoch 888/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9823 - val_loss: 0.0559 - val_accuracy: 0.9778\n",
      "Epoch 889/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9822 - val_loss: 0.0529 - val_accuracy: 0.9781\n",
      "Epoch 890/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.0546 - val_accuracy: 0.9782\n",
      "Epoch 891/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9827 - val_loss: 0.0557 - val_accuracy: 0.9781\n",
      "Epoch 892/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9828 - val_loss: 0.0540 - val_accuracy: 0.9779\n",
      "Epoch 893/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9831 - val_loss: 0.0509 - val_accuracy: 0.9791\n",
      "Epoch 894/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9811 - val_loss: 0.0538 - val_accuracy: 0.9784\n",
      "Epoch 895/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9827 - val_loss: 0.0654 - val_accuracy: 0.9764\n",
      "Epoch 896/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9828 - val_loss: 0.0599 - val_accuracy: 0.9769\n",
      "Epoch 897/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9824 - val_loss: 0.0561 - val_accuracy: 0.9773\n",
      "Epoch 898/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9817 - val_loss: 0.0585 - val_accuracy: 0.9771\n",
      "Epoch 899/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9820 - val_loss: 0.0559 - val_accuracy: 0.9773\n",
      "Epoch 900/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.0576 - val_accuracy: 0.9778\n",
      "Epoch 901/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9829 - val_loss: 0.0510 - val_accuracy: 0.9786\n",
      "Epoch 902/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9829 - val_loss: 0.0607 - val_accuracy: 0.9768\n",
      "Epoch 903/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9828 - val_loss: 0.0588 - val_accuracy: 0.9771\n",
      "Epoch 904/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9828 - val_loss: 0.0531 - val_accuracy: 0.9779\n",
      "Epoch 905/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.0508 - val_accuracy: 0.9787\n",
      "Epoch 906/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9830 - val_loss: 0.0567 - val_accuracy: 0.9781\n",
      "Epoch 907/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9831 - val_loss: 0.0481 - val_accuracy: 0.9797\n",
      "Epoch 908/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9818 - val_loss: 0.0533 - val_accuracy: 0.9791\n",
      "Epoch 909/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 0.0539 - val_accuracy: 0.9778\n",
      "Epoch 910/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9826 - val_loss: 0.0502 - val_accuracy: 0.9792\n",
      "Epoch 911/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9826 - val_loss: 0.0583 - val_accuracy: 0.9775\n",
      "Epoch 912/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9819 - val_loss: 0.0535 - val_accuracy: 0.9782\n",
      "Epoch 913/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9829 - val_loss: 0.0575 - val_accuracy: 0.9777\n",
      "Epoch 914/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9819 - val_loss: 0.0549 - val_accuracy: 0.9786\n",
      "Epoch 915/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.0655 - val_accuracy: 0.9760\n",
      "Epoch 916/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9816 - val_loss: 0.0617 - val_accuracy: 0.9766\n",
      "Epoch 917/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9830 - val_loss: 0.0495 - val_accuracy: 0.9787\n",
      "Epoch 918/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 0.0522 - val_accuracy: 0.9784\n",
      "Epoch 919/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9820 - val_loss: 0.0526 - val_accuracy: 0.9782\n",
      "Epoch 920/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9818 - val_loss: 0.0547 - val_accuracy: 0.9779\n",
      "Epoch 921/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 0.0534 - val_accuracy: 0.9790\n",
      "Epoch 922/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9828 - val_loss: 0.0599 - val_accuracy: 0.9776\n",
      "Epoch 923/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 0.0605 - val_accuracy: 0.9769\n",
      "Epoch 924/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9819 - val_loss: 0.0706 - val_accuracy: 0.9754\n",
      "Epoch 925/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9819 - val_loss: 0.0517 - val_accuracy: 0.9779\n",
      "Epoch 926/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9826 - val_loss: 0.0562 - val_accuracy: 0.9770\n",
      "Epoch 927/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9833 - val_loss: 0.0705 - val_accuracy: 0.9756\n",
      "Epoch 928/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9824 - val_loss: 0.0600 - val_accuracy: 0.9773\n",
      "Epoch 929/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9824 - val_loss: 0.0513 - val_accuracy: 0.9791\n",
      "Epoch 930/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9822 - val_loss: 0.0544 - val_accuracy: 0.9785\n",
      "Epoch 931/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9826 - val_loss: 0.0604 - val_accuracy: 0.9771\n",
      "Epoch 932/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9824 - val_loss: 0.0582 - val_accuracy: 0.9779\n",
      "Epoch 933/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9826 - val_loss: 0.0581 - val_accuracy: 0.9774\n",
      "Epoch 934/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9830 - val_loss: 0.0685 - val_accuracy: 0.9763\n",
      "Epoch 935/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9831 - val_loss: 0.0569 - val_accuracy: 0.9780\n",
      "Epoch 936/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9819 - val_loss: 0.0511 - val_accuracy: 0.9795\n",
      "Epoch 937/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9827 - val_loss: 0.0577 - val_accuracy: 0.9779\n",
      "Epoch 938/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.0555 - val_accuracy: 0.9776\n",
      "Epoch 939/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9830 - val_loss: 0.0581 - val_accuracy: 0.9761\n",
      "Epoch 940/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9835 - val_loss: 0.0531 - val_accuracy: 0.9788\n",
      "Epoch 941/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9829 - val_loss: 0.0554 - val_accuracy: 0.9784\n",
      "Epoch 942/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9829 - val_loss: 0.0564 - val_accuracy: 0.9781\n",
      "Epoch 943/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9823 - val_loss: 0.0529 - val_accuracy: 0.9788\n",
      "Epoch 944/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9834 - val_loss: 0.0525 - val_accuracy: 0.9776\n",
      "Epoch 945/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9832 - val_loss: 0.0607 - val_accuracy: 0.9767\n",
      "Epoch 946/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9827 - val_loss: 0.0587 - val_accuracy: 0.9777\n",
      "Epoch 947/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9838 - val_loss: 0.0621 - val_accuracy: 0.9773\n",
      "Epoch 948/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.0590 - val_accuracy: 0.9769\n",
      "Epoch 949/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.0544 - val_accuracy: 0.9784\n",
      "Epoch 950/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9824 - val_loss: 0.0552 - val_accuracy: 0.9785\n",
      "Epoch 951/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9830 - val_loss: 0.0558 - val_accuracy: 0.9778\n",
      "Epoch 952/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 0.0603 - val_accuracy: 0.9768\n",
      "Epoch 953/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9834 - val_loss: 0.0704 - val_accuracy: 0.9754\n",
      "Epoch 954/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9814 - val_loss: 0.0555 - val_accuracy: 0.9784\n",
      "Epoch 955/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9828 - val_loss: 0.0651 - val_accuracy: 0.9768\n",
      "Epoch 956/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9830 - val_loss: 0.0530 - val_accuracy: 0.9790\n",
      "Epoch 957/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9827 - val_loss: 0.0525 - val_accuracy: 0.9798\n",
      "Epoch 958/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9832 - val_loss: 0.0538 - val_accuracy: 0.9779\n",
      "Epoch 959/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.0562 - val_accuracy: 0.9781\n",
      "Epoch 960/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.0565 - val_accuracy: 0.9785\n",
      "Epoch 961/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9827 - val_loss: 0.0514 - val_accuracy: 0.9785\n",
      "Epoch 962/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9827 - val_loss: 0.0623 - val_accuracy: 0.9766\n",
      "Epoch 963/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9821 - val_loss: 0.0539 - val_accuracy: 0.9790\n",
      "Epoch 964/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9835 - val_loss: 0.0523 - val_accuracy: 0.9790\n",
      "Epoch 965/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9824 - val_loss: 0.0559 - val_accuracy: 0.9778\n",
      "Epoch 966/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9823 - val_loss: 0.0530 - val_accuracy: 0.9790\n",
      "Epoch 967/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9828 - val_loss: 0.0575 - val_accuracy: 0.9777\n",
      "Epoch 968/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9827 - val_loss: 0.0503 - val_accuracy: 0.9785\n",
      "Epoch 969/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9832 - val_loss: 0.0550 - val_accuracy: 0.9778\n",
      "Epoch 970/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9826 - val_loss: 0.0641 - val_accuracy: 0.9771\n",
      "Epoch 971/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9831 - val_loss: 0.0666 - val_accuracy: 0.9764\n",
      "Epoch 972/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 0.0534 - val_accuracy: 0.9785\n",
      "Epoch 973/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9824 - val_loss: 0.0526 - val_accuracy: 0.9788\n",
      "Epoch 974/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9828 - val_loss: 0.0719 - val_accuracy: 0.9758\n",
      "Epoch 975/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9821 - val_loss: 0.0518 - val_accuracy: 0.9791\n",
      "Epoch 976/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9831 - val_loss: 0.0583 - val_accuracy: 0.9776\n",
      "Epoch 977/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9826 - val_loss: 0.0666 - val_accuracy: 0.9761\n",
      "Epoch 978/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9825 - val_loss: 0.0506 - val_accuracy: 0.9799\n",
      "Epoch 979/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9828 - val_loss: 0.0566 - val_accuracy: 0.9778\n",
      "Epoch 980/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.0595 - val_accuracy: 0.9774\n",
      "Epoch 981/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9824 - val_loss: 0.0551 - val_accuracy: 0.9787\n",
      "Epoch 982/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9828 - val_loss: 0.0525 - val_accuracy: 0.9775\n",
      "Epoch 983/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9818 - val_loss: 0.0589 - val_accuracy: 0.9770\n",
      "Epoch 984/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9825 - val_loss: 0.0585 - val_accuracy: 0.9778\n",
      "Epoch 985/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9832 - val_loss: 0.0505 - val_accuracy: 0.9797\n",
      "Epoch 986/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9823 - val_loss: 0.0593 - val_accuracy: 0.9769\n",
      "Epoch 987/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9832 - val_loss: 0.0537 - val_accuracy: 0.9780\n",
      "Epoch 988/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9829 - val_loss: 0.0525 - val_accuracy: 0.9795\n",
      "Epoch 989/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9821 - val_loss: 0.0561 - val_accuracy: 0.9778\n",
      "Epoch 990/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9838 - val_loss: 0.0501 - val_accuracy: 0.9799\n",
      "Epoch 991/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9827 - val_loss: 0.0568 - val_accuracy: 0.9778\n",
      "Epoch 992/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9829 - val_loss: 0.0547 - val_accuracy: 0.9786\n",
      "Epoch 993/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9828 - val_loss: 0.0591 - val_accuracy: 0.9775\n",
      "Epoch 994/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9828 - val_loss: 0.0543 - val_accuracy: 0.9781\n",
      "Epoch 995/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9834 - val_loss: 0.0495 - val_accuracy: 0.9797\n",
      "Epoch 996/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9829 - val_loss: 0.0576 - val_accuracy: 0.9780\n",
      "Epoch 997/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9832 - val_loss: 0.0631 - val_accuracy: 0.9770\n",
      "Epoch 998/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.0561 - val_accuracy: 0.9780\n",
      "Epoch 999/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9829 - val_loss: 0.0574 - val_accuracy: 0.9776\n",
      "Epoch 1000/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9819 - val_loss: 0.0541 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 962us/step\n",
      "xtrain: (85868, 59), ytrain: (85868,)\n",
      "xvalid: (9011, 59), yvalid: (9011,)\n",
      "xtest: (9012, 59), ytest: (9012,)\n",
      "\n",
      "classification_report_Fold=5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Normal 0       0.99      0.98      0.99      8725\n",
      " Anomalous 1       0.58      0.82      0.68       287\n",
      "\n",
      "    accuracy                           0.98      9012\n",
      "   macro avg       0.79      0.90      0.83      9012\n",
      "weighted avg       0.98      0.98      0.98      9012\n",
      "\n",
      "confusion_matrix_Fold=5:\n",
      "\n",
      "True Negatives:  8558\n",
      "False Positives:  167\n",
      "False Negatives:  53\n",
      "True Positives:  234\n",
      "accuracy_score_Fold=5:\n",
      " 8792 \n",
      "\n",
      "End running time Fold=5: 210214_111150 ,-------------------------- \n",
      "\n",
      "\n",
      "classification_report_AllFolds:\n",
      "            Normal 0  Anomalous 1\n",
      "precision      0.99         0.59\n",
      "recall         0.98         0.83\n",
      "f1-score       0.99         0.69\n",
      "End running time: 210214_111150\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = None\n",
    "pd.set_option('display.max_columns', 500)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "random.seed(12345)\n",
    "\n",
    "###Start sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import recall_score, auc, roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.model_selection import train_test_split,TimeSeriesSplit,cross_val_score,KFold,cross_validate,GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "### End sklearn\n",
    "\n",
    "###***Start tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tf.random.set_seed(1234)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "###**** End tensorflow.keras\n",
    "#sys.path.append(\"..\")\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "pathAug = \"/content/drive/MyDrive/MasterThesis_Files/mainCodes/augmentation/\"\n",
    "#pathData =\"/content/drive/MyDrive/MasterThesis_Files/mainCodes/data/forCrossValidation/forAugShifted5/\"\n",
    "pathData =\"/content/drive/MyDrive/MasterThesis_Files/mainCodes/data/forCrossValidation/Shifted5_Rol_Lbl1/\"\n",
    "\n",
    "\n",
    "sys.path.insert(0,pathAug)\n",
    "sys.path.insert(1,pathData)\n",
    "\n",
    "import preprocessRollingLabel2_NN as aug\n",
    "\n",
    "\n",
    "#####End Import Libraries\n",
    "\n",
    "\n",
    "############ Start Running codes\n",
    "\n",
    "datestr = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "print(f\"Main Start running time : {datestr}\")\n",
    "\n",
    "accPerFold = []\n",
    "lossPerFold = []\n",
    "dfPrReF1=pd.DataFrame()\n",
    "\n",
    "\n",
    "# dfActual = pd.read_csv(pathData+\"dfpShifted5_ForAug_201201_202734_AllTested_Correct_NT_NH.csv\",header=None)\n",
    "#dfActual = pd.read_csv(pathData+\"dfpShifted5ForAug_1To5_FromAllTrainTest_201204_192153.csv\",header=None)\n",
    "dfActual = pd.read_csv(pathData+\"dfpShifted5_Rolling_210110_191921.csv\",header=None)\n",
    "\n",
    "\n",
    "\n",
    "#dfActual=dfActual[:5000]\n",
    "\n",
    "yX=dfActual.values\n",
    "X = yX[:, 1:]  # converts the df to a numpy array\n",
    "y = yX[:, 0]\n",
    "\n",
    "print(f\"\\n Number of Actual labeled 0: {len(y[np.where(y==0)])}\")\n",
    "print(f\"Number of Actual labeled 1: {len(y[np.where(y==1)])}\")\n",
    "print(f\"Number of Actual labeled 2: {len(y[np.where(y==2)])} \\n\")\n",
    "\n",
    "\n",
    "dataSplitPCT=.3\n",
    "dataSplitValTestPCT=.5\n",
    "\n",
    "train_test_split_Shuffle=True\n",
    "flagFitShuffle = True#False\n",
    "flagSeed=True\n",
    "\n",
    "p1=\"\"\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)#5\n",
    "# skf = KFold(n_splits=5,shuffle=False)#5\n",
    "model=0\n",
    "\n",
    "for foldNum, (trainIndex, testIndex) in enumerate(skf.split(X,y),start=1):\n",
    "\n",
    "    #print(\"TRAIN:\", trainIndex, \"TEST:\", testIndex)\n",
    "\n",
    "    yXtrain, yXtest = yX[trainIndex], yX[testIndex]\n",
    "    #ytrain, ytest = y[trainIndex], y[testIndex]\n",
    "\n",
    "    AugedNN=aug.GenerateAug_NN_Rolling(yXtrain,foldNum,flagLbl2=False,jitterNum4Lbl1=7,jitterNum4Lbl2=3)###***Generate synthetic data\n",
    "\n",
    "    datestrfoldNum = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "    print(f\"\\n Start running time Fold={foldNum}: {datestrfoldNum} ,-------------------------- \\n\")\n",
    "\n",
    "    Actual_AugedNN=np.concatenate((yXtrain,AugedNN),axis=0)\n",
    "    #yXtrain=Actual_AugedNN\n",
    "\n",
    "    yXtrain1, yXtrain2 = train_test_split(Actual_AugedNN, shuffle=train_test_split_Shuffle,\n",
    "                                                          test_size=dataSplitPCT, random_state=42,\n",
    "                                                          stratify=Actual_AugedNN[:,0])  # stratify=input_y\n",
    "\n",
    "    yXtrain = np.concatenate((yXtrain1, yXtrain2), axis=0)\n",
    "\n",
    "    yXvalid, yXtest = train_test_split(yXtest, shuffle=train_test_split_Shuffle,\n",
    "                                          test_size=dataSplitValTestPCT, random_state=42,\n",
    "                                          stratify=yXtest[:, 0])  # stratify=input_y\n",
    "\n",
    "    print(f\"\\n Number of Final yXtrain_Fold={foldNum} labeled 0: {len(yXtrain[np.where(yXtrain[:, 0] == 0)])}\")\n",
    "    print(f\"Number of Final yXtrain_Fold={foldNum} labeled 1: {len(yXtrain[np.where(yXtrain[:, 0] == 1)])}\")\n",
    "    print(f\"Number of Final yXtrain_Fold={foldNum} labeled 2: {len(yXtrain[np.where(yXtrain[:, 0] == 2)])} \\n\")\n",
    "\n",
    "    ytrain = yXtrain  [:,0]\n",
    "    yvalid = yXvalid  [:,0]\n",
    "    ytest  = yXtest   [:,0]\n",
    "\n",
    "    xtrain = yXtrain  [:,1:]\n",
    "    xvalid = yXvalid  [:,1:]\n",
    "    xtest  = yXtest   [:,1:]\n",
    "\n",
    "\n",
    "    neurons = xtrain.shape[1]\n",
    "\n",
    "    epochs = 1000#50#40#60#30#30# 150  # 0  # 100#300#60#300#10#200#00#150\n",
    "    batch = 512#32\n",
    "    lr = 0.0001\n",
    "\n",
    "    #flagR1 = True\n",
    "    flagR1=False\n",
    "    r1 = .1\n",
    "    r2 = .1\n",
    "    d1 = .2\n",
    "\n",
    "    if foldNum==1:\n",
    "        print(\"\\n Hyperparameters:\")\n",
    "        print(f\"epochs: {epochs}, batch: {batch}, lr: {lr}, neurons: {neurons}, flagFitShuffle: {flagFitShuffle} , train_test_split_Shuffle: {train_test_split_Shuffle}, flagSeed: {flagSeed}\\n \")\n",
    "\n",
    "        print(f\"\\n xtrain: {np.shape(xtrain)}, ytrain: {np.shape(ytrain)}\")\n",
    "        print(f\"xvalid: {np.shape(xvalid)}, yvalid: {np.shape(yvalid)}\")\n",
    "        print(f\"xtest: {np.shape(xtest)}, ytest: {np.shape(ytest)} \\n\")\n",
    "\n",
    "        #p1 = os.path.join(str(pathCurrent.parent.parent), \"Results\", \"Results_001_class_oppys\", \"bestModels\", \"\")\n",
    "\n",
    "        # pathSavingPlotsPerRunning = pathSavingPlots + datestr #+ \"_\" + modelname\n",
    "        # if not os.path.exists(pathSavingPlotsPerRunning):\n",
    "        #     os.makedirs(pathSavingPlotsPerRunning)\n",
    "\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(177, activation='tanh', input_dim=xtrain.shape[1]\n",
    "                    #,kernel_regularizer = l1(r1) if flagR1 else l2(r2),\n",
    "                    ))  # , input_dim=xtrain.shape[1]\n",
    "    #model.add(Dropout(d1))\n",
    "\n",
    "    model.add(Dense(150, activation='tanh',\n",
    "                   #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\n",
    "                   #kernel_regularizer=l1_l2(l1=r1, l2=r2),\n",
    "                    # bias_regularizer=l1(r2),\n",
    "                    #activity_regularizer=l1(r1) if flagR1 else l2(r2)\n",
    "                    # activity_regularizer=l1(r2)\n",
    "                    ))\n",
    "    #model.add(Dropout(d1))\n",
    "\n",
    "    model.add(Dense(90, activation='tanh',\n",
    "                    #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\n",
    "                    #kernel_regularizer=l1_l2(l1=r1, l2=r2)\n",
    "                    # bias_regularizer=l1(r2),\n",
    "                    #activity_regularizer = l1(r1) if flagR1 else l2(r2)\n",
    "                    # activity_regularizer=l2(r2)\n",
    "                    ))\n",
    "    #model.add(Dropout(d1))\n",
    "\n",
    "    # model.add(Dense(32, activation='tanh',\n",
    "    #                #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\n",
    "    #                 # bias_regularizer=l1(r2),\n",
    "    #                 #activity_regularizer = l1(r1) if flagR1 else l2(r2)\n",
    "    #                 # activity_regularizer=l2(r2)\n",
    "    #                 ))\n",
    "    #model.add(Dropout(d1))\n",
    "\n",
    "    # model.add(Dense(16, activation='tanh',\n",
    "    #                kernel_regularizer=l1(r1) if flagR1 else l2(r2),\n",
    "    #                #kernel_regularizer=l1_l2(l1=r1, l2=r2),\n",
    "    # #                 # bias_regularizer=l1(r2),\n",
    "    #                 #activity_regularizer=l1(r1) if flagR1 else l2(r2)\n",
    "    # #                 # activity_regularizer=l2(r2)\n",
    "    #                 ))\n",
    "    #model.add(Dropout(d1))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    adam = optimizers.Adam(lr)#lr\n",
    "    # cp = ModelCheckpoint(filepath=\"lstm_autoencoder_classifier.h5\",save_best_only=True,verbose=0)\n",
    "\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    #model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "    if foldNum == 1:\n",
    "        print(\"\\n Final test model.summary(): \\n\")\n",
    "        print(model.summary())\n",
    "\n",
    "        print(f\"\\n model.get_config: {str(model.get_config())}\")\n",
    "\n",
    "    # fit model\n",
    "    history1 = model.fit(xtrain, ytrain, batch_size=batch, epochs=epochs\n",
    "                         , validation_data=(xvalid, yvalid)\n",
    "                         , verbose=1, use_multiprocessing=True,\n",
    "                         shuffle=flagFitShuffle).history  # ,shuffle=True#,callbacks=[es]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history1['loss'], linewidth=2, label='Train')  # OR accuracy\n",
    "    plt.plot(history1['val_loss'], linewidth=2, label='Validation')  # OR val_accuracy\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.13, 1.13))\n",
    "    plt.title(f'Model loss Fold={foldNum}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,.2)\n",
    "    plt.xlabel('Epoch')\n",
    "\n",
    "    #plt.savefig(pathSavingPlotsPerRunning +\"/\" + f\"loss&val_loss_Fold={foldNum}_Epochs{epochs}_flagSeed{flagSeed}.png\", dpi=300, format='png')\n",
    "    plt.show()\n",
    "\n",
    "    yPred = model.predict(xtest, verbose=1)\n",
    "\n",
    "    l = []\n",
    "    for i in yPred:\n",
    "        if i < .5:\n",
    "            l.append(0)\n",
    "        else:\n",
    "            l.append(1)\n",
    "\n",
    "    yPred = l\n",
    "\n",
    "    print(f\"xtrain: {np.shape(xtrain)}, ytrain: {np.shape(ytrain)}\")\n",
    "    print(f\"xvalid: {np.shape(xvalid)}, yvalid: {np.shape(yvalid)}\")\n",
    "    print(f\"xtest: {np.shape(xtest)}, ytest: {np.shape(ytest)}\")\n",
    "\n",
    "\n",
    "    target_names = ['Normal 0', 'Anomalous 1']\n",
    "    print(f\"\\nclassification_report_Fold={foldNum}:\")\n",
    "    print(classification_report(ytest, yPred, target_names=target_names))\n",
    "\n",
    "    cr = pd.DataFrame(classification_report(ytest, yPred, target_names=target_names,output_dict=True))\n",
    "    dfPrReF1 = dfPrReF1.append(cr.iloc[:3, :2])\n",
    "\n",
    "    print(f\"confusion_matrix_Fold={foldNum}:\\n\")\n",
    "    tn, fp, fn, tp = confusion_matrix(ytest, yPred, labels=[0, 1]).ravel()\n",
    "    print(\"True Negatives: \", tn)\n",
    "    print(\"False Positives: \", fp)\n",
    "    print(\"False Negatives: \", fn)\n",
    "    print(\"True Positives: \", tp)\n",
    "\n",
    "\n",
    "    print(f\"accuracy_score_Fold={foldNum}:\\n {accuracy_score(ytest, yPred, normalize=False)} \\n\")\n",
    "\n",
    "    # Predicting test images\n",
    "    # preds = np.where(yPred < 0.5, 0, 1)\n",
    "\n",
    "    # mlbClasses = [0, 1, 2]\n",
    "    # # Plot confusion matrix\n",
    "    # plt.figure(figsize=(14, 8))\n",
    "    # for j, (label, matrix) in enumerate(zip(mlbClasses, mlbConfusion)):\n",
    "    #     plt.subplot(f'23{j + 1}')\n",
    "    #     labels = [f'Not_{label}', label]\n",
    "    #     sns.heatmap(matrix, annot=True, square=True, fmt='d', cbar=False, cmap='Blues',\n",
    "    #                 cbar_kws={'label': 'My Colorbar'},  # , fmt = 'd'\n",
    "    #                 xticklabels=labels, yticklabels=labels, linecolor='black', linewidth=1)\n",
    "    #\n",
    "    #     plt.ylabel('Actual class')\n",
    "    #     plt.xlabel(f'Predicted class_Fold={foldNum}')\n",
    "    #     plt.title(labels[0])\n",
    "    #\n",
    "    # plt.tight_layout()\n",
    "    #plt.savefig(pathSavingPlotsPerRunning +\"/\" + f\"ConfusionMatrix_Fold={foldNum}_Epochs{epochs}_flagSeed{flagSeed}.png\", dpi=300, format='png')\n",
    "    #plt.show()\n",
    "\n",
    "    datestr = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "    print(f\"End running time Fold={foldNum}: {datestr} ,-------------------------- \\n\")\n",
    "\n",
    "dfPrReF1=pd.DataFrame([np.round(dfPrReF1[dfPrReF1.index=='precision'].mean(),2),\n",
    "                       np.round(dfPrReF1[dfPrReF1.index=='recall'].mean(),2),np.round(dfPrReF1[dfPrReF1.index=='f1-score'].mean(),2)],\n",
    "                      index=['precision','recall','f1-score'])\n",
    "\n",
    "print(f\"\\nclassification_report_AllFolds:\\n {dfPrReF1}\")\n",
    "\n",
    "\n",
    "datestr = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "print(f\"End running time: {datestr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytjrnQfmjjrg"
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Etm5OKtgw-8L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89vp3n4lw-_z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkoWUjPkw_w3"
   },
   "source": [
    "## **Test that GPU is availabel or not:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaFQbEX0xGA3"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N23z3hoKxNoy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llcLaaLUxRtq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hovsUijExUsh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iex2kV8XxY8i"
   },
   "source": [
    "# **Test Camacity of assigned RAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvnEElW2xeYC"
   },
   "outputs": [],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELbwa_h-xeuh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "TestAuged_NN_Rolling_CV.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

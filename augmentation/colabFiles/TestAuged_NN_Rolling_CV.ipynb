{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestAuged_NN_Rolling_CV.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1IILKca04H8psf9XY5uPRo-nYXCUrv3RQ",
      "authorship_tag": "ABX9TyMccftFG99iilqeUTtqFY1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majidam20/MTP_AD/blob/main/mainCodes/augmentation/TestAuged_NN_Rolling_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U28pRChlTIhp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bveYbeBQTJmz"
      },
      "source": [
        "## **Start running RolLbl2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXy5Uq85HaYs"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "import gc\r\n",
        "import random\r\n",
        "import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "pd.options.display.max_rows = None\r\n",
        "pd.set_option('display.max_columns', 500)\r\n",
        "np.set_printoptions(threshold=sys.maxsize)\r\n",
        "np.set_printoptions(threshold=np.inf)\r\n",
        "\r\n",
        "os.environ['PYTHONHASHSEED'] = '0'\r\n",
        "np.random.seed(42)\r\n",
        "random.seed(12345)\r\n",
        "\r\n",
        "###Start sklearn\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\r\n",
        "from sklearn.metrics import recall_score, auc, roc_curve, roc_auc_score, precision_recall_curve\r\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\r\n",
        "from sklearn.model_selection import train_test_split,TimeSeriesSplit,cross_val_score,KFold,cross_validate,GridSearchCV\r\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\r\n",
        "from sklearn.metrics import multilabel_confusion_matrix\r\n",
        "### End sklearn\r\n",
        "\r\n",
        "###***Start tensorflow.keras\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.constraints import max_norm\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Dropout\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "tf.random.set_seed(1234)\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2\r\n",
        "###**** End tensorflow.keras\r\n",
        "#sys.path.append(\"..\")\r\n",
        "\r\n",
        "import sys\r\n",
        "from pathlib import Path\r\n",
        "pathAug = \"/content/drive/MyDrive/MasterThesis_Files/mainCodes/augmentation/\"\r\n",
        "pathData =\"/content/drive/MyDrive/MasterThesis_Files/mainCodes/data/forCrossValidation/Shifted5_Rol_Lbl2/\"\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "sys.path.insert(0,pathAug)\r\n",
        "sys.path.insert(1,pathData)\r\n",
        "\r\n",
        "import preprocessRollingLabel2_NN as aug\r\n",
        "\r\n",
        "#####End Import Libraries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5KxzUHw03_x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j29MxY7LgANj"
      },
      "source": [
        "\n",
        "############ Start Running codes\n",
        "\n",
        "\n",
        "datestr = time.strftime(\"%y%m%d_%H%M%S\")\n",
        "print(f\"Main Start running time : {datestr}\")\n",
        "\n",
        "#dfActual = pd.read_csv(pathData+\"Shifted5_NoLess5_AfterRol_Lbl2_5To1_210124_163135.csv\",header=None)\n",
        "dfActual = pd.read_csv(pathData+\"Shifted5_NoLess5_AfterRol_Lbl2_210124_155122.csv\",header=None)\n",
        "\n",
        "\n",
        "dfActual.head()\n",
        "\n",
        "accPerFold = []\n",
        "lossPerFold = []\n",
        "dfPrReF1=pd.DataFrame()\n",
        "\n",
        "#dfActual=dfActual[:5000]\n",
        "\n",
        "yX=dfActual.values\n",
        "X = yX[:, 1:]  # converts the df to a numpy array\n",
        "y = yX[:, 0]\n",
        "\n",
        "print(f\"\\n Number of Actual labeled 0: {len(y[np.where(y==0)])}\")\n",
        "print(f\"Number of Actual labeled 1: {len(y[np.where(y==1)])}\")\n",
        "print(f\"Number of Actual labeled 2: {len(y[np.where(y==2)])} \\n\")\n",
        "\n",
        "\n",
        "dataSplitPCT=.3\n",
        "dataSplitValTestPCT=.5\n",
        "\n",
        "train_test_split_Shuffle=True\n",
        "flagFitShuffle = True\n",
        "flagSeed=True\n",
        "\n",
        "p1=\"\"\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5,shuffle=True)#5\n",
        "model=0\n",
        "\n",
        "for foldNum, (trainIndex, testIndex) in enumerate(skf.split(X,y),start=1):\n",
        "\n",
        "    #print(\"TRAIN:\", trainIndex, \"TEST:\", testIndex)\n",
        "\n",
        "    yXtrain, yXtest = yX[trainIndex], yX[testIndex]\n",
        "    #ytrain, ytest = y[trainIndex], y[testIndex]\n",
        "\n",
        "    AugedNN=aug.GenerateAug_NN_Rolling(yXtrain,foldNum,flagLbl2=True,jitterNum4Lbl1=4,jitterNum4Lbl2=38)###***Generate synthetic data 38\n",
        "\n",
        "    datestrfoldNum = time.strftime(\"%y%m%d_%H%M%S\")\n",
        "    print(f\"\\n Start running time Fold={foldNum}: {datestrfoldNum} ,-------------------------- \\n\")\n",
        "\n",
        "    Actual_AugedNN=np.concatenate((yXtrain,AugedNN),axis=0)\n",
        "\n",
        "    yXtrain1, yXtrain2 = train_test_split(Actual_AugedNN, shuffle=train_test_split_Shuffle,\n",
        "                                                          test_size=dataSplitPCT, random_state=42,\n",
        "                                                          stratify=Actual_AugedNN[:,0])  # stratify=input_y\n",
        "\n",
        "    yXtrain = np.concatenate((yXtrain1, yXtrain2), axis=0)\n",
        "\n",
        "    yXvalid, yXtest = train_test_split(yXtest, shuffle=train_test_split_Shuffle,\n",
        "                                          test_size=dataSplitValTestPCT, random_state=42,\n",
        "                                          stratify=yXtest[:, 0])  # stratify=input_y\n",
        "\n",
        "    print(f\"\\n Number of Final yXtrain_Fold={foldNum} labeled 0: {len(yXtrain[np.where(yXtrain[:, 0] == 0)])}\")\n",
        "    print(f\"Number of Final yXtrain_Fold={foldNum} labeled 1: {len(yXtrain[np.where(yXtrain[:, 0] == 1)])}\")\n",
        "    print(f\"Number of Final yXtrain_Fold={foldNum} labeled 2: {len(yXtrain[np.where(yXtrain[:, 0] == 2)])} \\n\")\n",
        "\n",
        "    ytrain = to_categorical(yXtrain  [:,0] )\n",
        "    yvalid = to_categorical(yXvalid  [:,0] )\n",
        "    ytest  = to_categorical(yXtest   [:,0] )\n",
        "\n",
        "    xtrain = yXtrain  [:,1:]\n",
        "    xvalid = yXvalid  [:,1:]\n",
        "    xtest  = yXtest   [:,1:]\n",
        "\n",
        "\n",
        "    neurons = xtrain.shape[1]\n",
        "\n",
        "    epochs = 150#100#0#30#30# 150  # 0  # 100#300#60#300#10#200#00#150\n",
        "    batch = 512\n",
        "    lr = 0.0001\n",
        "\n",
        "    #flagR1 = True\n",
        "    flagR1=False\n",
        "    r1 = .1\n",
        "    r2 = .1\n",
        "    d1 = .2\n",
        "\n",
        "    if foldNum==1:\n",
        "        print(\"\\n Hyperparameters:\")\n",
        "        print(f\"epochs: {epochs}, batch: {batch}, lr: {lr}, neurons: {neurons}, flagFitShuffle: {flagFitShuffle} , train_test_split_Shuffle: {train_test_split_Shuffle}, flagSeed: {flagSeed}\\n \")\n",
        "\n",
        "        print(f\"\\n xtrain: {np.shape(xtrain)}, ytrain: {np.shape(ytrain)}\")\n",
        "        print(f\"xvalid: {np.shape(xvalid)}, yvalid: {np.shape(yvalid)}\")\n",
        "        print(f\"xtest: {np.shape(xtest)}, ytest: {np.shape(ytest)} \\n\")\n",
        "\n",
        "        #p1 = os.path.join(str(pathCurrent.parent.parent), \"Results\", \"Results_001_class_oppys\", \"bestModels\", \"\")\n",
        "        # pathSavingPlotsPerRunning = pathSavingPlots + datestr #+ \"_\" + modelname\n",
        "        # if not os.path.exists(pathSavingPlotsPerRunning):\n",
        "        #     os.makedirs(pathSavingPlotsPerRunning)\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(177, activation='tanh', input_dim=xtrain.shape[1]\n",
        "                    #,kernel_regularizer = l1(r1) if flagR1 else l2(r2),\n",
        "                    ))  # , input_dim=xtrain.shape[1]\n",
        "    #model.add(Dropout(d1))\n",
        "\n",
        "    model.add(Dense(150, activation='tanh'\n",
        "                    #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\n",
        "                    # ,# kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4),\n",
        "                    # bias_regularizer=l1(r2),\n",
        "                    #activity_regularizer=l1(r1) if flagR1 else l2(r2)\n",
        "                    # activity_regularizer=l1(r2)\n",
        "                    ))\n",
        "    #model.add(Dropout(d1))\n",
        "\n",
        "    model.add(Dense(90, activation='tanh'\n",
        "                   #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\n",
        "                    # bias_regularizer=l1(r2),\n",
        "                    #activity_regularizer = l1(r1) if flagR1 else l2(r2)\n",
        "                    # activity_regularizer=l2(r2)\n",
        "                    ))\n",
        "    #model.add(Dropout(d1))\n",
        "\n",
        "    model.add(Dense(295, activation='tanh'\n",
        "                    #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\n",
        "    #                 # bias_regularizer=l1(r2),\n",
        "    #                 activity_regularizer=l1(r1) if flagR1 else l2(r2)\n",
        "    #                 # activity_regularizer=l2(r2)\n",
        "                    ))\n",
        "    #model.add(Dropout(d1))\n",
        "\n",
        "    # model.add(Dense(1, activation='sigmoid'))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    adam = optimizers.Adam(lr)#lr\n",
        "    # cp = ModelCheckpoint(filepath=\"lstm_autoencoder_classifier.h5\",save_best_only=True,verbose=0)\n",
        "    # model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "    if foldNum == 1:\n",
        "        print(\"\\n Final test model.summary(): \\n\")\n",
        "        print(model.summary())\n",
        "\n",
        "        print(f\"\\n model.get_config: {str(model.get_config())}\")\n",
        "\n",
        "    # fit model\n",
        "    history1 = model.fit(xtrain, ytrain, batch_size=batch, epochs=epochs\n",
        "                         , validation_data=(xvalid, yvalid)\n",
        "                         , verbose=1, use_multiprocessing=True,\n",
        "                         shuffle=flagFitShuffle).history  # ,shuffle=True#,callbacks=[es]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(history1['loss'], linewidth=2, label='Train')  # OR accuracy\n",
        "    plt.plot(history1['val_loss'], linewidth=2, label='Validation')  # OR val_accuracy\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(1.13, 1.13))\n",
        "    plt.title(f'Model loss Fold={foldNum}')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "\n",
        "    #plt.savefig(pathSavingPlotsPerRunning +\"/\" + f\"loss&val_loss_Fold={foldNum}_Epochs{epochs}_flagSeed{flagSeed}.png\", dpi=300, format='png')\n",
        "    plt.show()\n",
        "\n",
        "    yPred = model.predict(xtest, verbose=1)\n",
        "\n",
        "    print(f\"confusion_matrix_Fold={foldNum}:\\n {confusion_matrix(ytest.argmax(axis=1), yPred.argmax(axis=1))} \\n\")\n",
        "\n",
        "    # Creating multilabel confusion matrix\n",
        "    mlbConfusion = multilabel_confusion_matrix(ytest.argmax(axis=1), yPred.argmax(axis=1))\n",
        "    print(f\"multilabel_confusion_matrix_Fold={foldNum}:\\n {mlbConfusion} \\n\")\n",
        "\n",
        "    print(f\"accuracy_score_Fold={foldNum}:\\n {accuracy_score(ytest.argmax(axis=1), yPred.argmax(axis=1), normalize=False)} \\n\")\n",
        "\n",
        "    print(f\"classification_report_Fold={foldNum}:\\n {classification_report(ytest.argmax(axis=1), yPred.argmax(axis=1))} \\n\")\n",
        "\n",
        "    cr=pd.DataFrame(classification_report(ytest.argmax(axis=1), yPred.argmax(axis=1),output_dict=True))\n",
        "    dfPrReF1=dfPrReF1.append(cr.iloc[:3,:3])\n",
        "\n",
        "    # Predicting test images\n",
        "    # preds = np.where(yPred < 0.5, 0, 1)\n",
        "\n",
        "    mlbClasses = [0, 1, 2]\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for j, (label, matrix) in enumerate(zip(mlbClasses, mlbConfusion)):\n",
        "        plt.subplot(f'23{j + 1}')\n",
        "        labels = [f'Not_{label}', label]\n",
        "        sns.heatmap(matrix, annot=True, square=True, fmt='d', cbar=False, cmap='Blues',\n",
        "                    cbar_kws={'label': 'My Colorbar'},  # , fmt = 'd'\n",
        "                    xticklabels=labels, yticklabels=labels, linecolor='black', linewidth=1)\n",
        "\n",
        "        plt.ylabel('Actual class')\n",
        "        plt.xlabel(f'Predicted class_Fold={foldNum}')\n",
        "        plt.title(labels[0])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig(pathSavingPlotsPerRunning +\"/\" + f\"ConfusionMatrix_Fold={foldNum}_Epochs{epochs}_flagSeed{flagSeed}.png\", dpi=300, format='png')\n",
        "    plt.show()\n",
        "\n",
        "    datestr = time.strftime(\"%y%m%d_%H%M%S\")\n",
        "    print(f\"End running time Fold={foldNum}: {datestr} ,-------------------------- \\n\")\n",
        "\n",
        "dfPrReF1=pd.DataFrame([np.round(dfPrReF1[dfPrReF1.index=='precision'].mean(),2),np.round(dfPrReF1[dfPrReF1.index=='recall'].mean(),2)\n",
        ",np.round(dfPrReF1[dfPrReF1.index=='f1-score'].mean(),2)],index=['precision','recall','f1-score'])\n",
        "\n",
        "print(f\"\\nclassification_report_AllFolds:\\n {dfPrReF1}\")\n",
        "\n",
        "datestr = time.strftime(\"%y%m%d_%H%M%S\")\n",
        "print(f\"End running time: {datestr}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuXYtlqxpsNe"
      },
      "source": [
        "# End running  RolLbl2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9zEE1AkST-3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu1S5oeop9-Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiOORdHtqT-x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKUFvQagSUGD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVVZVyLVj_Zc"
      },
      "source": [
        "from tensorflow.python.client import device_lib\r\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ9Rj0YFjfWx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX9ZZl-73Ev5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP6J0IarSgdJ"
      },
      "source": [
        "## **forAugShifted5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz1jPyPPm6Ir"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "import gc\r\n",
        "import random\r\n",
        "import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "pd.options.display.max_rows = None\r\n",
        "pd.set_option('display.max_columns', 500)\r\n",
        "np.set_printoptions(threshold=sys.maxsize)\r\n",
        "np.set_printoptions(threshold=np.inf)\r\n",
        "\r\n",
        "os.environ['PYTHONHASHSEED'] = '0'\r\n",
        "np.random.seed(42)\r\n",
        "random.seed(12345)\r\n",
        "\r\n",
        "###Start sklearn\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\r\n",
        "from sklearn.metrics import recall_score, auc, roc_curve, roc_auc_score, precision_recall_curve\r\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\r\n",
        "from sklearn.model_selection import train_test_split,TimeSeriesSplit,cross_val_score,KFold,cross_validate,GridSearchCV\r\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\r\n",
        "from sklearn.metrics import multilabel_confusion_matrix\r\n",
        "### End sklearn\r\n",
        "\r\n",
        "###***Start tensorflow.keras\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.constraints import max_norm\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Dropout\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "tf.random.set_seed(1234)\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2\r\n",
        "###**** End tensorflow.keras\r\n",
        "#sys.path.append(\"..\")\r\n",
        "import sys\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "pathAug = \"/content/drive/MyDrive/MasterThesis_Files/mainCodes/augmentation/\"\r\n",
        "#pathData =\"/content/drive/MyDrive/MasterThesis_Files/mainCodes/data/forCrossValidation/forAugShifted5/\"\r\n",
        "pathData =\"/content/drive/MyDrive/MasterThesis_Files/mainCodes/data/forCrossValidation/Shifted5_Rol_Lbl1/\"\r\n",
        "\r\n",
        "\r\n",
        "sys.path.insert(0,pathAug)\r\n",
        "sys.path.insert(1,pathData)\r\n",
        "\r\n",
        "import preprocessRollingLabel2_NN as aug\r\n",
        "\r\n",
        "\r\n",
        "#####End Import Libraries\r\n",
        "\r\n",
        "\r\n",
        "############ Start Running codes\r\n",
        "\r\n",
        "datestr = time.strftime(\"%y%m%d_%H%M%S\")\r\n",
        "print(f\"Main Start running time : {datestr}\")\r\n",
        "\r\n",
        "accPerFold = []\r\n",
        "lossPerFold = []\r\n",
        "dfPrReF1=pd.DataFrame()\r\n",
        "\r\n",
        "\r\n",
        "# dfActual = pd.read_csv(pathData+\"dfpShifted5_ForAug_201201_202734_AllTested_Correct_NT_NH.csv\",header=None)\r\n",
        "#dfActual = pd.read_csv(pathData+\"dfpShifted5ForAug_1To5_FromAllTrainTest_201204_192153.csv\",header=None)\r\n",
        "dfActual = pd.read_csv(pathData+\"dfpShifted5_Rolling_210110_191921.csv\",header=None)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#dfActual=dfActual[:5000]\r\n",
        "\r\n",
        "yX=dfActual.values\r\n",
        "X = yX[:, 1:]  # converts the df to a numpy array\r\n",
        "y = yX[:, 0]\r\n",
        "\r\n",
        "print(f\"\\n Number of Actual labeled 0: {len(y[np.where(y==0)])}\")\r\n",
        "print(f\"Number of Actual labeled 1: {len(y[np.where(y==1)])}\")\r\n",
        "print(f\"Number of Actual labeled 2: {len(y[np.where(y==2)])} \\n\")\r\n",
        "\r\n",
        "\r\n",
        "dataSplitPCT=.3\r\n",
        "dataSplitValTestPCT=.5\r\n",
        "\r\n",
        "train_test_split_Shuffle=True\r\n",
        "flagFitShuffle = True\r\n",
        "flagSeed=True\r\n",
        "\r\n",
        "p1=\"\"\r\n",
        "\r\n",
        "skf = StratifiedKFold(n_splits=5,shuffle=True)#5\r\n",
        "model=0\r\n",
        "\r\n",
        "for foldNum, (trainIndex, testIndex) in enumerate(skf.split(X,y),start=1):\r\n",
        "\r\n",
        "    #print(\"TRAIN:\", trainIndex, \"TEST:\", testIndex)\r\n",
        "\r\n",
        "    yXtrain, yXtest = yX[trainIndex], yX[testIndex]\r\n",
        "    #ytrain, ytest = y[trainIndex], y[testIndex]\r\n",
        "\r\n",
        "    AugedNN=aug.GenerateAug_NN_Rolling(yXtrain,foldNum,flagLbl2=False,jitterNum4Lbl1=6,jitterNum4Lbl2=5)###***Generate synthetic data\r\n",
        "\r\n",
        "    datestrfoldNum = time.strftime(\"%y%m%d_%H%M%S\")\r\n",
        "    print(f\"\\n Start running time Fold={foldNum}: {datestrfoldNum} ,-------------------------- \\n\")\r\n",
        "\r\n",
        "    Actual_AugedNN=np.concatenate((yXtrain,AugedNN),axis=0)\r\n",
        "\r\n",
        "    yXtrain1, yXtrain2 = train_test_split(Actual_AugedNN, shuffle=train_test_split_Shuffle,\r\n",
        "                                                          test_size=dataSplitPCT, random_state=42,\r\n",
        "                                                          stratify=Actual_AugedNN[:,0])  # stratify=input_y\r\n",
        "\r\n",
        "    yXtrain = np.concatenate((yXtrain1, yXtrain2), axis=0)\r\n",
        "\r\n",
        "    yXvalid, yXtest = train_test_split(yXtest, shuffle=train_test_split_Shuffle,\r\n",
        "                                          test_size=dataSplitValTestPCT, random_state=42,\r\n",
        "                                          stratify=yXtest[:, 0])  # stratify=input_y\r\n",
        "\r\n",
        "    print(f\"\\n Number of Final yXtrain_Fold={foldNum} labeled 0: {len(yXtrain[np.where(yXtrain[:, 0] == 0)])}\")\r\n",
        "    print(f\"Number of Final yXtrain_Fold={foldNum} labeled 1: {len(yXtrain[np.where(yXtrain[:, 0] == 1)])}\")\r\n",
        "    print(f\"Number of Final yXtrain_Fold={foldNum} labeled 2: {len(yXtrain[np.where(yXtrain[:, 0] == 2)])} \\n\")\r\n",
        "\r\n",
        "    ytrain = yXtrain  [:,0]\r\n",
        "    yvalid = yXvalid  [:,0]\r\n",
        "    ytest  = yXtest   [:,0]\r\n",
        "\r\n",
        "    xtrain = yXtrain  [:,1:]\r\n",
        "    xvalid = yXvalid  [:,1:]\r\n",
        "    xtest  = yXtest   [:,1:]\r\n",
        "\r\n",
        "\r\n",
        "    neurons = xtrain.shape[1]\r\n",
        "\r\n",
        "    epochs = 50#40#60#30#30# 150  # 0  # 100#300#60#300#10#200#00#150\r\n",
        "    batch = 32\r\n",
        "    lr = 0.001\r\n",
        "\r\n",
        "    #flagR1 = True\r\n",
        "    flagR1=False\r\n",
        "    r1 = .1\r\n",
        "    r2 = .1\r\n",
        "    d1 = .2\r\n",
        "\r\n",
        "    if foldNum==1:\r\n",
        "        print(\"\\n Hyperparameters:\")\r\n",
        "        print(f\"epochs: {epochs}, batch: {batch}, lr: {lr}, neurons: {neurons}, flagFitShuffle: {flagFitShuffle} , train_test_split_Shuffle: {train_test_split_Shuffle}, flagSeed: {flagSeed}\\n \")\r\n",
        "\r\n",
        "        print(f\"\\n xtrain: {np.shape(xtrain)}, ytrain: {np.shape(ytrain)}\")\r\n",
        "        print(f\"xvalid: {np.shape(xvalid)}, yvalid: {np.shape(yvalid)}\")\r\n",
        "        print(f\"xtest: {np.shape(xtest)}, ytest: {np.shape(ytest)} \\n\")\r\n",
        "\r\n",
        "        #p1 = os.path.join(str(pathCurrent.parent.parent), \"Results\", \"Results_001_class_oppys\", \"bestModels\", \"\")\r\n",
        "\r\n",
        "        # pathSavingPlotsPerRunning = pathSavingPlots + datestr #+ \"_\" + modelname\r\n",
        "        # if not os.path.exists(pathSavingPlotsPerRunning):\r\n",
        "        #     os.makedirs(pathSavingPlotsPerRunning)\r\n",
        "\r\n",
        "\r\n",
        "    del model\r\n",
        "    gc.collect()\r\n",
        "    tf.keras.backend.clear_session()\r\n",
        "    tf.compat.v1.reset_default_graph()\r\n",
        "\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(177, activation='tanh', input_dim=xtrain.shape[1]\r\n",
        "                    #,kernel_regularizer = l1(r1) if flagR1 else l2(r2),\r\n",
        "                    ))  # , input_dim=xtrain.shape[1]\r\n",
        "    #model.add(Dropout(d1))\r\n",
        "\r\n",
        "    model.add(Dense(150, activation='tanh',\r\n",
        "                   #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\r\n",
        "                   #kernel_regularizer=l1_l2(l1=r1, l2=r2),\r\n",
        "                    # bias_regularizer=l1(r2),\r\n",
        "                    #activity_regularizer=l1(r1) if flagR1 else l2(r2)\r\n",
        "                    # activity_regularizer=l1(r2)\r\n",
        "                    ))\r\n",
        "    #model.add(Dropout(d1))\r\n",
        "\r\n",
        "    model.add(Dense(90, activation='tanh',\r\n",
        "                    #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\r\n",
        "                    #kernel_regularizer=l1_l2(l1=r1, l2=r2)\r\n",
        "                    # bias_regularizer=l1(r2),\r\n",
        "                    #activity_regularizer = l1(r1) if flagR1 else l2(r2)\r\n",
        "                    # activity_regularizer=l2(r2)\r\n",
        "                    ))\r\n",
        "    #model.add(Dropout(d1))\r\n",
        "\r\n",
        "    # model.add(Dense(32, activation='tanh',\r\n",
        "    #                #kernel_regularizer=l1(r1) if flagR1 else l2(r2),\r\n",
        "    #                 # bias_regularizer=l1(r2),\r\n",
        "    #                 #activity_regularizer = l1(r1) if flagR1 else l2(r2)\r\n",
        "    #                 # activity_regularizer=l2(r2)\r\n",
        "    #                 ))\r\n",
        "    #model.add(Dropout(d1))\r\n",
        "\r\n",
        "    # model.add(Dense(16, activation='tanh',\r\n",
        "    #                kernel_regularizer=l1(r1) if flagR1 else l2(r2),\r\n",
        "    #                #kernel_regularizer=l1_l2(l1=r1, l2=r2),\r\n",
        "    # #                 # bias_regularizer=l1(r2),\r\n",
        "    #                 #activity_regularizer=l1(r1) if flagR1 else l2(r2)\r\n",
        "    # #                 # activity_regularizer=l2(r2)\r\n",
        "    #                 ))\r\n",
        "    #model.add(Dropout(d1))\r\n",
        "\r\n",
        "    model.add(Dense(1, activation='sigmoid'))\r\n",
        "    # model.add(Dense(3, activation='softmax'))\r\n",
        "\r\n",
        "    adam = optimizers.Adam(lr)#lr\r\n",
        "    # cp = ModelCheckpoint(filepath=\"lstm_autoencoder_classifier.h5\",save_best_only=True,verbose=0)\r\n",
        "\r\n",
        "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "    #model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "    # es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\r\n",
        "\r\n",
        "    if foldNum == 1:\r\n",
        "        print(\"\\n Final test model.summary(): \\n\")\r\n",
        "        print(model.summary())\r\n",
        "\r\n",
        "        print(f\"\\n model.get_config: {str(model.get_config())}\")\r\n",
        "\r\n",
        "    # fit model\r\n",
        "    history1 = model.fit(xtrain, ytrain, batch_size=batch, epochs=epochs\r\n",
        "                         , validation_data=(xvalid, yvalid)\r\n",
        "                         , verbose=1, #use_multiprocessing=True,\r\n",
        "                         shuffle=flagFitShuffle).history  # ,shuffle=True#,callbacks=[es]\r\n",
        "\r\n",
        "    plt.figure()\r\n",
        "    plt.plot(history1['loss'], linewidth=2, label='Train')  # OR accuracy\r\n",
        "    plt.plot(history1['val_loss'], linewidth=2, label='Validation')  # OR val_accuracy\r\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(1.13, 1.13))\r\n",
        "    plt.title(f'Model loss Fold={foldNum}')\r\n",
        "    plt.ylabel('Loss')\r\n",
        "    plt.ylim(0,1)\r\n",
        "    plt.xlabel('Epoch')\r\n",
        "\r\n",
        "    #plt.savefig(pathSavingPlotsPerRunning +\"/\" + f\"loss&val_loss_Fold={foldNum}_Epochs{epochs}_flagSeed{flagSeed}.png\", dpi=300, format='png')\r\n",
        "    #plt.show()\r\n",
        "\r\n",
        "    yPred = model.predict(xtest, verbose=1)\r\n",
        "\r\n",
        "    l = []\r\n",
        "    for i in yPred:\r\n",
        "        if i < .5:\r\n",
        "            l.append(0)\r\n",
        "        else:\r\n",
        "            l.append(1)\r\n",
        "\r\n",
        "    yPred = l\r\n",
        "\r\n",
        "    print(f\"xtrain: {np.shape(xtrain)}, ytrain: {np.shape(ytrain)}\")\r\n",
        "    print(f\"xvalid: {np.shape(xvalid)}, yvalid: {np.shape(yvalid)}\")\r\n",
        "    print(f\"xtest: {np.shape(xtest)}, ytest: {np.shape(ytest)}\")\r\n",
        "\r\n",
        "\r\n",
        "    target_names = ['Normal 0', 'Anomalous 1']\r\n",
        "    print(f\"\\nclassification_report_Fold={foldNum}:\")\r\n",
        "    print(classification_report(ytest, yPred, target_names=target_names))\r\n",
        "\r\n",
        "    cr = pd.DataFrame(classification_report(ytest, yPred, target_names=target_names,output_dict=True))\r\n",
        "    dfPrReF1 = dfPrReF1.append(cr.iloc[:3, :2])\r\n",
        "\r\n",
        "    print(f\"confusion_matrix_Fold={foldNum}:\\n\")\r\n",
        "    tn, fp, fn, tp = confusion_matrix(ytest, yPred, labels=[0, 1]).ravel()\r\n",
        "    print(\"True Negatives: \", tn)\r\n",
        "    print(\"False Positives: \", fp)\r\n",
        "    print(\"False Negatives: \", fn)\r\n",
        "    print(\"True Positives: \", tp)\r\n",
        "\r\n",
        "\r\n",
        "    print(f\"accuracy_score_Fold={foldNum}:\\n {accuracy_score(ytest, yPred, normalize=False)} \\n\")\r\n",
        "\r\n",
        "    # Predicting test images\r\n",
        "    # preds = np.where(yPred < 0.5, 0, 1)\r\n",
        "\r\n",
        "    # mlbClasses = [0, 1, 2]\r\n",
        "    # # Plot confusion matrix\r\n",
        "    # plt.figure(figsize=(14, 8))\r\n",
        "    # for j, (label, matrix) in enumerate(zip(mlbClasses, mlbConfusion)):\r\n",
        "    #     plt.subplot(f'23{j + 1}')\r\n",
        "    #     labels = [f'Not_{label}', label]\r\n",
        "    #     sns.heatmap(matrix, annot=True, square=True, fmt='d', cbar=False, cmap='Blues',\r\n",
        "    #                 cbar_kws={'label': 'My Colorbar'},  # , fmt = 'd'\r\n",
        "    #                 xticklabels=labels, yticklabels=labels, linecolor='black', linewidth=1)\r\n",
        "    #\r\n",
        "    #     plt.ylabel('Actual class')\r\n",
        "    #     plt.xlabel(f'Predicted class_Fold={foldNum}')\r\n",
        "    #     plt.title(labels[0])\r\n",
        "    #\r\n",
        "    # plt.tight_layout()\r\n",
        "    #plt.savefig(pathSavingPlotsPerRunning +\"/\" + f\"ConfusionMatrix_Fold={foldNum}_Epochs{epochs}_flagSeed{flagSeed}.png\", dpi=300, format='png')\r\n",
        "    #plt.show()\r\n",
        "    datestr = time.strftime(\"%y%m%d_%H%M%S\")\r\n",
        "    print(f\"End running time Fold={foldNum}: {datestr} ,-------------------------- \\n\")\r\n",
        "\r\n",
        "dfPrReF1=pd.DataFrame([np.round(dfPrReF1[dfPrReF1.index=='precision'].mean(),2),\r\n",
        "                       np.round(dfPrReF1[dfPrReF1.index=='recall'].mean(),2),np.round(dfPrReF1[dfPrReF1.index=='f1-score'].mean(),2)],\r\n",
        "                      index=['precision','recall','f1-score'])\r\n",
        "\r\n",
        "print(f\"\\nclassification_report_AllFolds:\\n {dfPrReF1}\")\r\n",
        "\r\n",
        "\r\n",
        "datestr = time.strftime(\"%y%m%d_%H%M%S\")\r\n",
        "print(f\"End running time: {datestr}\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytjrnQfmjjrg"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etm5OKtgw-8L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89vp3n4lw-_z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkoWUjPkw_w3"
      },
      "source": [
        "## **Test that GPU is availabel or not:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaFQbEX0xGA3"
      },
      "source": [
        "gpu_info = !nvidia-smi\r\n",
        "gpu_info = '\\n'.join(gpu_info)\r\n",
        "if gpu_info.find('failed') >= 0:\r\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\r\n",
        "  print('and then re-execute this cell.')\r\n",
        "else:\r\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N23z3hoKxNoy"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llcLaaLUxRtq"
      },
      "source": [
        "from tensorflow.python.client import device_lib\r\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hovsUijExUsh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iex2kV8XxY8i"
      },
      "source": [
        "# **Test Camacity of assigned RAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvnEElW2xeYC"
      },
      "source": [
        "from psutil import virtual_memory\r\n",
        "ram_gb = virtual_memory().total / 1e9\r\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\r\n",
        "\r\n",
        "if ram_gb < 20:\r\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\r\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\r\n",
        "  print('re-execute this cell.')\r\n",
        "else:\r\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELbwa_h-xeuh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
import os
import sys
import random
import time
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
pd.options.display.max_rows = None
pd.set_option('display.max_columns', 500)
np.set_printoptions(threshold=sys.maxsize)
np.set_printoptions(threshold=np.inf)
os.environ['PYTHONHASHSEED'] = '0'
random.seed(12345)
np.random.seed(42)

###Start sklearn
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import recall_score, auc, roc_curve, roc_auc_score, precision_recall_curve
from sklearn.metrics import precision_recall_fscore_support, f1_score
from sklearn.model_selection import train_test_split,TimeSeriesSplit,cross_val_score,KFold,cross_validate,GridSearchCV
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn import preprocessing
### End sklearn

###***Start tensorflow.keras
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import optimizers
from tensorflow.keras.optimizers import Adam
tf.random.set_seed(1234)
###**** End tensorflow.keras

from pathlib import Path
pathCurrrent = Path.cwd()
pathMainCodes = Path.cwd().parent
pathCurrrent = str(pathCurrrent).replace("\\", '/')
pathMainCodes = str(pathMainCodes).replace("\\", '/')
pathData = pathMainCodes + "/data/paperMachine/"
pathDataAuged = pathMainCodes + "/data/paperMachine/auged/"
pathDataAuged_jitter = pathMainCodes + "/data/paperMachine/auged/jitterFor_NN/jitters/"
pathData_NewFromWeb = pathMainCodes + "/data/paperMachine/paperMachine_NewFromWeb/"

7###NN model tests

datestr = time.strftime("%y%m%d_%H%M%S")
print(f"Start running time: {datestr}")

#dfpShifted5ForAug = pd.read_csv(pathData+"dfpShifted5_ForAug_201201_202734_AllTested_Correct_NT_NH.csv",header=None)# All LSTM generated by this DS
#dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5JitterAuged_1To5_201204_192153.csv",header=None)#.8
# dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_ForAug_withAugedFawaz_OneZero_1To5_201221_002448.csv",header=None)# Fawaz
#dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_ForAug_withAugedJitter_OneZero_1To5_201220_013915.csv",header=None)#Jitter
#dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_ForAug_withAugedFawaz4_OneZero_1To5_201221_011005.csv",header=None)# Fawaz*4
#dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_AugedMagnitude_OneZero_1To5_201222_154819.csv",header=None)#Magnitude
#dfpShifted5JitterAuged = pd.read_csv(pathData+"dfpShifted5_AugedFawazAll_OneZero_1To5_201223_172909.csv",header=None)# FawazAll
dfpShifted5ForAug = pd.read_csv(pathData_NewFromWeb+"dfpShifted5_ForAug_AllTrainTest_201204_161806.csv",header=None)#shuffled
#dfpShifted5ForAug = pd.read_csv(pathDataAuged_jitter+"df_jitter_OneZero_testSigma2_NN_201228_201804.csv",header=None)

dfpShifted5ForAug = dfpShifted5ForAug.loc[dfpShifted5ForAug[0]==1]
print(dfpShifted5ForAug.shape)
#dfpShifted5JitterAuged = dfpShifted5JitterAuged.loc[dfpShifted5JitterAuged[0]==0]

dfActual=dfpShifted5ForAug
#dfJAuged=dfpShifted5JitterAuged

rowCounts0 = len(dfActual)
#rowCounts1 = len(dfJAuged)

input_XActual = dfActual.iloc[:rowCounts0, 1:].values  # converts the df to a numpy array
input_yActual = dfActual.iloc[:rowCounts0, 0].values


#min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-10000, 20000))
#input_XActual = min_max_scaler.fit_transform(input_XActual)



epochs = 3#10#00
batch = 32
lr = 0.001
neurons=128
flagFitShuffle=True

print("Hyperparameters:")
print(f"epochs: {epochs}, batch: {batch}, lr: {lr}, neurons: {neurons}, flagFitShuffle: {flagFitShuffle} \n ")

adam = optimizers.Adam(lr)

class ExampleRandomNormal(tf.keras.initializers.Initializer):

    def __init__(self, mean, stddev):
      self.mean = mean
      self.stddev = stddev

    def __call__(self, shape, dtype=None):
      return tf.random.normal(shape, mean=self.mean, stddev=self.stddev, dtype=dtype)

    def get_config(self):  # To support serialization
      return {'mean': self.mean, 'stddev': self.stddev}

# initializer = ExampleRandomNormal(-1, 1)# tf.keras.initializers.RandomUniform(-1, 1)
# config = initializer.get_config()
# initializer = tf.keras.initializers.from_config(config)

model = Sequential()
model.add(Dense(input_XActual.shape[1], activation='tanh',input_dim=input_XActual.shape[1]))#,input_shape=(input_XActual.shape[1],),
model.add(Dense(neurons, activation='tanh'))#,kernel_initializer=initializer
model.add(Dense(neurons, activation='tanh'))
model.add(Dense(input_XActual.shape[1], activation='tanh'))

model.compile(optimizer=adam, loss='mse')

print(model.summary())


# cp = ModelCheckpoint(filepath="lstm_autoencoder_classifier.h5",
#                                save_best_only=True,
#                                verbose=0)

# tb = TensorBoard(log_dir='./logs',
#                 histogram_freq=0,
#                 write_graph=True,
#                 write_images=True)

autoencoder_history = model.fit(input_XActual, input_XActual,
                                                epochs=epochs,
                                                batch_size=batch,
                                                #validation_data=(xValidActual, xValidActual),
                                                verbose=1, use_multiprocessing=True,shuffle=flagFitShuffle)#.history,shuffle=False

# W_Input_Hidden = model.layers[0].get_weights()[0]
# W_Output_Hidden = model.layers[1].get_weights()[0]
#
# B_Input_Hidden = model.layers[0].get_weights()[1]
# B_Output_Hidden = model.layers[1].get_weights()[1]
#
# W_Input_Hidden = model.layers[2].get_weights()[0]
# W_Output_Hidden = model.layers[3].get_weights()[0]
#
# B_Input_Hidden = model.layers[2].get_weights()[1]
# B_Output_Hidden = model.layers[3].get_weights()[1]
#
# yPred = model.predict(input_XActual)
#
# W_Input_Hidden = model.layers[0].get_weights()[0]
# W_Output_Hidden = model.layers[1].get_weights()[0]
#
# B_Input_Hidden = model.layers[0].get_weights()[1]
# B_Output_Hidden = model.layers[1].get_weights()[1]
#
# W_Input_Hidden = model.layers[2].get_weights()[0]
# W_Output_Hidden = model.layers[3].get_weights()[0]
#
# B_Input_Hidden = model.layers[2].get_weights()[1]
# B_Output_Hidden = model.layers[3].get_weights()[1]

yPred=model.predict_proba(input_XActual)

datestr = time.strftime("%y%m%d_%H%M%S")

#pd.DataFrame(yPred).to_csv(pathDataAuged+'jitterFor_NN/'+f'dfpShifted5_Auged_NN_Ones_5To1_peyman_{datestr}.csv',index=None,header=None)
#pd.DataFrame(yPred).to_csv(pathDataAuged+'jitterFor_NN/'+f'dfpShifted5_Auged_NN_Ones_5To1_jitter_{datestr}.csv',index=None,header=None)
mse = np.mean(np.power(input_XActual - yPred, 2), axis=1)

print(f"MSE==> mean: {mse.mean()}, min: {mse.min()}, max: {mse.max()}")

datestr = time.strftime("%y%m%d_%H%M%S")
print(f"End running time: {datestr}")

